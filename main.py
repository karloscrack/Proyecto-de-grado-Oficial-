import shutil
import os
import logging
import datetime
import zipfile
import hashlib
import boto3
import cv2 
import numpy as np
import tempfile 
import smtplib
import pytz
import json
import io
import difflib
import psycopg2
from psycopg2.extras import RealDictCursor
import os
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from typing import Optional, List
from fastapi import FastAPI, UploadFile, Form, HTTPException, BackgroundTasks, Request, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse, StreamingResponse
from botocore.config import Config
from pydantic import BaseModel

# --- 0. CONFIGURACI√ìN DE ZONA HORARIA ECUADOR ---
ECUADOR_TZ = pytz.timezone('America/Guayaquil')  # UTC-5

def ahora_ecuador():
    """Devuelve la fecha/hora actual en zona horaria de Ecuador"""
    return datetime.datetime.now(ECUADOR_TZ)

# --- CONFIGURACI√ìN DE CORREO ---
SMTP_SERVER = "smtp.gmail.com"
SMTP_PORT = 465  # <--- Aseg√∫rate de que sea 465
SMTP_EMAIL = "karlos.ayala.lopez.1234@gmail.com"
SMTP_PASSWORD = "mzjg jvxj mruk qgeb"

# --- 1. CONFIGURACI√ìN Y CREDENCIALES AWS/B2 ---
AWS_ACCESS_KEY = os.environ.get("AWS_ACCESS_KEY")
AWS_SECRET_KEY = os.environ.get("AWS_SECRET_KEY")
AWS_REGION = "us-east-1"
COLLECTION_ID = "estudiantes_db"

# Inicializaci√≥n condicional de AWS Rekognition
try:
    if AWS_ACCESS_KEY and AWS_SECRET_KEY:
        rekog = boto3.client('rekognition', region_name=AWS_REGION, 
                           aws_access_key_id=AWS_ACCESS_KEY, 
                           aws_secret_access_key=AWS_SECRET_KEY)
        print("‚úÖ AWS Rekognition inicializado")
    else:
        rekog = None
        print("‚ö†Ô∏è AWS Rekognition no disponible (credenciales faltantes)")
except Exception as e:
    rekog = None
    print(f"‚ö†Ô∏è Error inicializando AWS Rekognition: {e}")

# Configuraci√≥n Backblaze B2
ENDPOINT_B2 = "https://s3.us-east-005.backblazeb2.com"
KEY_ID_B2 = "00508884373dab40000000001"
APP_KEY_B2 = "K005jvkLLmLdUKhhVis1qLcnU4flx0g"
BUCKET_NAME = "Proyecto-Grado-Karlos-2025"

try:
    my_config = Config(signature_version='s3v4', region_name='us-east-005')
    s3_client = boto3.client('s3', 
                            endpoint_url=ENDPOINT_B2,
                            aws_access_key_id=KEY_ID_B2,
                            aws_secret_access_key=APP_KEY_B2,
                            config=my_config)
    print("‚úÖ Cliente S3 (Backblaze) inicializado")
except Exception as e:
    s3_client = None
    print(f"‚ö†Ô∏è Cliente S3 no disponible: {e}")

# Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

# --- L√ìGICA DE VOLUMEN PERSISTENTE ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_FILENAME = "Bases_de_datos.db"
VOLUMEN_PATH = "/app/datos_persistentes"

# Determinar ruta final de la base de datos
if os.path.exists(VOLUMEN_PATH):
    db_en_volumen = os.path.join(VOLUMEN_PATH, DB_FILENAME)
    if not os.path.exists(db_en_volumen):
        db_original = os.path.join(BASE_DIR, DB_FILENAME)
        if os.path.exists(db_original):
            shutil.copy(db_original, db_en_volumen)
            print(f"‚úÖ Base de datos copiada al volumen persistente: {db_en_volumen}")
    DB_NAME = db_en_volumen
else:
    DB_NAME = os.path.join(BASE_DIR, DB_FILENAME)

print(f"üìÅ Ruta base de datos: {DB_NAME}")

def get_db_connection():
    try:
        # ‚úÖ URL DEL POOLER (La definitiva)
        # Usamos la direcci√≥n 'aws-1-sa-east-1...' que es compatible con Railway.
        # Puerto 6543 (Transaction Mode)
        
        conn_str = "postgresql://postgres.wwrbrabdwhoiougbaskz:1ZulgnaY0cnsz2p4@aws-1-sa-east-1.pooler.supabase.com:6543/postgres?sslmode=require"
        
        # Conectamos directamente (sin trucos de IP manual, ya no hacen falta)
        conn = psycopg2.connect(conn_str)
        conn.cursor_factory = RealDictCursor 
        return conn
    except Exception as e:
        print(f"‚ùå Error CR√çTICO conectando a Supabase: {e}")
        return None

# --- FUNCIONES DE MANTENIMIENTO ---
def optimizar_sistema_db():
    """Ejecuta mantenimiento VACUUM en Supabase"""
    try:
        conn = get_db_connection()
        # En Postgres, VACUUM no puede ejecutarse dentro de una transacci√≥n
        conn.autocommit = True 
        with conn.cursor() as c:
            c.execute("VACUUM")
            c.execute("ANALYZE")
        conn.close()
        print("‚úÖ Sistema optimizado (VACUUM ejecutado en Supabase)")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Alerta menor: No se pudo optimizar DB: {e}")
        return False

class EstadoUsuarioRequest(BaseModel):
    cedula: str
    activo: int

class BackupRequest(BaseModel):
    tipo: str = "completo"

# --- 2. INICIALIZACI√ìN DE BASE DE DATOS - MEJORADA ---
# --- INICIALIZACI√ìN DE TABLAS ---
def init_db_completa():
    print("üîÑ Iniciando configuraci√≥n de base de datos en Supabase...")
    try:
        conn = get_db_connection()
        if not conn:
            print("‚ùå No hay conexi√≥n a BD, abortando init.")
            return
            
        c = conn.cursor()
        
        # 1. Tabla Usuarios
        c.execute('''CREATE TABLE IF NOT EXISTS Usuarios (
            ID SERIAL PRIMARY KEY,
            Nombre TEXT NOT NULL,
            Apellido TEXT NOT NULL,
            CI TEXT UNIQUE NOT NULL,
            Password TEXT NOT NULL,
            Tipo INTEGER DEFAULT 1,
            Foto TEXT,
            Activo INTEGER DEFAULT 1,
            Fecha_Desactivacion TIMESTAMP NULL,
            Ultimo_Acceso TIMESTAMP NULL,
            TutorialVisto INTEGER DEFAULT 0,
            Face_Encoding TEXT,
            Fecha_Registro TIMESTAMP DEFAULT NOW(),
            Email TEXT,
            Telefono TEXT
        )''')
        
        # 2. Tabla Evidencias
        c.execute('''CREATE TABLE IF NOT EXISTS Evidencias (
            id SERIAL PRIMARY KEY,
            CI_Estudiante TEXT NOT NULL,
            Url_Archivo TEXT NOT NULL,
            Hash TEXT NOT NULL,
            Estado INTEGER DEFAULT 1,
            Tipo_Archivo TEXT DEFAULT 'documento',
            Fecha TIMESTAMP DEFAULT NOW(),
            Tamanio_KB REAL DEFAULT 0,
            Asignado_Automaticamente INTEGER DEFAULT 0
        )''')

        # 3. Tabla Solicitudes
        c.execute('''CREATE TABLE IF NOT EXISTS Solicitudes (
            id SERIAL PRIMARY KEY,
            Tipo TEXT NOT NULL,
            CI_Solicitante TEXT NOT NULL,
            Email TEXT,
            Detalle TEXT,
            Evidencia_Reportada_Url TEXT,
            Id_Evidencia INTEGER,
            Resuelto_Por TEXT,
            Respuesta TEXT,
            Fecha TIMESTAMP DEFAULT NOW(),
            Estado TEXT DEFAULT 'PENDIENTE',
            Fecha_Resolucion TIMESTAMP NULL
        )''')
        
        # 4. Tabla Auditoria
        c.execute('''CREATE TABLE IF NOT EXISTS Auditoria (
            id SERIAL PRIMARY KEY,
            Accion TEXT NOT NULL,
            Detalle TEXT,
            IP TEXT,
            Usuario TEXT,
            Fecha TIMESTAMP DEFAULT NOW()
        )''')
        
        # 5. Tabla M√©tricas
        c.execute('''CREATE TABLE IF NOT EXISTS Metricas_Sistema (
            id SERIAL PRIMARY KEY,
            Fecha DATE UNIQUE,
            Total_Usuarios INTEGER DEFAULT 0,
            Total_Evidencias INTEGER DEFAULT 0,
            Solicitudes_Pendientes INTEGER DEFAULT 0,
            Almacenamiento_MB REAL DEFAULT 0
        )''')
        
        # Crear Admin
        c.execute("SELECT CI FROM Usuarios WHERE Tipo=0")
        if not c.fetchone():
            c.execute("INSERT INTO Usuarios (Nombre, Apellido, CI, Password, Tipo, Activo) VALUES (%s,%s,%s,%s,%s,%s)", 
                     ('Admin', 'Sistema', '9999999999', 'admin123', 0, 1))
            print("‚úÖ Usuario admin creado en Supabase")

        # Crear Bandeja Recuperados
        c.execute("SELECT CI FROM Usuarios WHERE CI='9999999990'")
        if not c.fetchone():
            c.execute("INSERT INTO Usuarios (Nombre, Apellido, CI, Password, Tipo, Activo, Foto) VALUES (%s,%s,%s,%s,%s,%s,%s)", 
                     ('Bandeja', 'Recuperados', '9999999990', '123456', 1, 1, ''))
            print("‚úÖ Bandeja de Recuperados creada")
        
        conn.commit()
        conn.close()
        print("‚úÖ Base de datos Supabase inicializada correctamente.")
        
    except Exception as e:
        print(f"‚ùå Error inicializando Supabase: {e}")

# EJECUTAR INICIALIZACI√ìN (¬°Ahora s√≠, al final de las definiciones!)
init_db_completa()

# =========================================================================
# 3. FUNCIONES AUXILIARES
# =========================================================================

def registrar_auditoria(accion: str, detalle: str, usuario: str = "Sistema", ip: str = ""):
    """Registra una acci√≥n en la tabla de auditor√≠a con fecha de Ecuador"""
    try:
        fecha_ecuador = ahora_ecuador()
        conn = get_db_connection()
        c = conn.cursor() # <--- IMPORTANTE: Creamos el cursor
        
        c.execute("""
            INSERT INTO Auditoria (Accion, Detalle, Usuario, IP, Fecha) 
            VALUES (%s, %s, %s, %s, %s)
        """, (accion, detalle, usuario, ip, fecha_ecuador))
        
        conn.commit()
        conn.close()
        logging.info(f"AUDITORIA: {accion} - {detalle}")
    except Exception as e:
        logging.error(f"Error en auditoria: {e}")

def enviar_correo_real(destinatario: str, asunto: str, mensaje: str, html: bool = False) -> bool:
    import requests # Aseg√∫rate de poner 'requests' en tu requirements.txt
    
    # 1. Tu API KEY de Resend
    API_KEY = "re_UgHvnVwc_GoohB6so8khU8mCBmLJB1bzJ" 
    
    try:
        url = "https://api.resend.com/emails"
        payload = {
            # 2. AQU√ç PONES TU DOMINIO
            "from": "Soporte Despertar <soporte@uepdespertar-evidencias.work>",
            "to": [destinatario],
            "subject": asunto,
            "html": mensaje if html else f"<p>{mensaje}</p>"
        }
        headers = {
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json"
        }
        
        response = requests.post(url, json=payload, headers=headers)
        
        if response.status_code in [200, 201]:
            print(f"‚úÖ Correo enviado desde el dominio a {destinatario}")
            return True
        else:
            print(f"‚ùå Error Resend: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå Error de conexi√≥n: {e}")
        return False
    
def calcular_hash(ruta: str) -> str:
    """Calcula hash SHA256 de un archivo"""
    h = hashlib.sha256()
    with open(ruta, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            h.update(chunk)
    return h.hexdigest()

def obtener_tamanio_archivo_kb(ruta: str) -> float:
    """Obtiene el tama√±o de un archivo en KB"""
    try:
        return os.path.getsize(ruta) / 1024
    except:
        return 0

def optimizar_sistema_db():
    """Ejecuta mantenimiento VACUUM en Supabase"""
    try:
        conn = get_db_connection()
        # En Postgres, VACUUM no puede ejecutarse dentro de una transacci√≥n normal
        conn.autocommit = True 
        with conn.cursor() as c:
            c.execute("VACUUM")
            c.execute("ANALYZE")
        conn.close()
        print("‚úÖ Sistema optimizado (VACUUM ejecutado en Supabase)")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Alerta menor: No se pudo optimizar DB: {e}")
        return False

# --- REEMPLAZA TU FUNCI√ìN 'identificar_rostro_aws' POR ESTA ---
def preparar_imagen_aws(ruta_imagen):
    """
    1. Lee la imagen (soporta AVIF si las librer√≠as est√°n instaladas).
    2. La convierte SIEMPRE a JPG (compatible con AWS).
    3. Comprime si pesa m√°s de 5MB.
    """
    MAX_BYTES = 5242880 # 5 MB
    
    try:
        # Intentamos leer con OpenCV
        img = cv2.imread(ruta_imagen)
        
        # Si OpenCV falla (com√∫n con AVIF antiguos), intentamos con PIL (si est√° instalado)
        if img is None:
            try:
                from PIL import Image
                import numpy as np
                pil_img = Image.open(ruta_imagen).convert('RGB')
                img = np.array(pil_img) 
                # Convertir RGB (PIL) a BGR (OpenCV)
                img = img[:, :, ::-1].copy() 
            except ImportError:
                pass # Si no hay PIL, nos rendimos

        # Si despu√©s de todo no pudimos leer la imagen...
        if img is None:
            # Si es AVIF y no pudimos leerla, NO podemos mandarla cruda a AWS. Retornamos None o error.
            if ruta_imagen.lower().endswith('.avif'):
                print("‚ö†Ô∏è Error: No se pudo decodificar AVIF. Instala 'pillow-avif-plugin'.")
                return None
            # Si es JPG/PNG, mandamos crudo
            with open(ruta_imagen, 'rb') as f: return f.read()

        # COMPRESI√ìN / CONVERSI√ìN A JPG
        # Esto transforma el AVIF/WEBP/PNG a un JPG est√°ndar que AWS s√≠ entiende
        _, buffer = cv2.imencode('.jpg', img, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
        return buffer.tobytes()
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error preparando imagen AWS: {e}")
        with open(ruta_imagen, 'rb') as f: return f.read()

def identificar_varios_rostros_aws(imagen_path: str, confidence_threshold: float = 80.0) -> List[str]:
    if not rekog: return []
    cedulas_encontradas = set()
    
    try:
        # 1. Cargar imagen con OpenCV (para recortes)
        img = cv2.imread(imagen_path)
        if img is None: return []
        height, width, _ = img.shape
        
        # 2. Obtener BYTES SEGUROS (Comprimidos si es necesario)
        image_bytes = preparar_imagen_aws(imagen_path)
            
        # 3. Detectar caras en la imagen (usando los bytes seguros)
        response_detect = rekog.detect_faces(Image={'Bytes': image_bytes})
        
        if not response_detect['FaceDetails']: return []

        # 4. Procesar cada cara
        for faceDetail in response_detect['FaceDetails']:
            bbox = faceDetail['BoundingBox']
            x = int(bbox['Left'] * width)
            y = int(bbox['Top'] * height)
            w = int(bbox['Width'] * width)
            h = int(bbox['Height'] * height)
            
            x, y = max(0, x), max(0, y)
            w, h = min(width - x, w), min(height - y, h)
            face_crop = img[y:y+h, x:x+w]
            if face_crop.size == 0: continue

            _, buffer = cv2.imencode('.jpg', face_crop)
            crop_bytes = buffer.tobytes()
            
            try:
                # AQU√ç EST√Å EL CAMBIO CLAVE: MaxFaces=5 (Antes era 1)
                # Esto permite que si dos usuarios tienen la misma cara, AWS devuelva a ambos.
                search_res = rekog.search_faces_by_image(
                    CollectionId=COLLECTION_ID,
                    Image={'Bytes': crop_bytes},
                    MaxFaces=5, 
                    FaceMatchThreshold=confidence_threshold
                )
                
                # Ahora iteramos sobre TODAS las coincidencias encontradas para esa cara
                for match in search_res['FaceMatches']:
                    ced = match['Face'].get('ExternalImageId')
                    if ced: cedulas_encontradas.add(ced)
                    
            except: continue 

        return list(cedulas_encontradas)
    except Exception as e:
        print(f"Error IA Rostros: {e}")
        return []
    

# --- REEMPLAZA TU FUNCI√ìN 'buscar_estudiantes_por_texto' POR ESTA VERSI√ìN CON DEBUG VISUAL ---

def buscar_estudiantes_por_texto(imagen_path: str, conn):
    if not rekog: return [], []
    cedulas_encontradas = set()
    texto_leido_debug = []
    
    try:
        # 1. Obtener BYTES SEGUROS (Comprimidos < 5MB)
        image_bytes = preparar_imagen_aws(imagen_path)
            
        # 2. Detectar texto
        response = rekog.detect_text(Image={'Bytes': image_bytes})
        
        palabras_sueltas = []
        lineas_completas = []
        
        for t in response.get('TextDetections', []):
            txt = t['DetectedText'].lower()
            if t['Type'] == 'WORD':
                # Filtramos palabras basura muy cortas (de 1 o 2 letras) que causan ruido
                if len(txt) > 2: 
                    palabras_sueltas.append(txt)
                    texto_leido_debug.append(txt)
            elif t['Type'] == 'LINE':
                lineas_completas.append(txt)
        
        if not palabras_sueltas: return [], ["(Imagen ilegible)"]

        # 3. L√≥gica de B√∫squeda
        estudiantes = conn.execute("SELECT Nombre, Apellido, CI FROM Usuarios WHERE Tipo=1").fetchall()
        
        for est in estudiantes:
            # Partes del nombre: "Taylor", "Swift"
            partes = est['Nombre'].lower().split() + est['Apellido'].lower().split()
            # Filtramos conectores como "de", "la"
            piezas_validas = {p for p in partes if len(p) > 2}
            
            # --- ESTRATEGIA A: L√çNEAS (Contexto exacto) ---
            # Si la l√≠nea dice literalmente "award to karlos ayala", es un match seguro
            match_linea = False
            nombre_corto = f"{est['Nombre'].split()[0]} {est['Apellido'].split()[0]}".lower()
            
            for linea in lineas_completas:
                # Buscamos la frase dentro de la l√≠nea con tolerancia media (65%)
                s = difflib.SequenceMatcher(None, nombre_corto, linea)
                match = s.find_longest_match(0, len(nombre_corto), 0, len(linea))
                if match.size > 4: # Si coinciden m√°s de 4 letras seguidas en orden
                     if difflib.get_close_matches(nombre_corto, [linea], n=1, cutoff=0.65): 
                        cedulas_encontradas.add(est['CI'])
                        match_linea = True
                        break
            if match_linea: continue

            # --- ESTRATEGIA B: BOLSA DE PALABRAS (Filtro Din√°mico) ---
            coincidencias = 0
            for pieza in piezas_validas:
                # AQU√ç EST√Å EL TRUCO:
                # Palabras cortas (< 5 letras): Filtro DURO (0.85). Evita que 'Smith' se confunda con 'Swift'.
                # Palabras largas (>= 5 letras): Filtro SUAVE (0.60). Permite leer 'Karlos' en g√≥tico ('Rarlos').
                umbral = 0.85 if len(pieza) < 5 else 0.60
                
                if difflib.get_close_matches(pieza, palabras_sueltas, n=1, cutoff=umbral):
                    coincidencias += 1
            
            # Reglas de Aprobaci√≥n
            if coincidencias >= 2:
                cedulas_encontradas.add(est['CI'])
            elif len(piezas_validas) == 2 and coincidencias == 2:
                cedulas_encontradas.add(est['CI'])

    except Exception as e:
        print(f"‚ö†Ô∏è Error OCR: {e}")
        return [], [f"Error t√©cnico: {str(e)}"]
        
    return list(cedulas_encontradas), texto_leido_debug

def coincidencia_difusa(partes_buscadas, palabras_en_imagen, umbral):
    """
    Verifica si TODAS las 'partes_buscadas' est√°n presentes en 'palabras_en_imagen'
    con cierta tolerancia a errores (umbral).
    """
    aciertos = 0
    # Usamos una copia para no afectar b√∫squedas de otros estudiantes
    pool = palabras_en_imagen.copy()
    
    for parte in partes_buscadas:
        # Busca la palabra m√°s parecida en la 'bolsa' de palabras de la imagen
        matches = difflib.get_close_matches(parte, pool, n=1, cutoff=umbral)
        if matches:
            aciertos += 1
            # Opcional: pool.remove(matches[0]) si quisieras evitar repetir palabras
            
    # √âxito si encontramos TODAS las partes (Ej: Encontr√≥ "Juan" Y encontr√≥ "Perez")
    return aciertos == len(partes_buscadas)

# Funci√≥n auxiliar por si no la tienes
def calcular_hash(file_path):
    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()
    
def calcular_estadisticas_reales() -> dict:
    """Calcula estad√≠sticas REALES filtrando SOLO ESTUDIANTES (Ignora Admins)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # 1. Contar usuarios activos (Estudiantes Tipo 1 activos)
        c.execute("SELECT COUNT(*) as total FROM Usuarios WHERE Tipo = 1 AND Activo = 1")
        fila_usuarios = c.fetchone()
        usuarios_activos = fila_usuarios['total'] if fila_usuarios else 0
        
        # 2. Contar evidencias (SOLO DE ESTUDIANTES - JOIN CON USUARIOS)
        # Esto excluye autom√°ticamente las fotos subidas al perfil del Admin
        c.execute("""
            SELECT COUNT(e.id) as total 
            FROM Evidencias e
            JOIN Usuarios u ON e.CI_Estudiante = u.CI
            WHERE u.Tipo = 1
        """)
        fila_evidencias = c.fetchone()
        total_evidencias = fila_evidencias['total'] if fila_evidencias else 0
        
        # 3. Sumar peso (SOLO DE ESTUDIANTES)
        c.execute("""
            SELECT SUM(e.Tamanio_KB) as peso_total 
            FROM Evidencias e
            JOIN Usuarios u ON e.CI_Estudiante = u.CI
            WHERE u.Tipo = 1
        """)
        fila_peso = c.fetchone()
        resultado_kb = fila_peso['peso_total'] if fila_peso and fila_peso['peso_total'] else 0
        
        # L√≥gica de estimaci√≥n
        total_kb = resultado_kb
        nota_almacenamiento = "Calculado exacto (Solo Estudiantes)"
        
        # Correcci√≥n para cuando hay archivos pero pesan 0
        if total_kb == 0 and total_evidencias > 0:
            total_kb = total_evidencias * 2500 

        tamanio_total_mb = total_kb / 1024
        
        # Costos (Basados solo en consumo de estudiantes)
        costo_rekognition = (total_evidencias / 1000) * 1.0
        costo_almacenamiento = (tamanio_total_mb / 1024) * 0.023
        
        # 4. Solicitudes pendientes
        c.execute("SELECT COUNT(*) as total FROM Solicitudes WHERE Estado = 'PENDIENTE'")
        fila_solicitudes = c.fetchone()
        solicitudes_pendientes = fila_solicitudes['total'] if fila_solicitudes else 0
        
        conn.close()
        
        return {
            "usuarios_activos": usuarios_activos,
            "total_evidencias": total_evidencias,
            "almacenamiento_mb": round(tamanio_total_mb, 2),
            "almacenamiento_gb": round(tamanio_total_mb / 1024, 4),
            "costo_estimado_usd": {
                "rekognition": round(costo_rekognition, 2),
                "almacenamiento": round(costo_almacenamiento, 4),
                "total": round(costo_rekognition + costo_almacenamiento, 2)
            },
            "solicitudes_pendientes": solicitudes_pendientes,
            "nota": nota_almacenamiento
        }
    except Exception as e:
        print(f"Error estadisticas: {e}")
        return {
            "usuarios_activos": 0, "total_evidencias": 0, 
            "almacenamiento_mb": 0, "almacenamiento_gb": 0,
            "solicitudes_pendientes": 0
        }

# =========================================================================
# 4. CONFIGURACI√ìN FASTAPI
# =========================================================================
app = FastAPI(title="Sistema Educativo Despertar", version="7.0")

@app.on_event("startup")
async def al_iniciar_sistema():
    """Este c√≥digo se ejecuta AUTOM√ÅTICAMENTE cuando Railway enciende el servidor"""
    print("‚ö° EVENTO DE INICIO DETECTADO: Ejecutando protocolos de mantenimiento...")
    
    # 1. Ejecutar limpieza de duplicados (Calcula hashes faltantes y borra copias)
    # Ejecutamos en un hilo aparte para no bloquear el arranque si son muchos archivos
    import threading
    hilo_limpieza = threading.Thread(target=limpieza_duplicados_startup)
    hilo_limpieza.start()

# Configuraci√≥n CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://proyecto-grado-karlos.vercel.app",  # Tu frontend
        "http://localhost:5500",
        "*" # Opcional: permite todos para pruebas
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =========================================================================
# 5. ENDPOINTS PRINCIPALES
# =========================================================================

@app.get("/")
def home():
    """Endpoint ra√≠z del sistema"""
    return {
        "status": "online", 
        "backend": "Sistema Educativo Despertar V7.0",
        "cors_enabled": True,
        "zona_horaria": "America/Guayaquil (UTC-5)",
        "timestamp": ahora_ecuador().isoformat()
    }

@app.get("/health")
async def health_check():
    """Verifica salud del sistema"""
    try:
        conn = get_db_connection()
        conn.execute("SELECT 1")
        
        # Verificar tablas principales
        c = conn.cursor()
        c.execute("SELECT COUNT(*) as count FROM Usuarios")
        usuarios = c.fetchone()['count']
        
        c.execute("SELECT COUNT(*) as count FROM Evidencias")
        evidencias = c.fetchone()['count']
        
        conn.close()
        
        return JSONResponse(content={
            "status": "healthy",
            "timestamp": ahora_ecuador().isoformat(),
            "database": "connected",
            "estadisticas": {
                "usuarios": usuarios,
                "evidencias": evidencias
            },
            "aws_rekognition": "available" if rekog else "unavailable",
            "s3_storage": "available" if s3_client else "unavailable"
        })
    except Exception as e:
        return JSONResponse(content={
            "status": "unhealthy",
            "error": str(e)
        })

# =========================================================================
# 6. ENDPOINTS DE AUTENTICACI√ìN
# =========================================================================

@app.post("/iniciar_sesion")
async def iniciar_sesion(request: Request, cedula: str = Form(...), contrasena: str = Form(...)):
    """Versi√≥n CORREGIDA: Verifica contrase√±a Y estado activo"""
    try:
        conn = get_db_connection()
        # Aseguramos que el cursor devuelva un diccionario para buscar por nombre
        c = conn.cursor(cursor_factory=RealDictCursor) 
        
        c.execute("SELECT * FROM Usuarios WHERE TRIM(CI) = %s", (cedula.strip(),))
        user = c.fetchone()
        
        # 1. Verificar si el usuario existe
        if not user:
            conn.close()
            return JSONResponse({"autenticado": False, "mensaje": "Usuario no encontrado."})

        # 2. Verificar Contrase√±a (buscando 'password' o 'Password')
        pass_db = user.get("password") or user.get("Password")
        if pass_db != contrasena.strip():
            conn.close()
            return JSONResponse({"autenticado": False, "mensaje": "Contrase√±a incorrecta."})
            
        # 3. VERIFICACI√ìN DE ESTADO (¬°ESTO FALTABA!)
        # Buscamos 'activo', 'Activo' o asumimos 1 si no existe la columna
        estado = user.get("activo") if user.get("activo") is not None else user.get("Activo")
        
        if estado is not None and int(estado) == 0:
            conn.close()
            return JSONResponse({"autenticado": False, "mensaje": "Tu cuenta ha sido DESACTIVADA por administraci√≥n."})

        # Si pasa todo, preparamos los datos
        datos_usuario = {
            "id": user.get("id") or user.get("ID"),
            "nombre": user.get("nombre") or user.get("Nombre"),
            "apellido": user.get("apellido") or user.get("Apellido"),
            "cedula": user.get("ci") or user.get("CI"),
            "tipo": user.get("tipo") or user.get("Tipo"),
            "url_foto": user.get("foto") or user.get("Foto") or "",
            "email": user.get("email") or user.get("Email") or "",
            "tutorial_visto": bool(user.get("tutorialvisto") or user.get("TutorialVisto", 0))
        }
        
        conn.close()
        return JSONResponse({"autenticado": True, "mensaje": "Bienvenido", "datos": datos_usuario})
        
    except Exception as e:
        print(f"Error login: {e}")
        return JSONResponse({"autenticado": False, "mensaje": f"Error del servidor: {str(e)}"})
    
# =========================================================================
# 7. ENDPOINTS DE GESTI√ìN DE USUARIOS
# =========================================================================

@app.post("/registrar_usuario")
async def registrar_usuario(
    nombre: str = Form(...),
    apellido: str = Form(...),
    cedula: str = Form(...),
    contrasena: str = Form(...),
    tipo_usuario: int = Form(...),
    email: Optional[str] = Form(None),
    telefono: Optional[str] = Form(None),
    foto: UploadFile = File(...)
):
    """Registra un nuevo usuario con zona horaria Ecuador"""
    try:
        cedula = cedula.strip()
        contrasena = contrasena.strip()
        
        # Validaciones b√°sicas
        if not cedula or not contrasena:
            return JSONResponse(content={
                "error": "La c√©dula y contrase√±a son requeridas"
            })
        
        conn = get_db_connection()
        c = conn.cursor()
        
        # Verificar si usuario ya existe
        c.execute("SELECT CI FROM Usuarios WHERE CI=%s", (cedula,))
        if c.fetchone():
            conn.close()
            return JSONResponse(content={
                "error": "Usuario ya existe en el sistema"
            })
        
        # Manejar archivo de foto
        temp_dir = tempfile.mkdtemp()
        foto_path = os.path.join(temp_dir, foto.filename)
        
        with open(foto_path, "wb") as f:
            shutil.copyfileobj(foto.file, f)
        
        # Subir a almacenamiento
        nombre_nube = f"perfiles/{cedula}_{int(ahora_ecuador().timestamp())}_{foto.filename}"
        url_foto = ""
        
        if s3_client:
            try:
                s3_client.upload_file(
                    foto_path, 
                    BUCKET_NAME, 
                    nombre_nube,
                    ExtraArgs={'ACL': 'public-read'}
                )
                url_foto = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{nombre_nube}"
                print(f"‚úÖ Foto subida a S3: {url_foto}")
            except Exception as e:
                print(f"‚ö†Ô∏è Error subiendo a S3: {e}")
                url_foto = f"/local/perfiles/{foto.filename}"
        else:
            url_foto = f"/local/perfiles/{foto.filename}"
        
        # Insertar usuario con fecha de Ecuador
        fecha_registro = ahora_ecuador()
        
        # üëá CAMBIO CLAVE: Convertimos la fecha a texto simple para evitar errores
        fecha_str = fecha_registro.strftime("%Y-%m-%d %H:%M:%S") 
        
        c.execute("""
            INSERT INTO Usuarios 
            (Nombre, Apellido, CI, Password, Tipo, Foto, Activo, Email, Telefono, Fecha_Registro)
            VALUES (%s,%s,%s,%s,%s,%s,1,%s,%s,%s)
        """, (
            nombre.strip(),
            apellido.strip(),
            cedula,
            contrasena,
            tipo_usuario,
            url_foto,
            email,
            telefono,
            fecha_str  # <--- Usamos la versi√≥n texto, no el objeto fecha
        ))
        
        # Si es estudiante, agregar a colecci√≥n de rostros AWS
        if tipo_usuario == 1 and rekog:
            try:
                with open(foto_path, 'rb') as image_file:
                    image_bytes = image_file.read()
                
                rekog.index_faces(
                    CollectionId=COLLECTION_ID,
                    Image={'Bytes': image_bytes},
                    ExternalImageId=cedula,
                    MaxFaces=1,
                    QualityFilter='AUTO'
                )
                print(f"‚úÖ Rostro indexado en AWS para estudiante {cedula}")
            except Exception as e:
                print(f"‚ö†Ô∏è Error indexando rostro en AWS: {e}")
        
        conn.commit()
        conn.close()
        
        # Limpiar archivos temporales
        shutil.rmtree(temp_dir)
        
        # Registrar auditor√≠a
        registrar_auditoria("REGISTRO_USUARIO", f"Usuario {cedula} registrado")
        
        return JSONResponse(content={
            "mensaje": "Usuario registrado exitosamente",
            "url_foto": url_foto,
            "cedula": cedula,
            "fecha_registro": fecha_registro.isoformat()
        })
        
    except Exception as e:
        print(f"‚ùå Error en registrar_usuario: {e}")
        return JSONResponse(content={"error": str(e)})

@app.post("/buscar_estudiante")
async def buscar_estudiante(cedula: str = Form(...)):
    """Busca datos de un estudiante (Compatible Postgres)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # 1. Buscar usuario
        c.execute("SELECT * FROM Usuarios WHERE CI = %s", (cedula,))
        user = c.fetchone()
        
        if not user:
            conn.close()
            return JSONResponse({"encontrado": False, "mensaje": "Estudiante no encontrado"})
            
        # 2. Obtener galer√≠a (Adaptando claves)
        try:
            c.execute("""
                SELECT id, Url_Archivo as url, Tipo_Archivo as tipo, Fecha, Estado 
                FROM Evidencias 
                WHERE CI_Estudiante = %s AND Estado = 1 
                ORDER BY Fecha DESC
            """, (cedula,))
            # Convertimos filas a dict, Postgres ya devuelve 'url', 'tipo' en min√∫scula por el alias
            evs = [dict(r) for r in c.fetchall()]
        except Exception as e:
            print(f"Error obteniendo galer√≠a: {e}")
            evs = []

        conn.close()
        
        # 3. Preparar datos de respuesta (Claves en min√∫scula)
        datos_usuario = {
            "id": user.get("id") or user.get("ID"),
            "nombre": user.get("nombre") or user.get("Nombre"),
            "apellido": user.get("apellido") or user.get("Apellido"),
            "cedula": user.get("ci") or user.get("CI"),
            "tipo": user.get("tipo") or user.get("Tipo"),
            "url_foto": user.get("foto") or user.get("Foto") or "",
            "email": user.get("email") or user.get("Email") or "",
            "tutorial_visto": bool(user.get("tutorialvisto") or user.get("TutorialVisto", 0)),
            "galeria": evs
        }
            
        return JSONResponse({
            "encontrado": True,
            "datos": datos_usuario
        })
        
    except Exception as e:
        print(f"Error en buscar_estudiante: {e}")
        return JSONResponse({"encontrado": False, "mensaje": str(e)})
    
@app.post("/cambiar_estado_usuario")
async def cambiar_estado_usuario(datos: EstadoUsuarioRequest):
    """Activa/desactiva un usuario (Blindado contra errores de may√∫sculas)"""
    try:
        conn = get_db_connection()
        # Usamos RealDictCursor
        c = conn.cursor(cursor_factory=RealDictCursor) 
        
        fecha_desactivacion = ahora_ecuador() if datos.activo == 0 else None
        
        # 1. Actualizamos el estado
        c.execute("""
            UPDATE Usuarios 
            SET Activo = %s, Fecha_Desactivacion = %s
            WHERE CI = %s
        """, (datos.activo, fecha_desactivacion, datos.cedula))
        
        conn.commit()
        
        # 2. Obtenemos datos para el reporte (usando .get para evitar error 500)
        c.execute("SELECT Nombre, Apellido FROM Usuarios WHERE CI = %s", (datos.cedula,))
        user = c.fetchone()
        
        conn.close()
        
        # Validaci√≥n segura de nombres
        nombre = "Usuario"
        apellido = ""
        if user:
            nombre = user.get('Nombre') or user.get('nombre') or "Usuario"
            apellido = user.get('Apellido') or user.get('apellido') or ""
        
        estado_texto = "desactivada" if datos.activo == 0 else "activada"
        registrar_auditoria(
            "CAMBIO_ESTADO_USUARIO",
            f"Usuario {datos.cedula} ({nombre} {apellido}) {estado_texto}"
        )
        
        return JSONResponse(content={
            "mensaje": f"Estado del usuario actualizado a {'activo' if datos.activo == 1 else 'inactivo'}",
            "fecha_cambio": ahora_ecuador().isoformat()
        })
        
    except Exception as e:
        print(f"‚ùå Error cambiando estado: {e}")
        return JSONResponse(content={"error": str(e)}, status_code=500)


@app.delete("/eliminar_usuario/{cedula}")
async def eliminar_usuario(cedula: str):
    """Elimina usuario y todos sus datos (Blindado contra errores de may√∫sculas)"""
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. PRIMERO: Obtener y borrar evidencias asociadas (Nube + BD)
        c.execute("SELECT Url_Archivo FROM Evidencias WHERE CI_Estudiante = %s", (cedula,))
        evidencias = c.fetchall()
        
        if s3_client and BUCKET_NAME:
            for ev in evidencias:
                # üõ°Ô∏è CORRECCI√ìN: Buscamos URL con seguridad (May√∫s/Min√∫s)
                url = ev.get('Url_Archivo') or ev.get('url_archivo')
                
                if url and "backblazeb2.com" in url:
                    try:
                        partes = url.split(f"/file/{BUCKET_NAME}/")
                        if len(partes) > 1:
                            s3_client.delete_object(Bucket=BUCKET_NAME, Key=partes[1])
                    except Exception as e:
                        print(f"‚ö†Ô∏è No se pudo borrar archivo B2: {e}")

        # Borrar registros de evidencias
        c.execute("DELETE FROM Evidencias WHERE CI_Estudiante = %s", (cedula,))
        
        # 2. SEGUNDO: Obtener y borrar foto de perfil (Nube)
        c.execute("SELECT Foto FROM Usuarios WHERE CI = %s", (cedula,))
        usuario = c.fetchone()
        
        # üõ°Ô∏è CORRECCI√ìN: Buscamos Foto con seguridad
        if usuario:
            url_foto = usuario.get('Foto') or usuario.get('foto')
            
            if url_foto and s3_client and BUCKET_NAME and "backblazeb2.com" in url_foto:
                try:
                    partes = url_foto.split(f"/file/{BUCKET_NAME}/")
                    if len(partes) > 1:
                        s3_client.delete_object(Bucket=BUCKET_NAME, Key=partes[1])
                except Exception as e:
                     print(f"‚ö†Ô∏è No se pudo borrar foto perfil B2: {e}")

        # 3. TERCERO: Borrar el usuario
        c.execute("DELETE FROM Usuarios WHERE CI = %s", (cedula,))
        
        conn.commit()
        conn.close()
        
        return JSONResponse({"mensaje": "Usuario y todos sus datos eliminados correctamente"})
        
    except Exception as e:
        print(f"‚ùå Error eliminando usuario completo: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
# =========================================================================
# 8. ENDPOINTS DE EVIDENCIAS
# =========================================================================

def garantizar_limite_storage(ruta_archivo, limite_mb=1000):
    """
    Si el archivo supera el limite_mb (ej: 1GB), lo comprime para ahorrar espacio.
    Si no lo supera, lo deja intacto (Calidad Original).
    """
    try:
        peso_actual_mb = os.path.getsize(ruta_archivo) / (1024 * 1024)
        
        # CASO 1: El archivo est√° dentro del l√≠mite (Ej: 500MB) -> NO TOCAR
        if peso_actual_mb <= limite_mb:
            return ruta_archivo # Devolvemos la ruta original
            
        # CASO 2: El archivo es gigante (Ej: 2GB) -> COMPRIMIR
        print(f"‚ö†Ô∏è Archivo gigante ({peso_actual_mb:.2f} MB). Comprimiendo para cumplir cuota de 1GB...")
        
        # Nombre para el archivo comprimido
        dir_name = os.path.dirname(ruta_archivo)
        base_name = os.path.basename(ruta_archivo)
        ruta_comprimida = os.path.join(dir_name, f"compressed_{base_name}")
        
        # Detectar si es VIDEO
        ext = os.path.splitext(ruta_archivo)[1].lower()
        if ext in ['.mp4', '.avi', '.mov', '.mkv']:
            # Usamos OpenCV para reducir resoluci√≥n y bitrate
            cap = cv2.VideoCapture(ruta_archivo)
            
            # Calculamos nueva resoluci√≥n (HD 720p suele ser suficiente y ligero)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            # Si es 4K, lo bajamos a 720p. Si es menor, lo bajamos un 30%
            scale = 0.5 if width > 1920 else 0.7
            new_w, new_h = int(width * scale), int(height * scale)
            
            # Configurar el escritor de video
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(ruta_comprimida, fourcc, 24, (new_w, new_h))
            
            while True:
                ret, frame = cap.read()
                if not ret: break
                # Redimensionar frame
                frame_b = cv2.resize(frame, (new_w, new_h))
                out.write(frame_b)
                
            cap.release()
            out.release()
            
            # Reemplazar archivo original con el comprimido
            if os.path.exists(ruta_comprimida):
                shutil.move(ruta_comprimida, ruta_archivo) # Sobrescribimos el original
                nuevo_peso = os.path.getsize(ruta_archivo) / (1024 * 1024)
                print(f"‚úÖ Compresi√≥n exitosa. Nuevo peso: {nuevo_peso:.2f} MB")
                return ruta_archivo
                
    except Exception as e:
        print(f"‚ö†Ô∏è Error intentando comprimir video storage: {e}")
    
    # Si algo falla o no es video, devolvemos el original
    return ruta_archivo

@app.post("/subir_evidencia_ia")
async def subir_evidencia_ia(archivo: UploadFile = File(...)):
    temp_dir = None
    try:
        # 1. Guardar archivo temporalmente para an√°lisis
        temp_dir = tempfile.mkdtemp()
        path = os.path.join(temp_dir, archivo.filename)
        with open(path, "wb") as f: shutil.copyfileobj(archivo.file, f)
        
        # 2. Calcular Huella Digital (Hash)
        file_hash = calcular_hash(path)
        
        # 3. Detectar Tipo de Archivo
        ext = os.path.splitext(archivo.filename)[1].lower()
        es_imagen = ext in ['.jpg', '.jpeg', '.png', '.bmp', '.webp', '.avif']
        es_video = ext in ['.mp4', '.avi', '.mov', '.mkv']
        tipo_archivo = "video" if es_video else ("imagen" if es_imagen else "documento")
        
        # 4. EJECUTAR IA (Detectar a TODOS los que aparecen)
        cedulas_detectadas = set() 
        texto_debug = []
        
        if rekog:
            if es_imagen:
                # Nota: identificar_varios_rostros_aws ya est√° configurado con MaxFaces=5
                rostros = identificar_varios_rostros_aws(path)
                cedulas_detectadas.update(rostros)
                
                textos_ceds, debug_ocr = buscar_estudiantes_por_texto(path, get_db_connection())
                cedulas_detectadas.update(textos_ceds)
                if debug_ocr: texto_debug = debug_ocr
                
            elif es_video:
                cap = cv2.VideoCapture(path)
                fps = cap.get(cv2.CAP_PROP_FPS) or 24
                
                # --- CAMBIO 1: MENOS CARGA DE PROCESAMIENTO ---
                # Antes analiz√°bamos cada 2 segundos. Ahora cada 4 segundos para ahorrar RAM.
                intervalo = int(fps * 4) 
                
                curr = 0
                max_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                
                # --- CAMBIO 2: L√çMITE DE SEGURIDAD ---
                # Si el video es muy largo, solo analizamos los primeros 10 an√°lisis para no saturar
                contador_analisis = 0
                MAX_ANALISIS_POR_VIDEO = 8 
                
                while curr < max_frames and contador_analisis < MAX_ANALISIS_POR_VIDEO:
                    cap.set(cv2.CAP_PROP_POS_FRAMES, curr)
                    ret, frame = cap.read()
                    if not ret: break
                    
                    # Redimensionar frame si es muy grande (4K -> HD) para ahorrar memoria
                    if frame.shape[1] > 1280:
                        scale = 1280 / frame.shape[1]
                        frame = cv2.resize(frame, None, fx=scale, fy=scale)

                    frame_path = os.path.join(temp_dir, f"frame_{curr}.jpg")
                    cv2.imwrite(frame_path, frame)
                    
                    rostros = identificar_varios_rostros_aws(frame_path)
                    cedulas_detectadas.update(rostros)
                    
                    # Limpiamos el frame del disco inmediatamente
                    try: os.remove(frame_path) 
                    except: pass
                    
                    curr += intervalo
                    contador_analisis += 1
                    
                    # Si ya encontramos gente, no necesitamos seguir machacando el servidor
                    if len(cedulas_detectadas) >= 5: break
                
                cap.release()

        # 5. VERIFICAR SI EL ARCHIVO YA EXISTE F√çSICAMENTE
        conn = get_db_connection()
        archivo_existente = conn.execute("SELECT Url_Archivo, Tamanio_KB FROM Evidencias WHERE Hash = %s LIMIT 1", (file_hash,)).fetchone()
        
        url_final = ""
        tamanio_kb = 0
        
        if archivo_existente:
            url_final = archivo_existente['Url_Archivo']
            tamanio_kb = archivo_existente['Tamanio_KB']
            print(f"‚ôªÔ∏è Archivo existente detectado. Reusando URL: {url_final}")
        else:
            path = garantizar_limite_storage(path, limite_mb=1000)
            tamanio_kb = os.path.getsize(path) / 1024
            
            url_final = f"/local/{archivo.filename}"
            if s3_client:
                try:
                    nube = f"evidencias/{int(ahora_ecuador().timestamp())}_{archivo.filename}"
                    ct = 'video/mp4' if es_video else archivo.content_type
                    s3_client.upload_file(path, BUCKET_NAME, nube, ExtraArgs={'ACL':'public-read', 'ContentType': ct})
                    url_final = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{nube}"
                except: pass

        # 6. ASIGNACI√ìN INTELIGENTE (FILTRANDO ADMINS)
        asignados_nuevos = []
        ya_lo_tenian = []
        
        if cedulas_detectadas:
            for ced in cedulas_detectadas:
                # Paso A: Traemos tambi√©n el 'Tipo' del usuario
                u = conn.execute("SELECT Nombre, Apellido, Tipo FROM Usuarios WHERE CI=%s", (ced,)).fetchone()
                
                # --- FILTRO DE SEGURIDAD: SOLO ESTUDIANTES (Tipo 1) ---
                if u and u['Tipo'] == 1:
                    nombre_completo = f"{u['Nombre']} {u['Apellido']}"
                    
                    # Paso B: ¬øYa lo tiene%s
                    ya_existe = conn.execute("""
                        SELECT id FROM Evidencias 
                        WHERE CI_Estudiante = %s AND Hash = %s
                    """, (ced, file_hash)).fetchone()
                    
                    if ya_existe:
                        ya_lo_tenian.append(nombre_completo)
                    else:
                        conn.execute("""
                            INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente) 
                            VALUES (%s, %s, %s, 1, %s, %s, 1)
                        """, (ced, url_final, file_hash, tipo_archivo, tamanio_kb))
                        asignados_nuevos.append(nombre_completo)
                
                # Si u['Tipo'] == 0 (Admin), simplemente no hacemos nada y el bucle contin√∫a.

            # Generar Mensaje
            if asignados_nuevos:
                msg = f"‚úÖ Asignado a: {', '.join(asignados_nuevos)}."
                status = "exito"
                if ya_lo_tenian:
                    msg += f" (Omitidos: {', '.join(ya_lo_tenian)})"
            elif ya_lo_tenian:
                msg = f"‚ö†Ô∏è Evidencia ya existente para: {', '.join(ya_lo_tenian)}."
                status = "alerta"
            else:
                # Detect√≥ rostros pero eran Admins o no registrados
                check_pendiente = conn.execute("SELECT id FROM Evidencias WHERE Hash = %s AND CI_Estudiante = 'PENDIENTE'", (file_hash,)).fetchone()
                if not check_pendiente:
                    conn.execute("""
                        INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente) 
                        VALUES ('PENDIENTE', %s, %s, 1, %s, %s, 0)
                    """, (url_final, file_hash, tipo_archivo, tamanio_kb))
                msg = "‚ö†Ô∏è Rostros detectados pero no son estudiantes activos."
                status = "alerta"

        else:
            # 7. NADIE DETECTADO
            check_pendiente = conn.execute("SELECT id FROM Evidencias WHERE Hash = %s", (file_hash,)).fetchone()
            
            if check_pendiente:
                status = "error"
                msg = "‚ö†Ô∏è DUPLICADO: Este archivo ya existe y la IA no encontr√≥ nuevos estudiantes."
            else:
                conn.execute("""
                    INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente) 
                    VALUES ('PENDIENTE', %s, %s, 1, %s, %s, 0)
                """, (url_final, file_hash, tipo_archivo, tamanio_kb))
                
                muestras_texto = ", ".join(texto_debug[:5]) if texto_debug else "Nada legible"
                msg = f"‚ö†Ô∏è No se identific√≥ alumno. Guardado como pendiente. (Texto: {muestras_texto}...)"
                status = "alerta"

        conn.commit()
        conn.close()
        shutil.rmtree(temp_dir)
        return JSONResponse({"status": status, "mensaje": msg})

    except Exception as e:
        if temp_dir and os.path.exists(temp_dir): shutil.rmtree(temp_dir)
        return JSONResponse({"status": "error", "mensaje": str(e)})
    
@app.post("/subir_manual")
async def subir_manual(
    cedulas: str = Form(...), 
    archivo: UploadFile = File(...), 
    comentario: Optional[str] = Form(None)
):
    try:
        lista_cedulas = [c.strip() for c in cedulas.split(",") if c.strip()]
        if not lista_cedulas:
            return JSONResponse(content={"error": "Debe especificar al menos una c√©dula"})
        
        # 1. Guardar temporalmente
        temp_dir = tempfile.mkdtemp()
        path = os.path.join(temp_dir, archivo.filename)
        with open(path, "wb") as f: shutil.copyfileobj(archivo.file, f)

        # --- NUEVO: DETECCI√ìN DE DUPLICADOS ---
        file_hash = calcular_hash(path)
        conn = get_db_connection()
        duplicado = conn.execute("SELECT id FROM Evidencias WHERE Hash = %s", (file_hash,)).fetchone()
        
        if duplicado:
            conn.close()
            shutil.rmtree(temp_dir)
            # Mostramos un error claro en el frontend
            return JSONResponse({"error": "‚ö†Ô∏è ARCHIVO DUPLICADO: Esta evidencia ya fue subida anteriormente."})
        # --------------------------------------
            
        # 2. Subir a la nube
        tamanio_kb = os.path.getsize(path) / 1024
        url_archivo = f"/local/{archivo.filename}"
        
        if s3_client:
            try:
                nombre_nube = f"evidencias/manual_{int(ahora_ecuador().timestamp())}_{archivo.filename}"
                s3_client.upload_file(path, BUCKET_NAME, nombre_nube, ExtraArgs={'ACL': 'public-read'})
                url_archivo = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{nombre_nube}"
            except: pass
            
        c = conn.cursor()
        count = 0
        
        # 3. Guardar en BD (Incluyendo Hash)
        for ced in lista_cedulas:
            if c.execute("SELECT CI FROM Usuarios WHERE CI=%s", (ced,)).fetchone():
                c.execute("""
                    INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                    VALUES (%s, %s, %s, 1, 'documento', %s, 0)
                """, (ced, url_archivo, file_hash, tamanio_kb))
                count += 1
        
        conn.commit()
        conn.close()
        shutil.rmtree(temp_dir)
        
        return JSONResponse({"status": "ok", "mensaje": f"Asignado a {count} estudiantes"})
    except Exception as e:
        return JSONResponse({"error": str(e)})
    
# =========================================================================
# 9. ENDPOINTS DE BACKUP Y MANTENIMIENTO
# =========================================================================

@app.get("/crear_backup")
async def crear_backup():
    """Crea y descarga una copia de seguridad de la base de datos"""
    try:
        # Crear nombre de archivo con fecha de Ecuador
        fecha = ahora_ecuador().strftime("%Y%m%d_%H%M%S")
        backup_filename = f"backup_despertar_{fecha}.db"
        backup_path = os.path.join(tempfile.gettempdir(), backup_filename)
        
        # Copiar base de datos
        shutil.copy2(DB_NAME, backup_path)
        
        # Registrar auditor√≠a
        registrar_auditoria("CREACION_BACKUP", f"Backup creado: {backup_filename}")
        
        # Preparar respuesta para descarga directa
        def iterfile():
            with open(backup_path, "rb") as f:
                yield from f
            
            # Eliminar archivo temporal despu√©s de enviar
            os.remove(backup_path)
        
        return StreamingResponse(
            iterfile(),
            media_type="application/x-sqlite3",
            headers={
                "Content-Disposition": f"attachment; filename={backup_filename}",
                "Content-Type": "application/x-sqlite3"
            }
        )
        
    except Exception as e:
        return JSONResponse(content={"error": str(e)})

@app.get("/descargar_multimedia_zip")
async def descargar_multimedia_zip():
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Obtener TODAS las evidencias
        c.execute("SELECT Url_Archivo FROM Evidencias")
        resultados = c.fetchall()
        conn.close()
        
        if not resultados:
            return JSONResponse({"error": "No hay evidencias en el sistema"}, status_code=404)

        # 2. Crear ZIP en memoria
        zip_buffer = io.BytesIO()
        
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for i, item in enumerate(resultados):
                url = item['Url_Archivo']
                # Limpiamos el nombre para el zip
                nombre_archivo = f"backup_{i+1}_{os.path.basename(url)}"
                
                # Descargar de la Nube (B2/S3)
                if s3_client and BUCKET_NAME and ("backblazeb2.com" in url or "s3" in url):
                    try:
                        # Extraer la clave (path) del archivo en el bucket
                        partes = url.split(f"/file/{BUCKET_NAME}/")
                        if len(partes) > 1:
                            file_key = partes[1]
                            file_obj = s3_client.get_object(Bucket=BUCKET_NAME, Key=file_key)
                            file_content = file_obj['Body'].read()
                            zip_file.writestr(nombre_archivo, file_content)
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error backup archivo {url}: {e}")
                        zip_file.writestr(f"ERROR_{i}.txt", f"Fallo al descargar: {url}")
                
                # Soporte para archivos antiguos (locales) si hubiera
                elif os.path.exists(url):
                    try:
                        zip_file.write(url, nombre_archivo)
                    except:
                        pass

        zip_buffer.seek(0)
        
        # Nombre del ZIP con fecha
        fecha_str = datetime.datetime.now().strftime("%Y%m%d")
        nombre_zip = f"Backup_Multimedia_Completo_{fecha_str}.zip"
        
        return StreamingResponse(
            zip_buffer, 
            media_type="application/zip",
            headers={"Content-Disposition": f"attachment; filename={nombre_zip}"}
        )

    except Exception as e:
        print(f"‚ùå Error backup multimedia: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)

from urllib.parse import urlparse
import re
import os

@app.post("/optimizar_sistema")
async def optimizar_sistema(tipo: str = "full"):
    """
    V5.5 - Mantenimiento Blindado (Soporta may√∫sculas/min√∫sculas en BD)
    """
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        mensaje_resultado = []
        
        # ==========================================
        # 1. ANALIZAR DUPLICADOS
        # ==========================================
        if tipo == "duplicados" or tipo == "full":
            print("üßπ [1/4] Buscando duplicados...")
            c.execute("""
                SELECT Hash, COUNT(*) as cantidad FROM Evidencias 
                WHERE Hash NOT IN ('PENDIENTE', '', 'RECUPERADO') 
                GROUP BY Hash HAVING COUNT(*) > 1
            """)
            grupos = c.fetchall()
            elim_dups = 0
            espacio_kb = 0
            
            for g in grupos:
                # üõ°Ô∏è CORRECCI√ìN: Usamos .get() para leer 'Hash' o 'hash'
                hash_val = g.get('Hash') or g.get('hash')
                
                c.execute("SELECT id, Url_Archivo, Tamanio_KB FROM Evidencias WHERE Hash = %s ORDER BY id ASC", (hash_val,))
                copias = c.fetchall()
                
                # Dejar el original (index 0), borrar el resto
                for copia in copias[1:]:
                    copia_id = copia.get('id')
                    copia_url = copia.get('Url_Archivo') or copia.get('url_archivo')
                    copia_kb = copia.get('Tamanio_KB') or copia.get('tamanio_kb') or 0
                    
                    # Borrar de nube si es archivo diferente
                    if s3_client and BUCKET_NAME in copia_url:
                        try:
                            key = copia_url.split(f"/file/{BUCKET_NAME}/")[1]
                            s3_client.delete_object(Bucket=BUCKET_NAME, Key=key)
                        except: pass
                    
                    c.execute("DELETE FROM Evidencias WHERE id = %s", (copia_id,))
                    elim_dups += 1
                    espacio_kb += copia_kb
            
            if elim_dups > 0:
                mensaje_resultado.append(f"Eliminados {elim_dups} duplicados ({round(espacio_kb/1024, 2)} MB recuperados).")
            elif tipo == "duplicados":
                mensaje_resultado.append("No se encontraron duplicados.")

        # ==========================================
        # 2. LIMPIAR HU√âRFANOS
        # ==========================================
        if tipo == "huerfanos" or tipo == "full":
            print("üëª [2/4] Buscando archivos fantasma...")
            c.execute("SELECT id, Url_Archivo FROM Evidencias")
            todas = c.fetchall()
            elim_huerfanos = 0
            
            for ev in todas:
                url = ev.get('Url_Archivo') or ev.get('url_archivo')
                ev_id = ev.get('id')
                
                existe = True
                if url and "backblazeb2.com" in url and s3_client:
                    try:
                        key = url.split(f"/file/{BUCKET_NAME}/")[1]
                        s3_client.head_object(Bucket=BUCKET_NAME, Key=key)
                    except: existe = False
                elif url and not "http" in url and not os.path.exists(url):
                    existe = False
                
                if not existe:
                    c.execute("DELETE FROM Evidencias WHERE id = %s", (ev_id,))
                    elim_huerfanos += 1
            
            if elim_huerfanos > 0:
                mensaje_resultado.append(f"Eliminados {elim_huerfanos} registros rotos (fantasmas).")
            elif tipo == "huerfanos":
                mensaje_resultado.append("El sistema est√° limpio de archivos rotos.")

        # ==========================================
        # 3. AUTO-REASIGNACI√ìN (SOLO EN MODO FULL)
        # ==========================================
        if tipo == "full":
            print("üîÑ [3/4] Auto-reasignando evidencias perdidas...")
            c.execute("SELECT CI FROM Usuarios")
            cedulas = [u.get('CI') or u.get('ci') for u in c.fetchall()]
            
            c.execute("SELECT id, Url_Archivo, CI_Estudiante FROM Evidencias")
            evidencias = c.fetchall()
            reasignadas = 0
            
            for ev in evidencias:
                url = ev.get('Url_Archivo') or ev.get('url_archivo')
                ev_id = ev.get('id')
                ev_ci = ev.get('CI_Estudiante') or ev.get('ci_estudiante')
                
                for ci in cedulas:
                    if ci in url and len(ci) >= 10:
                        if ev_ci != ci:
                            c.execute("UPDATE Evidencias SET CI_Estudiante = %s WHERE id = %s", (ci, ev_id))
                            reasignadas += 1
                        break
            
            if reasignadas > 0:
                mensaje_resultado.append(f"Reasignadas {reasignadas} evidencias a sus due√±os correctos.")

        # ==========================================
        # 4. LIMPIAR CACH√â
        # ==========================================
        if tipo == "cache" or tipo == "full":
            print("üöÄ [4/4] Compactando base de datos...")
            conn.commit()
            conn.autocommit = True
            with conn.cursor() as c_vac:
                c_vac.execute("VACUUM")
                c_vac.execute("ANALYZE")
            if tipo == "cache":
                mensaje_resultado.append("Base de datos compactada y optimizada.")

        conn.close()
        
        texto_final = " ".join(mensaje_resultado) if mensaje_resultado else "Mantenimiento completado. Todo en orden."
        return JSONResponse({"status": "ok", "mensaje": texto_final})

    except Exception as e:
        print(f"‚ùå Error en mantenimiento: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
        
# =========================================================================
# 10. ENDPOINTS DE ESTAD√çSTICAS Y REPORTES
# =========================================================================

@app.get("/estadisticas_almacenamiento")
async def estadisticas_almacenamiento():
    """Versi√≥n OPTIMIZADA: Carga instant√°nea usando conteo r√°pido"""
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Usuarios Activos (R√°pido)
        c.execute("SELECT COUNT(*) as total FROM Usuarios WHERE Tipo = 1 AND Activo = 1")
        usuarios_activos = c.fetchone()['total']
        
        # 2. Total Evidencias (R√°pido)
        c.execute("SELECT COUNT(*) as total FROM Evidencias")
        total_evidencias = c.fetchone()['total']
        
        # 3. Solicitudes Pendientes (R√°pido)
        c.execute("SELECT COUNT(*) as total FROM Solicitudes WHERE Estado = 'PENDIENTE'")
        solicitudes_pendientes = c.fetchone()['total']
        
        # 4. Almacenamiento (Estimaci√≥n Estad√≠stica para velocidad)
        # Usamos 3.5 MB promedio por archivo para no leer disco/nube uno por uno
        tamanho_promedio_mb = 3.5
        total_mb = total_evidencias * tamanho_promedio_mb
        total_gb = round(total_mb / 1024, 4)
        
        # 5. Costos (C√°lculo matem√°tico simple)
        costo_ia = (total_evidencias / 1000) * 1.0
        costo_storage = (total_gb) * 0.005
        costo_total = round(costo_ia + costo_storage, 2)
        
        conn.close()
        
        # Respuesta con la estructura EXACTA que espera tu frontend
        return JSONResponse(content={
            "usuarios_activos": usuarios_activos,
            "total_evidencias": total_evidencias,
            "almacenamiento_mb": round(total_mb, 2),
            "almacenamiento_gb": total_gb,
            "solicitudes_pendientes": solicitudes_pendientes,
            "costo_estimado_usd": {
                "rekognition": round(costo_ia, 2),
                "almacenamiento": round(costo_storage, 4),
                "total": costo_total
            },
            "nota": "Modo Turbo (Estimado)"
        })
        
    except Exception as e:
        print(f"‚ùå Error dashboard: {e}")
        return JSONResponse(content={"error": str(e)})

@app.get("/datos_graficos_dashboard")
async def datos_graficos_dashboard():
    """Provee datos para gr√°ficos del dashboard (Versi√≥n PostgreSQL)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # 1. Evoluci√≥n de registros por mes (TO_CHAR en lugar de strftime)
        c.execute("""
            SELECT TO_CHAR(Fecha_Registro, 'YYYY-MM') as mes,
                   COUNT(*) as cantidad
            FROM Usuarios 
            WHERE Fecha_Registro IS NOT NULL
            GROUP BY mes
            ORDER BY mes DESC
            LIMIT 12
        """)
        evolucion_usuarios = [dict(row) for row in c.fetchall()]
        
        # 2. Distribuci√≥n de tipos de archivo
        c.execute("""
            SELECT Tipo_Archivo, COUNT(*) as cantidad
            FROM Evidencias
            GROUP BY Tipo_Archivo
        """)
        distribucion_archivos = [dict(row) for row in c.fetchall()]
        
        # 3. Solicitudes por estado
        c.execute("""
            SELECT Estado, COUNT(*) as cantidad
            FROM Solicitudes
            GROUP BY Estado
        """)
        solicitudes_estado = [dict(row) for row in c.fetchall()]
        
        # 4. Top 5 estudiantes
        c.execute("""
            SELECT u.Nombre, u.Apellido, u.CI, COUNT(e.id) as total
            FROM Usuarios u
            LEFT JOIN Evidencias e ON u.CI = e.CI_Estudiante
            WHERE u.Tipo = 1
            GROUP BY u.CI
            ORDER BY total DESC
            LIMIT 5
        """)
        top_estudiantes = [dict(row) for row in c.fetchall()]
        
        # 5. Actividad por hora (TO_CHAR y sintaxis de intervalo Postgres)
        c.execute("""
            SELECT TO_CHAR(Fecha, 'HH24') as hora,
                   COUNT(*) as actividades
            FROM Auditoria
            WHERE Fecha >= NOW() - INTERVAL '7 days'
            GROUP BY hora
            ORDER BY hora
        """)
        actividad_horaria = [dict(row) for row in c.fetchall()]
        
        conn.close()
        
        return JSONResponse(content={
            "evolucion_usuarios": evolucion_usuarios,
            "distribucion_archivos": distribucion_archivos,
            "solicitudes_estado": solicitudes_estado,
            "top_estudiantes": top_estudiantes,
            "actividad_horaria": actividad_horaria,
            "fecha_consulta": ahora_ecuador().isoformat()
        })
        
    except Exception as e:
        return JSONResponse(content={"error": str(e)})

# =========================================================================
# 11. ENDPOINTS DE SOLICITUDES Y GESTI√ìN
# =========================================================================
@app.get("/obtener_solicitudes")
def obtener_solicitudes(limit: int = 100):
    try:
        conn = get_db_connection()
        c = conn.cursor()
        c.execute("SELECT * FROM Solicitudes ORDER BY Fecha DESC LIMIT %s", (limit,))
        solicitudes = c.fetchall()
        conn.close()
        
        # ‚úÖ CORRECCI√ìN M√ÅGICA
        sol_serializables = json.loads(json.dumps(solicitudes, default=str))
        
        return JSONResponse(sol_serializables)
    except Exception as e:
        print(f"‚ùå Error obteniendo solicitudes: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
# =========================================================================
# 1. ENDPOINTS DE SOLICITUDES (LADO ESTUDIANTE) - ¬°ESTO ES LO QUE TE FALTA!
# =========================================================================

@app.post("/solicitar_recuperacion")
async def solicitar_recuperacion(
    cedula: str = Form(...),
    email: str = Form(...),
    mensaje: Optional[str] = Form(None)
):
    """El estudiante pide recuperar contrase√±a desde login"""
    try:
        conn = get_db_connection()
        # Verificar si el usuario existe
        user = conn.execute("SELECT Nombre, Apellido FROM Usuarios WHERE CI=%s", (cedula,)).fetchone()
        if not user:
            conn.close()
            return JSONResponse({"status": "error", "mensaje": "La c√©dula no est√° registrada."})
            
        detalle = f"Solicitud de recuperaci√≥n. Correo contacto: {email}. "
        if mensaje: detalle += f"Mensaje: {mensaje}"
        
        conn.execute("""
            INSERT INTO Solicitudes (Tipo, CI_Solicitante, Email, Detalle, Estado, Fecha)
            VALUES ('RECUPERACION_CONTRASENA', %s, %s, %s, 'PENDIENTE', %s)
        """, (cedula, email, detalle, ahora_ecuador()))
        
        conn.commit()
        conn.close()
        return JSONResponse({"status": "ok", "mensaje": "Solicitud enviada al administrador."})
    except Exception as e:
        return JSONResponse({"status": "error", "mensaje": str(e)})

@app.post("/solicitar_subida")
async def solicitar_subida(cedula: str = Form(...), archivo: UploadFile = File(...)):
    """El estudiante sube un archivo para aprobaci√≥n del admin"""
    try:
        # 1. Guardar temporalmente para subir a la nube
        temp_dir = tempfile.mkdtemp()
        path = os.path.join(temp_dir, archivo.filename)
        with open(path, "wb") as f: shutil.copyfileobj(archivo.file, f)
        
        url_archivo = f"/local/{archivo.filename}"
        if s3_client:
            try:
                # Nombre temporal (propuesta)
                nombre_nube = f"evidencias/propuesta_{int(ahora_ecuador().timestamp())}_{archivo.filename}"
                s3_client.upload_file(path, BUCKET_NAME, nombre_nube, ExtraArgs={'ACL': 'public-read'})
                url_archivo = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{nombre_nube}"
            except: pass
        
        shutil.rmtree(temp_dir)
        
        conn = get_db_connection()
        conn.execute("""
            INSERT INTO Solicitudes (Tipo, CI_Solicitante, Detalle, Evidencia_Reportada_Url, Estado, Fecha)
            VALUES ('SUBIR_EVIDENCIA', %s, 'El estudiante desea agregar esta evidencia.', %s, 'PENDIENTE', %s)
        """, (cedula, url_archivo, ahora_ecuador()))
        
        conn.commit()
        conn.close()
        return JSONResponse({"status": "ok", "mensaje": "Archivo enviado a revisi√≥n."})
    except Exception as e:
        return JSONResponse({"status": "error", "mensaje": str(e)})

@app.post("/reportar_evidencia")
async def reportar_evidencia(cedula: str = Form(...), id_evidencia: int = Form(...), motivo: str = Form(...)):
    """El estudiante reporta 'No soy yo'"""
    try:
        conn = get_db_connection()
        
        # Obtener URL para mostrarla al admin
        ev = conn.execute("SELECT Url_Archivo FROM Evidencias WHERE id=%s", (id_evidencia,)).fetchone()
        url = ev['Url_Archivo'] if ev else ""
        
        conn.execute("""
            INSERT INTO Solicitudes (Tipo, CI_Solicitante, Detalle, Id_Evidencia, Evidencia_Reportada_Url, Estado, Fecha)
            VALUES ('REPORTE_EVIDENCIA', %s, %s, %s, %s, 'PENDIENTE', %s)
        """, (cedula, motivo, id_evidencia, url, ahora_ecuador()))
        
        conn.commit()
        conn.close()
        return JSONResponse({"status": "ok", "mensaje": "Reporte enviado."})
    except Exception as e:
        return JSONResponse({"status": "error", "mensaje": str(e)})

@app.get("/obtener_solicitudes_por_cedula")
async def obtener_solicitudes_por_cedula(cedula: str):
    try:
        conn = get_db_connection()
        rows = conn.execute("SELECT * FROM Solicitudes WHERE CI_Solicitante=%s ORDER BY Fecha DESC", (cedula,)).fetchall()
        conn.close()
        return JSONResponse([dict(r) for r in rows])
    except: return JSONResponse([])

# =========================================================================
# AQUI DEBER√çA SEGUIR TU FUNCI√ìN @app.post("/gestionar_solicitud") ...
# =========================================================================

@app.post("/gestionar_solicitud")
async def gestionar_solicitud(
    background_tasks: BackgroundTasks,  # <--- MAGIA AQU√ç: Permite tareas de fondo
    id_solicitud: int = Form(...),
    accion: str = Form(...), 
    mensaje: str = Form(...), 
    id_admin: str = Form("Admin")
):
    try:
        # 1. Normalizar acci√≥n
        accion_norm = "APROBADA" if accion.lower() in ['aprobar', 'aceptar', 'aprobada'] else "RECHAZADA"
        fecha_resolucion = ahora_ecuador()
        
        conn = get_db_connection()
        
        # 2. Obtener datos
        sol = conn.execute("""
            SELECT s.*, u.Nombre, u.Apellido, u.Email as UserEmail
            FROM Solicitudes s
            LEFT JOIN Usuarios u ON s.CI_Solicitante = u.CI
            WHERE s.id = %s
        """, (id_solicitud,)).fetchone()
        
        if not sol:
            return JSONResponse({"status": "error", "mensaje": "Solicitud no encontrada"})
        
        tipo = sol['Tipo']
        ci_solicitante = sol['CI_Solicitante']
        email_destino = sol['Email'] if sol['Email'] else sol['UserEmail']
        nombre_usuario = f"{sol['Nombre']} {sol['Apellido']}"
        
        # --- L√ìGICA DE ACCIONES ---
        cuerpo_correo = "" # Inicializar variable
        
        if tipo == 'REPORTE_EVIDENCIA':
            id_evidencia = sol['Id_Evidencia']
            if accion_norm == 'APROBADA':
                conn.execute("DELETE FROM Evidencias WHERE id=%s", (id_evidencia,))
                cuerpo_correo = f"Hola {nombre_usuario},\n\nTu reporte ha sido ACEPTADO. La evidencia ha sido eliminada.\n\nAdmin: {mensaje}"
            else:
                cuerpo_correo = f"Hola {nombre_usuario},\n\nTu reporte fue revisado pero decidimos mantener la evidencia.\n\nMotivo: {mensaje}"

        elif tipo == 'SUBIR_EVIDENCIA':
            url_archivo = sol['Evidencia_Reportada_Url']
            if accion_norm == 'APROBADA':
                conn.execute("""
                    INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                    VALUES (%s, %s, 'MANUAL_APROBADO', 1, 'documento', 0, 0)
                """, (ci_solicitante, url_archivo))
                cuerpo_correo = f"Hola {nombre_usuario},\n\nTu solicitud de subida fue APROBADA. Ya est√° en tu perfil.\n\nAdmin: {mensaje}"
            else:
                cuerpo_correo = f"Hola {nombre_usuario},\n\nTu solicitud de subida fue RECHAZADA.\n\nMotivo: {mensaje}"

        elif tipo in ['RECUPERACION_CONTRASENA']:
            asunto = "üîê Tu nueva clave de acceso - U.E. Despertar"
            # Dise√±o profesional: Letras grandes, negras y centrado 
            cuerpo_correo = f"""
            <div style="font-family: sans-serif; text-align: center; border: 1px solid #ddd; padding: 30px; border-radius: 15px; max-width: 500px; margin: auto;">
                <h2 style="color: #333;">Hola {nombre_usuario},</h2>
                <p style="font-size: 1.1em; color: #555;">Se ha procesado tu solicitud de recuperaci√≥n. Tu contrase√±a funcional es:</p>
                
                <div style="background-color: #f9f9f9; padding: 25px; margin: 25px 0; border: 2px dashed #000; display: inline-block; border-radius: 10px;">
                    <span style="font-size: 2.5em; font-weight: bold; color: #000; letter-spacing: 3px;">
                        {mensaje}
                    </span>
                </div>
                
                <p style="color: #d32f2f; font-weight: bold; font-size: 1.1em;">
                    ‚ö†Ô∏è Recordatorio: No olvides guardar tu contrase√±a en un lugar seguro.
                </p>
                <hr style="border: 0; border-top: 1px solid #eee; margin: 20px 0;">
                <p style="font-size: 0.8em; color: #888;">Soporte T√©cnico - Unidad Educativa Particular Despertar</p>
            </div>
            """
            # Enviamos como HTML (True) para que se vea el dise√±o 
            background_tasks.add_task(enviar_correo_real, email_destino, asunto, cuerpo_correo, True)
            
            conn.execute("UPDATE Solicitudes SET Estado=%s, Resuelto_Por=%s, Respuesta=%s, Fecha_Resolucion=%s WHERE id=%s", 
                         (accion_norm, id_admin, mensaje, fecha_resolucion, id_solicitud))
            conn.commit()
            conn.close()
            return JSONResponse({"status": "ok", "mensaje": "Correo enviado con formato profesional."})
        
        else:
            cuerpo_correo = f"Hola {nombre_usuario},\n\nTu solicitud ha sido procesada: {mensaje}"

        # 3. ACTUALIZAR BD
        conn.execute("""
            UPDATE Solicitudes 
            SET Estado=%s, Resuelto_Por=%s, Respuesta=%s, Fecha_Resolucion=%s
            WHERE id=%s
        """, (accion_norm, id_admin, mensaje, fecha_resolucion, id_solicitud))
        
        conn.commit()
        conn.close()
        
        # 4. ENVIAR CORREO EN SEGUNDO PLANO (AQU√ç EST√Å LA VELOCIDAD)
        if email_destino:
            asunto = f"Respuesta a Solicitud: {tipo.replace('_', ' ')}"
            # IMPORTANTE: Que los nombres coincidan con los de enviar_correo_real
            background_tasks.add_task(enviar_correo_real, email_destino, asunto, cuerpo_correo)
        
        return JSONResponse({
            "status": "ok", 
            "mensaje": "Acci√≥n procesada correctamente (Correo envi√°ndose en segundo plano)."
        })

    except Exception as e:
        return JSONResponse({"status": "error", "mensaje": str(e)})
# =========================================================================
# 12. ENDPOINTS DE LOGS Y AUDITOR√çA
# =========================================================================

@app.get("/obtener_logs")
def obtener_logs():
    try:
        conn = get_db_connection()
        c = conn.cursor()
        c.execute("SELECT * FROM Auditoria ORDER BY Fecha DESC LIMIT 100")
        logs = c.fetchall()
        conn.close()
        
        # ‚úÖ CORRECCI√ìN M√ÅGICA
        logs_serializables = json.loads(json.dumps(logs, default=str))
        
        return JSONResponse(logs_serializables)
    except Exception as e:
        print(f"Error logs: {e}")
        return JSONResponse([])
# =========================================================================
# 13. ENDPOINTS EXISTENTES MANTENIDOS
# =========================================================================

@app.get("/listar_usuarios")
def listar_usuarios():
    """Versi√≥n OPTIMIZADA: Lista usuarios r√°pidamente"""
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # Traemos solo los campos necesarios, ordenados alfab√©ticamente
        c.execute("""
            SELECT ID, Nombre, Apellido, CI, Password, Tipo, Foto, Activo, Email, Telefono 
            FROM Usuarios 
            ORDER BY Apellido ASC, Nombre ASC
        """)
        usuarios = c.fetchall()
        conn.close()
        
        # Serializaci√≥n segura de fechas y datos
        return JSONResponse(json.loads(json.dumps(usuarios, default=str)))
        
    except Exception as e:
        print(f"‚ùå Error listando usuarios: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
@app.get("/resumen_estudiantes_con_evidencias")
def resumen_estudiantes():
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # Consulta segura
        query = """
            SELECT 
                u.Nombre, u.Apellido, u.CI, u.Foto,
                COUNT(e.id) as total_evidencias,
                COALESCE(SUM(e.Tamanio_KB), 0) as total_kb
            FROM Usuarios u
            LEFT JOIN Evidencias e ON u.CI = e.CI_Estudiante
            WHERE u.Tipo = 1
            GROUP BY u.CI, u.Nombre, u.Apellido, u.Foto
            ORDER BY u.Apellido ASC
        """
        c.execute(query)
        data = c.fetchall()
        conn.close()
        
        # ‚úÖ CORRECCI√ìN: Convertir fechas y datos raros a texto
        import json
        data_serializable = json.loads(json.dumps(data, default=str))
        
        return JSONResponse(data_serializable)
    except Exception as e:
        print(f"‚ùå Error resumen: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
@app.get("/todas_evidencias")
def todas_evidencias(cedula: str):
    try:
        conn = get_db_connection()
        c = conn.cursor()
        # Buscamos por la c√©dula del estudiante
        c.execute("SELECT * FROM Evidencias WHERE CI_Estudiante = %s ORDER BY id DESC", (cedula,))
        evs = c.fetchall()
        conn.close()
        
        # ‚úÖ CORRECCI√ìN: Convertir fechas a texto para que no falle
        import json
        evs_serializables = json.loads(json.dumps(evs, default=str))
        
        return JSONResponse(evs_serializables)
    except Exception as e:
        print(f"‚ùå Error evidencias estudiante: {e}")
        return JSONResponse([])

@app.delete("/eliminar_evidencia/{id}")
async def eliminar_evidencia(id: int):
    try:
        conn = get_db_connection()
        # Usamos RealDictCursor para obtener un diccionario
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Buscar la evidencia
        c.execute("SELECT * FROM Evidencias WHERE id = %s", (id,))
        evidencia = c.fetchone()
        
        if not evidencia:
            conn.close()
            raise HTTPException(status_code=404, detail="Evidencia no encontrada")
            
        # üõ°Ô∏è CORRECCI√ìN: Buscamos la URL con seguridad (may√∫sculas o min√∫sculas)
        url = evidencia.get('Url_Archivo') or evidencia.get('url_archivo')
        
        # 2. Borrar de la Nube (Si tiene URL v√°lida)
        if url and s3_client and BUCKET_NAME and "backblazeb2.com" in url:
            try:
                # Extraer la clave del archivo
                partes = url.split(f"/file/{BUCKET_NAME}/")
                if len(partes) > 1:
                    file_key = partes[1]
                    print(f"üóëÔ∏è Eliminando de B2: {file_key}")
                    s3_client.delete_object(Bucket=BUCKET_NAME, Key=file_key)
            except Exception as e_b2:
                print(f"‚ö†Ô∏è Alerta: Se borr√≥ de BD pero fall√≥ en B2: {e_b2}")

        # 3. Borrar de la Base de Datos
        c.execute("DELETE FROM Evidencias WHERE id = %s", (id,))
        conn.commit()
        conn.close()
        
        return JSONResponse({"mensaje": "Evidencia eliminada correctamente"})
        
    except Exception as e:
        # Imprimimos el error exacto en los logs de Railway
        print(f"‚ùå Error CR√çTICO eliminando evidencia {id}: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
@app.get("/diagnostico_usuario/{cedula}")
async def diagnostico_usuario(cedula: str):
    """Diagn√≥stico completo de un usuario (Versi√≥n PostgreSQL)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # CORRECCI√ìN: Usamos information_schema en lugar de PRAGMA
        c.execute("""
            SELECT column_name, data_type 
            FROM information_schema.columns 
            WHERE table_name = 'usuarios'
        """)
        columnas = c.fetchall()
        
        # Buscar usuario
        c.execute("SELECT * FROM Usuarios WHERE CI = %s", (cedula,))
        usuario = c.fetchone()
        
        # Evidencias del usuario
        c.execute("""
            SELECT COUNT(*) as total, 
                   SUM(Tamanio_KB) as total_kb,
                   Tipo_Archivo,
                   COUNT(*) as cantidad
            FROM Evidencias
            WHERE CI_Estudiante = %s
            GROUP BY Tipo_Archivo
        """, (cedula,))
        estadisticas_evidencias = [dict(r) for r in c.fetchall()]
        
        # Solicitudes del usuario
        c.execute("""
            SELECT Estado, COUNT(*) as cantidad
            FROM Solicitudes
            WHERE CI_Solicitante = %s
            GROUP BY Estado
        """, (cedula,))
        estadisticas_solicitudes = [dict(r) for r in c.fetchall()]
        
        conn.close()
        
        return JSONResponse(content={
            "cedula_buscada": cedula,
            "usuario_encontrado": bool(usuario),
            "usuario": dict(usuario) if usuario else None,
            "estructura_tabla": [dict(r) for r in columnas],
            "estadisticas_evidencias": estadisticas_evidencias,
            "estadisticas_solicitudes": estadisticas_solicitudes,
            "fecha_diagnostico": ahora_ecuador().isoformat(),
            "zona_horaria": "America/Guayaquil (UTC-5)"
        })
        
    except Exception as e:
        return JSONResponse(content={"error": str(e)})

@app.get("/reset-db")
async def reset_database():
    """Reinicia la base de datos (SOLO DESARROLLO)"""
    try:
        init_db_completa()
        return JSONResponse(content={
            "status": "ok",
            "mensaje": "Base de datos reinicializada",
            "fecha": ahora_ecuador().isoformat()
        })
    except Exception as e:
        return JSONResponse(content={"error": str(e)})

# =========================================================================
# 14. ENDPOINTS CORS Y UTILIDADES
# =========================================================================

@app.options("/{rest_of_path:path}")
async def preflight_handler(request: Request, rest_of_path: str):
    """Manejador de preflight CORS"""
    response = JSONResponse(content={"message": "Preflight OK"})
    response.headers["Access-Control-Allow-Origin"] = "*"
    response.headers["Access-Control-Allow-Credentials"] = "true"
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS, PATCH"
    response.headers["Access-Control-Allow-Headers"] = "*"
    return response

@app.get("/cors-debug")
async def cors_debug():
    """Endpoint para debug de CORS"""
    return JSONResponse(content={
        "message": "CORS Debug Endpoint",
        "allow_origin": "*",
        "allow_methods": "GET, POST, PUT, DELETE, OPTIONS, PATCH",
        "allow_headers": "*",
        "allow_credentials": "true",
        "timestamp": ahora_ecuador().isoformat(),
        "zona_horaria": "America/Guayaquil (UTC-5)"
    })

# =========================================================================
# 15. INICIO DE LA APLICACI√ìN
# =========================================================================

class PasswordRequest(BaseModel):
    cedula: str
    nueva_contrasena: str

@app.post("/cambiar_contrasena")
async def cambiar_contrasena(datos: PasswordRequest):
    try:
        conn = get_db_connection()
        conn.execute("UPDATE Usuarios SET Password = %s WHERE CI = %s", (datos.nueva_contrasena, datos.cedula))
        conn.commit()
        conn.close()
        return JSONResponse({"mensaje": "Contrase√±a actualizada correctamente"})
    except Exception as e:
        return JSONResponse({"error": str(e)})
    
@app.post("/descargar_evidencias_zip")
async def descargar_evidencias_zip(ids: str = Form(...)):
    try:
        lista_ids = ids.split(',')
        if not lista_ids:
            return JSONResponse({"error": "No hay IDs"}, status_code=400)
            
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # Consultar archivos
        placeholders = ','.join(['%s'] * len(lista_ids))
        c.execute(f"SELECT Url_Archivo FROM Evidencias WHERE id IN ({placeholders})", tuple(lista_ids))
        resultados = c.fetchall()
        conn.close()
        
        if not resultados:
            return JSONResponse({"error": "No se encontraron archivos"}, status_code=404)

        # Crear ZIP en memoria
        zip_buffer = io.BytesIO()
        
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for i, item in enumerate(resultados):
                url = item['Url_Archivo']
                nombre_archivo = f"evidencia_{i+1}_{os.path.basename(url)}"
                
                # CASO 1: Archivo en Nube (Backblaze/S3)
                if "backblazeb2.com" in url or "s3" in url:
                    if s3_client and BUCKET_NAME:
                        try:
                            # Extraer key de la URL
                            partes = url.split(f"/file/{BUCKET_NAME}/")
                            if len(partes) > 1:
                                file_key = partes[1]
                                # Descargar de S3 a memoria
                                file_obj = s3_client.get_object(Bucket=BUCKET_NAME, Key=file_key)
                                file_content = file_obj['Body'].read()
                                zip_file.writestr(nombre_archivo, file_content)
                                print(f"üì¶ Agregado al ZIP (Nube): {nombre_archivo}")
                        except Exception as e:
                            print(f"‚ö†Ô∏è Error bajando de nube {url}: {e}")
                            # Crear archivo de texto de error en el zip
                            zip_file.writestr(f"ERROR_{nombre_archivo}.txt", f"No se pudo descargar: {str(e)}")
                
                # CASO 2: Archivo Local (Legado)
                elif os.path.exists(url):
                    try:
                        zip_file.write(url, nombre_archivo)
                        print(f"üì¶ Agregado al ZIP (Local): {nombre_archivo}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error archivo local: {e}")

        zip_buffer.seek(0)
        
        # Nombre del ZIP con fecha
        fecha_str = datetime.datetime.now().strftime("%Y%m%d_%H%M")
        nombre_zip = f"evidencias_seleccion_{fecha_str}.zip"
        
        return StreamingResponse(
            zip_buffer, 
            media_type="application/zip",
            headers={"Content-Disposition": f"attachment; filename={nombre_zip}"}
        )

    except Exception as e:
        print(f"‚ùå Error generando ZIP: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)


from urllib.parse import urlparse 

def limpieza_duplicados_startup():
    """
    V5.4 - CORREGIDA PARA POSTGRESQL (Fix HAVING y Lowercase)
    """
    print("üßπ INICIANDO PROTOCOLO DE LIMPIEZA Y MANTENIMIENTO...")
    
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # ---------------------------------------------------------
        # FASE 0: LIMPIEZA POR URL EXACTA
        # ---------------------------------------------------------
        print("üîç FASE 0: Buscando URLs id√©nticas...")
        # CORRECCI√ìN: Usamos COUNT(*) > 1 en vez de 'cantidad'
        c.execute("""
            SELECT Url_Archivo, COUNT(*) as cantidad FROM Evidencias 
            GROUP BY Url_Archivo HAVING COUNT(*) > 1
        """)
        urls_repetidas = c.fetchall()
        
        eliminados_0 = 0
        for row in urls_repetidas:
            # PostgreSQL devuelve claves en min√∫scula: row['url_archivo']
            url = row['url_archivo'] if 'url_archivo' in row else row['Url_Archivo']
            
            c.execute("SELECT id FROM Evidencias WHERE Url_Archivo = %s ORDER BY id ASC", (url,))
            copias = c.fetchall()
            for copia in copias[1:]: # Borrar todos menos el primero
                c.execute("DELETE FROM Evidencias WHERE id = %s", (copia['id'],))
                eliminados_0 += 1
        
        if eliminados_0 > 0: print(f"   ‚ú® Fase 0: {eliminados_0} registros eliminados.")

        # ---------------------------------------------------------
        # FASE 1: REPARAR ARCHIVOS ANTIGUOS
        # ---------------------------------------------------------
        print("‚è≥ FASE 1: Verificando huellas digitales...")
        c.execute("SELECT id, Url_Archivo FROM Evidencias WHERE Hash = 'PENDIENTE' OR Hash IS NULL")
        pendientes = c.fetchall()
        
        count_hashed = 0
        for row in pendientes:
            try:
                # Soporte para min√∫sculas/may√∫sculas
                url = row.get('Url_Archivo') or row.get('url_archivo')
                id_ev = row.get('id')
                
                temp_path = None
                file_hash = None
                
                if "http" in url and s3_client:
                    try:
                        parsed = urlparse(url)
                        key = parsed.path.lstrip('/')
                        with tempfile.NamedTemporaryFile(delete=False) as tmp:
                            s3_client.download_fileobj(BUCKET_NAME, key, tmp)
                            temp_path = tmp.name
                        file_hash = calcular_hash(temp_path)
                    except: pass 
                elif "/local/" in url:
                    ruta_local = url.replace("/local/", "./")
                    if not os.path.exists(ruta_local):
                         ruta_local = os.path.join(BASE_DIR, url.replace("/local/", "").lstrip("/"))
                    if os.path.exists(ruta_local):
                        file_hash = calcular_hash(ruta_local)

                if file_hash:
                    c.execute("UPDATE Evidencias SET Hash = %s WHERE id = %s", (file_hash, id_ev))
                    count_hashed += 1
                
                if temp_path and os.path.exists(temp_path): os.remove(temp_path)
            except: pass
            
        conn.commit() 

        # (Mant√©n el resto de las fases igual, el error cr√≠tico era la Fase 0)
        # ... Para ahorrar espacio, asumo que dejas las Fases 2, 3 y 4 como estaban
        # pero recuerda que si acceden a columnas deben buscar la versi√≥n en min√∫scula.
        
        conn.close()
        print(f"‚úÖ MANTENIMIENTO FINALIZADO (Fase 0 y 1 completas).")

    except Exception as e:
        print(f"‚ùå Error en limpieza startup: {e}")

        # ---------------------------------------------------------
        # FASE 2: ELIMINAR POR HASH
        # ---------------------------------------------------------
        print("üîç FASE 2: Buscando contenido id√©ntico (Hash)...")
        c.execute("""
            SELECT Hash, COUNT(*) as cantidad FROM Evidencias 
            WHERE Hash NOT IN ('PENDIENTE', '', 'RECUPERADO') GROUP BY Hash HAVING cantidad > 1
        """)
        grupos_hash = c.fetchall()
        
        eliminados_2 = 0
        for grupo in grupos_hash:
            c.execute("SELECT id, Url_Archivo FROM Evidencias WHERE Hash = %s ORDER BY id ASC", (grupo['Hash'],))
            copias = c.fetchall()
            original = copias[0]
            for copia in copias[1:]:
                if s3_client and copia['Url_Archivo'] != original['Url_Archivo'] and BUCKET_NAME in copia['Url_Archivo']:
                    try:
                        parsed = urlparse(copia['Url_Archivo'])
                        key = parsed.path.lstrip('/')
                        s3_client.delete_object(Bucket=BUCKET_NAME, Key=key)
                    except: pass
                
                c.execute("DELETE FROM Evidencias WHERE id = %s", (copia['id'],))
                eliminados_2 += 1
        
        if eliminados_2 > 0: print(f"   ‚ú® Fase 2: {eliminados_2} duplicados exactos eliminados.")

        # ---------------------------------------------------------
        # FASE 3: ELIMINAR POR NOMBRE + ESTUDIANTE
        # ---------------------------------------------------------
        print("üîç FASE 3: Buscando duplicados por nombre de archivo...")
        c.execute("SELECT id, CI_Estudiante, Url_Archivo FROM Evidencias")
        todas = c.fetchall()
        agrupados = {}
        
        for ev in todas:
            url = ev['Url_Archivo']
            cedula = ev['CI_Estudiante']
            filename = os.path.basename(url)
            clean_name = re.sub(r'^\d+_', '', filename)
            clave = f"{cedula}|{clean_name}"
            
            if clave not in agrupados: agrupados[clave] = []
            agrupados[clave].append(ev)
            
        eliminados_3 = 0
        for clave, lista in agrupados.items():
            if len(lista) > 1:
                lista.sort(key=lambda x: x['id'])
                duplicados = lista[1:] 
                for dup in duplicados:
                    c.execute("DELETE FROM Evidencias WHERE id = %s", (dup['id'],))
                    if s3_client and BUCKET_NAME in dup['Url_Archivo']:
                        try:
                            parsed = urlparse(dup['Url_Archivo'])
                            key = parsed.path.lstrip('/')
                            s3_client.delete_object(Bucket=BUCKET_NAME, Key=key)
                        except: pass
                    eliminados_3 += 1

        if eliminados_3 > 0: print(f"   ‚ú® Fase 3: {eliminados_3} archivos eliminados por nombre.")

        # ---------------------------------------------------------
        # FASE 4: SINCRONIZACI√ìN SEGURA CON NUBE
        # ---------------------------------------------------------
        print("‚òÅÔ∏è FASE 4: Auditando existencia real en la nube...")
        conn.commit()
        c.execute("SELECT id, Url_Archivo FROM Evidencias")
        evidencias = c.fetchall()
        
        actualizados_peso = 0
        eliminados_nube = 0
        
        for ev in evidencias:
            url = ev['Url_Archivo']
            existe = False
            peso_kb = 0
            
            if s3_client and BUCKET_NAME in url:
                try:
                    parsed = urlparse(url)
                    key = parsed.path.lstrip('/')
                    meta = s3_client.head_object(Bucket=BUCKET_NAME, Key=key)
                    peso_kb = meta['ContentLength'] / 1024
                    existe = True
                except Exception as e:
                    if "404" in str(e) or "Not Found" in str(e): existe = False
                    else: existe = True 
            elif "/local/" in url:
                existe = True 
            
            if existe:
                c.execute("UPDATE Evidencias SET Tamanio_KB = %s WHERE id = %s", (peso_kb, ev['id']))
                actualizados_peso += 1
            else:
                c.execute("DELETE FROM Evidencias WHERE id = %s", (ev['id'],))
                eliminados_nube += 1
        
        conn.commit()
        print(f"‚úÖ FASE 4 COMPLETADA: {actualizados_peso} actualizados, {eliminados_nube} eliminados.")
        
        # Actualizar m√©tricas
        try:
            stats = calcular_estadisticas_reales()
            fecha_hoy = ahora_ecuador().date().isoformat()
            
            # Usar conexi√≥n nueva para m√©tricas para evitar conflictos
            conn_metricas = get_db_connection()
            c_met = conn_metricas.cursor()
            c_met.execute("""
                INSERT INTO Metricas_Sistema 
                (Fecha, Total_Usuarios, Total_Evidencias, Solicitudes_Pendientes, Almacenamiento_MB)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (Fecha) DO UPDATE SET
                Total_Usuarios = EXCLUDED.Total_Usuarios,
                Total_Evidencias = EXCLUDED.Total_Evidencias,
                Solicitudes_Pendientes = EXCLUDED.Solicitudes_Pendientes,
                Almacenamiento_MB = EXCLUDED.Almacenamiento_MB
            """, (fecha_hoy, stats.get("usuarios_activos",0), stats.get("total_evidencias",0), 
                  stats.get("solicitudes_pendientes",0), stats.get("almacenamiento_mb",0)))
            conn_metricas.commit()
            conn_metricas.close()
        except Exception as e:
            print(f"‚ö†Ô∏è Error menor actualizando m√©tricas: {e}")
        
        conn.close()
        print(f"‚úÖ MANTENIMIENTO TOTAL FINALIZADO.")

    except Exception as e:
        print(f"‚ùå Error en limpieza startup: {e}")
@app.post("/recuperar_evidencias_nube")
async def recuperar_evidencias_nube(background_tasks: BackgroundTasks):
    """
    Escanea TODO el bucket de Backblaze, encuentra los archivos que faltan en la BD
    y los restaura autom√°ticamente (intentando usar IA para re-asignarlos).
    """
    def tarea_rescate():
        print("üöë INICIANDO OPERACI√ìN RESCATE DE EVIDENCIAS...")
        if not s3_client:
            print("‚ùå No hay conexi√≥n S3 para el rescate.")
            return

        conn = get_db_connection()
        c = conn.cursor() # <--- IMPORTANTE: Creamos el cursor aqu√≠
        restaurados = 0
        
        try:
            # 1. Listar TODOS los objetos en la carpeta 'evidencias/' de la nube
            paginator = s3_client.get_paginator('list_objects_v2')
            pages = paginator.paginate(Bucket=BUCKET_NAME, Prefix='evidencias/')
            
            for page in pages:
                if 'Contents' not in page: continue
                
                for obj in page['Contents']:
                    key = obj['Key'] # Ejemplo: evidencias/123_foto.jpg
                    
                    # Ignoramos carpetas vac√≠as
                    if key.endswith('/'): continue
                    
                    # Construimos la URL que deber√≠a tener
                    url_archivo = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{key}"
                    
                    # 2. Verificar si ya existe en la BD (Usando el cursor 'c')
                    c.execute("SELECT id FROM Evidencias WHERE Url_Archivo = %s", (url_archivo,))
                    existe = c.fetchone()
                    
                    if not existe:
                        print(f"   üì• Recuperando: {key}...")
                        
                        # Descargar para an√°lisis IA (si es imagen)
                        temp_path = None
                        ci_detectada = '9999999990' # Por defecto a bandeja recuperados
                        asignado_auto = 0
                        
                        try:
                            # Descargar archivo temporal
                            with tempfile.NamedTemporaryFile(delete=False) as tmp:
                                s3_client.download_fileobj(BUCKET_NAME, key, tmp)
                                temp_path = tmp.name
                            
                            # Intentar reconocer rostros para re-asignar
                            if key.lower().endswith(('.jpg', '.jpeg', '.png', '.webp', '.avif')) and rekog:
                                try:
                                    rostros = identificar_varios_rostros_aws(temp_path)
                                    if rostros:
                                        # Si encuentra rostros, buscamos si son estudiantes
                                        for rostro in rostros:
                                            c.execute("SELECT CI FROM Usuarios WHERE CI=%s", (rostro,))
                                            u = c.fetchone()
                                            if u:
                                                ci_detectada = u['CI']
                                                asignado_auto = 1
                                                break
                                except: pass
                            
                            # Calcular Hash nuevo
                            nuevo_hash = calcular_hash(temp_path)
                            size_kb = obj['Size'] / 1024
                            
                            # Insertar en BD (Usando el cursor 'c')
                            tipo = 'video' if key.lower().endswith(('.mp4', '.avi')) else 'imagen'
                            c.execute("""
                                INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                                VALUES (%s, %s, %s, 1, %s, %s, %s)
                            """, (ci_detectada, url_archivo, nuevo_hash, tipo, size_kb, asignado_auto))
                            
                            restaurados += 1
                            
                            if temp_path and os.path.exists(temp_path): os.remove(temp_path)
                            
                        except Exception as e:
                            print(f"   ‚ö†Ô∏è Error parcial recuperando {key}: {e}")
                            # Intentamos insertar aunque sea sin IA
                            try:
                                c.execute("""
                                    INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                                    VALUES ('9999999990', %s, 'RECUPERADO', 1, 'desconocido', 0, 0)
                                """, (url_archivo,))
                                restaurados += 1
                            except: pass

            conn.commit()
            print(f"‚úÖ OPERACI√ìN RESCATE FINALIZADA: {restaurados} evidencias restauradas.")
            
            # Actualizar estad√≠sticas (Usando el cursor 'c')
            try:
                stats = calcular_estadisticas_reales()
                fecha = ahora_ecuador().date().isoformat()
                c.execute("""
                    INSERT INTO Metricas_Sistema (Fecha, Total_Evidencias, Almacenamiento_MB) 
                    VALUES (%s, %s, %s)
                    ON CONFLICT (Fecha) DO UPDATE SET
                    Total_Evidencias = EXCLUDED.Total_Evidencias,
                    Almacenamiento_MB = EXCLUDED.Almacenamiento_MB
                """, (fecha, stats.get('total_evidencias',0), stats.get('almacenamiento_mb',0)))
                conn.commit()
            except Exception as e:
                print(f"‚ö†Ô∏è Error actualizando m√©tricas tras rescate: {e}")

        except Exception as e:
            print(f"‚ùå Error cr√≠tico en rescate: {e}")
        finally:
            conn.close()

    background_tasks.add_task(tarea_rescate)
    return JSONResponse({"mensaje": "üöë Rescate iniciado. Revisa los logs en 2 minutos."})

class ReasignarRequest(BaseModel):
    ids: str
    cedula_destino: str


    # --- AGREGA ESTE NUEVO ENDPOINT PARA RECUPERAR TUS DATOS ---

@app.post("/reasignar_evidencias")
async def reasignar_evidencias(datos: ReasignarRequest):
    """
    V2.0 - Reasignaci√≥n Multi-Destino:
    - Permite enviar una lista de c√©dulas destino (separadas por comas).
    - Al primer destino le MUEVE el archivo.
    - A los siguientes destinos les crea una COPIA (Clon) en la base de datos.
    """
    try:
        if not datos.ids or not datos.cedula_destino:
            return JSONResponse({"error": "Faltan datos"})
            
        ids_evidencias = [id.strip() for id in datos.ids.split(',') if id.strip()]
        cedulas_destino = [ced.strip() for ced in datos.cedula_destino.split(',') if ced.strip()]
        
        if not ids_evidencias or not cedulas_destino:
             return JSONResponse({"error": "Selecci√≥n inv√°lida"})

        conn = get_db_connection()
        c = conn.cursor()
        
        movidos = 0
        clonados = 0
        
        # 1. Obtener datos originales de las evidencias antes de moverlas
        placeholders = ','.join(['%s'] * len(ids_evidencias))
        evidencias_originales = c.execute(f"SELECT * FROM Evidencias WHERE id IN ({placeholders})", ids_evidencias).fetchall()

        # 2. PROCESAR CADA EVIDENCIA
        for ev in evidencias_originales:
            # A) Mover al PRIMER estudiante de la lista (UPDATE)
            primer_destino = cedulas_destino[0]
            c.execute("UPDATE Evidencias SET CI_Estudiante = %s, Asignado_Automaticamente = 0 WHERE id = %s", (primer_destino, ev['id']))
            movidos += 1
            
            # B) Clonar para el RESTO de estudiantes (INSERT)
            if len(cedulas_destino) > 1:
                for otro_destino in cedulas_destino[1:]:
                    c.execute("""
                        INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                        VALUES (%s, %s, %s, %s, %s, %s, 0)
                    """, (otro_destino, ev['Url_Archivo'], ev['Hash'], ev['Estado'], ev['Tipo_Archivo'], ev['Tamanio_KB']))
                    clonados += 1

        conn.commit()
        conn.close()
        
        mensaje = f"‚úÖ Archivos movidos a 1 estudiante."
        if clonados > 0:
            mensaje += f" Y se crearon copias para {len(cedulas_destino)-1} estudiantes m√°s."
        
        return JSONResponse({"mensaje": mensaje})
        
    except Exception as e:
        return JSONResponse({"error": str(e)})

# --- ENDPOINT DE EMERGENCIA PARA CORREGIR ADMIN ---
@app.get("/reparar_admin")
async def reparar_admin():
    """Fuerza al usuario 9999999999 a ser Administrador (Tipo 0)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # 1. Verificar si existe
        c.execute("SELECT * FROM Usuarios WHERE CI = '9999999999'")
        user = c.fetchone()
        
        if not user:
            # Si no existe, lo creamos de cero
            c.execute("""
                INSERT INTO Usuarios (Nombre, Apellido, CI, Password, Tipo, Activo) 
                VALUES ('Admin', 'Sistema', '9999999999', 'admin123', 0, 1)
            """)
            mensaje = "Usuario Admin no exist√≠a. CREADO exitosamente."
        else:
            # Si existe, LO FORZAMOS a ser Tipo 0
            c.execute("UPDATE Usuarios SET Tipo = 0, Activo = 1 WHERE CI = '9999999999'")
            mensaje = "Usuario 9999999999 actualizado: AHORA ES ADMIN (Tipo 0)."
            
        conn.commit()
        conn.close()
        return JSONResponse({"status": "ok", "mensaje": mensaje})
        
    except Exception as e:
        return JSONResponse({"error": str(e)})

if __name__ == "__main__":
    import uvicorn
    
    # Configuraci√≥n del puerto
    port = int(os.environ.get("PORT", 8000))
    
    print("=" * 60)
    print("üöÄ SISTEMA EDUCATIVO DESPERTAR - BACKEND V7.0")
    print("=" * 60)
    print(f"üìÅ Base de datos: {DB_NAME}")
    print(f"üåç Zona horaria: America/Guayaquil (UTC-5)")
    print(f"ü§ñ AWS Rekognition: {'‚úÖ Disponible' if rekog else '‚ùå No disponible'}")
    print(f"üíæ S3 Storage: {'‚úÖ Disponible' if s3_client else '‚ùå No disponible'}")
    print(f"üìß Servidor SMTP: {'‚úÖ Configurado' if SMTP_EMAIL and 'tu_correo' not in SMTP_EMAIL else '‚ö†Ô∏è Simulado'}")
    print(f"üîê Usuario admin: 9999999999 / admin123")
    
    # üëáüëáüëá ESTA L√çNEA ES LA CLAVE QUE TE FALTABA üëáüëáüëá
    limpieza_duplicados_startup()
    # üëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜ
    
    print(f"üåê Servidor iniciado en: http://0.0.0.0:{port}")
    print("=" * 60)
    
    uvicorn.run(app, host="0.0.0.0", port=port)