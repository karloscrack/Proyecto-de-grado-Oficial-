import shutil
import os
import logging
import datetime
import zipfile
import hashlib
import boto3
import cv2 
import numpy as np
import tempfile 
import smtplib
import pytz
import json
import io
import difflib
import psycopg2
from psycopg2.extras import RealDictCursor
import os
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from typing import Optional, List
from fastapi import FastAPI, UploadFile, Form, HTTPException, BackgroundTasks, Request, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse, StreamingResponse
from botocore.config import Config
from pydantic import BaseModel
from fastapi.encoders import jsonable_encoder

# --- 0. CONFIGURACI√ìN DE ZONA HORARIA ECUADOR ---
ECUADOR_TZ = pytz.timezone('America/Guayaquil')  # UTC-5

def ahora_ecuador():
    """Devuelve la fecha/hora actual en zona horaria de Ecuador"""
    return datetime.datetime.now(ECUADOR_TZ)

# --- CONFIGURACI√ìN DE CORREO ---
SMTP_SERVER = "smtp.gmail.com"
SMTP_PORT = 465  # <--- Aseg√∫rate de que sea 465
SMTP_EMAIL = "karlos.ayala.lopez.1234@gmail.com"
SMTP_PASSWORD = "mzjg jvxj mruk qgeb"

# --- 1. CONFIGURACI√ìN Y CREDENCIALES AWS/B2 ---
AWS_ACCESS_KEY = os.environ.get("AWS_ACCESS_KEY")
AWS_SECRET_KEY = os.environ.get("AWS_SECRET_KEY")
AWS_REGION = "us-east-1"
COLLECTION_ID = "estudiantes_db"

# Inicializaci√≥n condicional de AWS Rekognition
try:
    if AWS_ACCESS_KEY and AWS_SECRET_KEY:
        rekog = boto3.client('rekognition', region_name=AWS_REGION, 
                           aws_access_key_id=AWS_ACCESS_KEY, 
                           aws_secret_access_key=AWS_SECRET_KEY)
        print("‚úÖ AWS Rekognition inicializado")
    else:
        rekog = None
        print("‚ö†Ô∏è AWS Rekognition no disponible (credenciales faltantes)")
except Exception as e:
    rekog = None
    print(f"‚ö†Ô∏è Error inicializando AWS Rekognition: {e}")

# Configuraci√≥n Backblaze B2
ENDPOINT_B2 = "https://s3.us-east-005.backblazeb2.com"
KEY_ID_B2 = "00508884373dab40000000001"
APP_KEY_B2 = "K005jvkLLmLdUKhhVis1qLcnU4flx0g"
BUCKET_NAME = "Proyecto-Grado-Karlos-2025"

try:
    my_config = Config(signature_version='s3v4', region_name='us-east-005')
    s3_client = boto3.client('s3', 
                            endpoint_url=ENDPOINT_B2,
                            aws_access_key_id=KEY_ID_B2,
                            aws_secret_access_key=APP_KEY_B2,
                            config=my_config)
    print("‚úÖ Cliente S3 (Backblaze) inicializado")
except Exception as e:
    s3_client = None
    print(f"‚ö†Ô∏è Cliente S3 no disponible: {e}")

# Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

# --- L√ìGICA DE VOLUMEN PERSISTENTE ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_FILENAME = "Bases_de_datos.db"
VOLUMEN_PATH = "/app/datos_persistentes"

# Determinar ruta final de la base de datos
if os.path.exists(VOLUMEN_PATH):
    db_en_volumen = os.path.join(VOLUMEN_PATH, DB_FILENAME)
    if not os.path.exists(db_en_volumen):
        db_original = os.path.join(BASE_DIR, DB_FILENAME)
        if os.path.exists(db_original):
            shutil.copy(db_original, db_en_volumen)
            print(f"‚úÖ Base de datos copiada al volumen persistente: {db_en_volumen}")
    DB_NAME = db_en_volumen
else:
    DB_NAME = os.path.join(BASE_DIR, DB_FILENAME)

print(f"üìÅ Ruta base de datos: {DB_NAME}")

def get_db_connection():
    try:
        # ‚úÖ URL DEL POOLER (La definitiva)
        # Usamos la direcci√≥n 'aws-1-sa-east-1...' que es compatible con Railway.
        # Puerto 6543 (Transaction Mode)
        
        conn_str = "postgresql://postgres.wwrbrabdwhoiougbaskz:1ZulgnaY0cnsz2p4@aws-1-sa-east-1.pooler.supabase.com:6543/postgres?sslmode=require"
        
        # Conectamos directamente (sin trucos de IP manual, ya no hacen falta)
        conn = psycopg2.connect(conn_str)
        conn.cursor_factory = RealDictCursor 
        return conn
    except Exception as e:
        print(f"‚ùå Error CR√çTICO conectando a Supabase: {e}")
        return None

# --- FUNCIONES DE MANTENIMIENTO ---
def optimizar_sistema_db():
    """Ejecuta mantenimiento VACUUM en Supabase"""
    try:
        conn = get_db_connection()
        # En Postgres, VACUUM no puede ejecutarse dentro de una transacci√≥n
        conn.autocommit = True 
        with conn.cursor() as c:
            c.execute("VACUUM")
            c.execute("ANALYZE")
        conn.close()
        print("‚úÖ Sistema optimizado (VACUUM ejecutado en Supabase)")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Alerta menor: No se pudo optimizar DB: {e}")
        return False

class EstadoUsuarioRequest(BaseModel):
    cedula: str
    activo: int

class BackupRequest(BaseModel):
    tipo: str = "completo"

# --- 2. INICIALIZACI√ìN DE BASE DE DATOS - MEJORADA ---
# --- INICIALIZACI√ìN DE TABLAS ---
def init_db_completa():
    print("üîÑ Iniciando configuraci√≥n de base de datos en Supabase...")
    try:
        conn = get_db_connection()
        if not conn:
            print("‚ùå No hay conexi√≥n a BD, abortando init.")
            return
            
        c = conn.cursor()
        
        # 1. Tabla Usuarios
        c.execute('''CREATE TABLE IF NOT EXISTS Usuarios (
            ID SERIAL PRIMARY KEY,
            Nombre TEXT NOT NULL,
            Apellido TEXT NOT NULL,
            CI TEXT UNIQUE NOT NULL,
            Password TEXT NOT NULL,
            Tipo INTEGER DEFAULT 1,
            Foto TEXT,
            Activo INTEGER DEFAULT 1,
            Fecha_Desactivacion TIMESTAMP NULL,
            Ultimo_Acceso TIMESTAMP NULL,
            TutorialVisto INTEGER DEFAULT 0,
            Face_Encoding TEXT,
            Fecha_Registro TIMESTAMP DEFAULT NOW(),
            Email TEXT,
            Telefono TEXT
        )''')
        
        # 2. Tabla Evidencias
        c.execute('''CREATE TABLE IF NOT EXISTS Evidencias (
            id SERIAL PRIMARY KEY,
            CI_Estudiante TEXT NOT NULL,
            Url_Archivo TEXT NOT NULL,
            Hash TEXT NOT NULL,
            Estado INTEGER DEFAULT 1,
            Tipo_Archivo TEXT DEFAULT 'documento',
            Fecha TIMESTAMP DEFAULT NOW(),
            Tamanio_KB REAL DEFAULT 0,
            Asignado_Automaticamente INTEGER DEFAULT 0
        )''')

        # 3. Tabla Solicitudes
        c.execute('''CREATE TABLE IF NOT EXISTS Solicitudes (
            id SERIAL PRIMARY KEY,
            Tipo TEXT NOT NULL,
            CI_Solicitante TEXT NOT NULL,
            Email TEXT,
            Detalle TEXT,
            Evidencia_Reportada_Url TEXT,
            Id_Evidencia INTEGER,
            Resuelto_Por TEXT,
            Respuesta TEXT,
            Fecha TIMESTAMP DEFAULT NOW(),
            Estado TEXT DEFAULT 'PENDIENTE',
            Fecha_Resolucion TIMESTAMP NULL
        )''')
        
        # 4. Tabla Auditoria
        c.execute('''CREATE TABLE IF NOT EXISTS Auditoria (
            id SERIAL PRIMARY KEY,
            Accion TEXT NOT NULL,
            Detalle TEXT,
            IP TEXT,
            Usuario TEXT,
            Fecha TIMESTAMP DEFAULT NOW()
        )''')
        
        # 5. Tabla M√©tricas
        c.execute('''CREATE TABLE IF NOT EXISTS Metricas_Sistema (
            id SERIAL PRIMARY KEY,
            Fecha DATE UNIQUE,
            Total_Usuarios INTEGER DEFAULT 0,
            Total_Evidencias INTEGER DEFAULT 0,
            Solicitudes_Pendientes INTEGER DEFAULT 0,
            Almacenamiento_MB REAL DEFAULT 0
        )''')
        
        # Crear Admin
        c.execute("SELECT CI FROM Usuarios WHERE Tipo=0")
        if not c.fetchone():
            c.execute("INSERT INTO Usuarios (Nombre, Apellido, CI, Password, Tipo, Activo) VALUES (%s,%s,%s,%s,%s,%s)", 
                     ('Admin', 'Sistema', '9999999999', 'admin123', 0, 1))
            print("‚úÖ Usuario admin creado en Supabase")

        # Crear Bandeja Recuperados
        c.execute("SELECT CI FROM Usuarios WHERE CI='9999999990'")
        if not c.fetchone():
            c.execute("INSERT INTO Usuarios (Nombre, Apellido, CI, Password, Tipo, Activo, Foto) VALUES (%s,%s,%s,%s,%s,%s,%s)", 
                     ('Bandeja', 'Recuperados', '9999999990', '123456', 1, 1, ''))
            print("‚úÖ Bandeja de Recuperados creada")
        
        conn.commit()
        conn.close()
        print("‚úÖ Base de datos Supabase inicializada correctamente.")
        
    except Exception as e:
        print(f"‚ùå Error inicializando Supabase: {e}")

# EJECUTAR INICIALIZACI√ìN (¬°Ahora s√≠, al final de las definiciones!)
init_db_completa()

# =========================================================================
# 3. FUNCIONES AUXILIARES
# =========================================================================

def registrar_auditoria(accion: str, detalle: str, usuario: str = "Sistema", ip: str = ""):
    """
    Registra una acci√≥n OBLIGANDO la hora de Ecuador como TEXTO PLANO.
    Esto evita que la base de datos la convierta a UTC.
    """
    conn = None
    try:
        # 1. Obtener la hora exacta de Ecuador
        fecha_obj = ahora_ecuador()
        
        # 2. TRUCO DE ORO: Convertirla a texto simple AQUI en Python
        # As√≠ la base de datos guarda "2025-01-01 10:00" tal cual, sin sumar 5 horas.
        fecha_str = fecha_obj.strftime("%Y-%m-%d %H:%M:%S")
        
        conn = get_db_connection()
        if conn:
            c = conn.cursor()
            c.execute("""
                INSERT INTO Auditoria (Accion, Detalle, Usuario, IP, Fecha) 
                VALUES (%s, %s, %s, %s, %s)
            """, (accion, detalle, usuario, ip, fecha_str)) # <--- Enviamos el texto, no el objeto
            
            conn.commit()
            print(f"üìù LOG REGISTRADO (EC): {accion} - {detalle}")
    except Exception as e:
        print(f"‚ùå Error en auditoria: {e}")
    finally:
        if conn: conn.close()

def enviar_correo_real(destinatario: str, asunto: str, mensaje: str, html: bool = False) -> bool:
    import requests # Aseg√∫rate de poner 'requests' en tu requirements.txt
    
    # 1. Tu API KEY de Resend
    API_KEY = "re_UgHvnVwc_GoohB6so8khU8mCBmLJB1bzJ" 
    
    try:
        url = "https://api.resend.com/emails"
        payload = {
            # 2. AQU√ç PONES TU DOMINIO
            "from": "Soporte Despertar <soporte@uepdespertar-evidencias.work>",
            "to": [destinatario],
            "subject": asunto,
            "html": mensaje if html else f"<p>{mensaje}</p>"
        }
        headers = {
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json"
        }
        
        response = requests.post(url, json=payload, headers=headers)
        
        if response.status_code in [200, 201]:
            print(f"‚úÖ Correo enviado desde el dominio a {destinatario}")
            return True
        else:
            print(f"‚ùå Error Resend: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå Error de conexi√≥n: {e}")
        return False
    
def calcular_hash(ruta: str) -> str:
    """Calcula hash SHA256 de un archivo"""
    h = hashlib.sha256()
    with open(ruta, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            h.update(chunk)
    return h.hexdigest()

def obtener_tamanio_archivo_kb(ruta: str) -> float:
    """Obtiene el tama√±o de un archivo en KB"""
    try:
        return os.path.getsize(ruta) / 1024
    except:
        return 0

def optimizar_sistema_db():
    """Ejecuta mantenimiento VACUUM en Supabase"""
    try:
        conn = get_db_connection()
        # En Postgres, VACUUM no puede ejecutarse dentro de una transacci√≥n normal
        conn.autocommit = True 
        with conn.cursor() as c:
            c.execute("VACUUM")
            c.execute("ANALYZE")
        conn.close()
        print("‚úÖ Sistema optimizado (VACUUM ejecutado en Supabase)")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Alerta menor: No se pudo optimizar DB: {e}")
        return False

# --- REEMPLAZA TU FUNCI√ìN 'identificar_rostro_aws' POR ESTA ---
def preparar_imagen_aws(ruta_imagen):
    """
    1. Lee la imagen (soporta AVIF si las librer√≠as est√°n instaladas).
    2. La convierte SIEMPRE a JPG (compatible con AWS).
    3. Comprime si pesa m√°s de 5MB.
    """
    MAX_BYTES = 5242880 # 5 MB
    
    try:
        # Intentamos leer con OpenCV
        img = cv2.imread(ruta_imagen)
        
        # Si OpenCV falla (com√∫n con AVIF antiguos), intentamos con PIL (si est√° instalado)
        if img is None:
            try:
                from PIL import Image
                import numpy as np
                pil_img = Image.open(ruta_imagen).convert('RGB')
                img = np.array(pil_img) 
                # Convertir RGB (PIL) a BGR (OpenCV)
                img = img[:, :, ::-1].copy() 
            except ImportError:
                pass # Si no hay PIL, nos rendimos

        # Si despu√©s de todo no pudimos leer la imagen...
        if img is None:
            # Si es AVIF y no pudimos leerla, NO podemos mandarla cruda a AWS. Retornamos None o error.
            if ruta_imagen.lower().endswith('.avif'):
                print("‚ö†Ô∏è Error: No se pudo decodificar AVIF. Instala 'pillow-avif-plugin'.")
                return None
            # Si es JPG/PNG, mandamos crudo
            with open(ruta_imagen, 'rb') as f: return f.read()

        # COMPRESI√ìN / CONVERSI√ìN A JPG
        # Esto transforma el AVIF/WEBP/PNG a un JPG est√°ndar que AWS s√≠ entiende
        _, buffer = cv2.imencode('.jpg', img, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
        return buffer.tobytes()
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error preparando imagen AWS: {e}")
        with open(ruta_imagen, 'rb') as f: return f.read()

def identificar_varios_rostros_aws(imagen_path: str, confidence_threshold: float = 70.0) -> List[str]:
    if not rekog: return []
    cedulas_encontradas = set()
    
    try:
        # 1. Cargar imagen con OpenCV (para recortes)
        img = cv2.imread(imagen_path)
        if img is None: return []
        height, width, _ = img.shape
        
        # 2. Obtener BYTES SEGUROS (Comprimidos si es necesario)
        image_bytes = preparar_imagen_aws(imagen_path)
            
        # 3. Detectar caras en la imagen (usando los bytes seguros)
        response_detect = rekog.detect_faces(Image={'Bytes': image_bytes})
        
        if not response_detect['FaceDetails']: return []

        # 4. Procesar cada cara
        for faceDetail in response_detect['FaceDetails']:
            bbox = faceDetail['BoundingBox']
            x = int(bbox['Left'] * width)
            y = int(bbox['Top'] * height)
            w = int(bbox['Width'] * width)
            h = int(bbox['Height'] * height)
            
            x, y = max(0, x), max(0, y)
            w, h = min(width - x, w), min(height - y, h)
            face_crop = img[y:y+h, x:x+w]
            if face_crop.size == 0: continue

            _, buffer = cv2.imencode('.jpg', face_crop)
            crop_bytes = buffer.tobytes()
            
            try:
                # AQU√ç EST√Å EL CAMBIO CLAVE: MaxFaces=5 (Antes era 1)
                # Esto permite que si dos usuarios tienen la misma cara, AWS devuelva a ambos.
                search_res = rekog.search_faces_by_image(
                    CollectionId=COLLECTION_ID,
                    Image={'Bytes': crop_bytes},
                    MaxFaces=5, 
                    FaceMatchThreshold=confidence_threshold
                )
                
                # Ahora iteramos sobre TODAS las coincidencias encontradas para esa cara
                for match in search_res['FaceMatches']:
                    ced = match['Face'].get('ExternalImageId')
                    if ced: cedulas_encontradas.add(ced)
                    
            except: continue 

        return list(cedulas_encontradas)
    except Exception as e:
        print(f"Error IA Rostros: {e}")
        return []
    

# --- REEMPLAZA TU FUNCI√ìN 'buscar_estudiantes_por_texto' POR ESTA VERSI√ìN CON DEBUG VISUAL ---

def buscar_estudiantes_por_texto(imagen_path: str, cursor): # <--- Ahora recibe un cursor
    if not rekog: return [], []
    cedulas_encontradas = set()
    texto_leido_debug = []
    
    try:
        image_bytes = preparar_imagen_aws(imagen_path)
        response = rekog.detect_text(Image={'Bytes': image_bytes})
        
        palabras_sueltas = [t['DetectedText'].lower() for t in response.get('TextDetections', []) if t['Type'] == 'WORD']
        
        # --- USAMOS EL CURSOR 'cursor' RECIBIDO ---
        cursor.execute("SELECT Nombre, Apellido, CI FROM Usuarios WHERE Tipo=1")
        estudiantes = cursor.fetchall()
        
        for est in estudiantes:
            nombre_db = est.get('Nombre') or est.get('nombre')
            apellido_db = est.get('Apellido') or est.get('apellido')
            ci_db = est.get('CI') or est.get('ci')
            
            # L√≥gica de comparaci√≥n...
            partes = nombre_db.lower().split() + apellido_db.lower().split()
            piezas_validas = {p for p in partes if len(p) > 2}
            
            coincidencias = 0
            for pieza in piezas_validas:
                if difflib.get_close_matches(pieza, palabras_sueltas, n=1, cutoff=0.8):
                    coincidencias += 1
            
            if coincidencias >= 2:
                cedulas_encontradas.add(ci_db)

    except Exception as e:
        print(f"‚ö†Ô∏è Error OCR: {e}")
        
    return list(cedulas_encontradas), texto_leido_debug

def coincidencia_difusa(partes_buscadas, palabras_en_imagen, umbral):
    """
    Verifica si TODAS las 'partes_buscadas' est√°n presentes en 'palabras_en_imagen'
    con cierta tolerancia a errores (umbral).
    """
    aciertos = 0
    # Usamos una copia para no afectar b√∫squedas de otros estudiantes
    pool = palabras_en_imagen.copy()
    
    for parte in partes_buscadas:
        # Busca la palabra m√°s parecida en la 'bolsa' de palabras de la imagen
        matches = difflib.get_close_matches(parte, pool, n=1, cutoff=umbral)
        if matches:
            aciertos += 1
            # Opcional: pool.remove(matches[0]) si quisieras evitar repetir palabras
            
    # √âxito si encontramos TODAS las partes (Ej: Encontr√≥ "Juan" Y encontr√≥ "Perez")
    return aciertos == len(partes_buscadas)

# Funci√≥n auxiliar por si no la tienes
def calcular_hash(file_path):
    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()
    
def calcular_estadisticas_reales() -> dict:
    """Calcula estad√≠sticas REALES filtrando SOLO ESTUDIANTES (Ignora Admins)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # 1. Contar usuarios activos (Estudiantes Tipo 1 activos)
        c.execute("SELECT COUNT(*) as total FROM Usuarios WHERE Tipo = 1 AND Activo = 1")
        fila_usuarios = c.fetchone()
        usuarios_activos = fila_usuarios['total'] if fila_usuarios else 0
        
        # 2. Contar evidencias (SOLO DE ESTUDIANTES - JOIN CON USUARIOS)
        # Esto excluye autom√°ticamente las fotos subidas al perfil del Admin
        c.execute("""
            SELECT COUNT(e.id) as total 
            FROM Evidencias e
            JOIN Usuarios u ON e.CI_Estudiante = u.CI
            WHERE u.Tipo = 1
        """)
        fila_evidencias = c.fetchone()
        total_evidencias = fila_evidencias['total'] if fila_evidencias else 0
        
        # 3. Sumar peso (SOLO DE ESTUDIANTES)
        c.execute("""
            SELECT SUM(e.Tamanio_KB) as peso_total 
            FROM Evidencias e
            JOIN Usuarios u ON e.CI_Estudiante = u.CI
            WHERE u.Tipo = 1
        """)
        fila_peso = c.fetchone()
        resultado_kb = fila_peso['peso_total'] if fila_peso and fila_peso['peso_total'] else 0
        
        # L√≥gica de estimaci√≥n
        total_kb = resultado_kb
        nota_almacenamiento = "Calculado exacto (Solo Estudiantes)"
        
        # Correcci√≥n para cuando hay archivos pero pesan 0
        if total_kb == 0 and total_evidencias > 0:
            total_kb = total_evidencias * 2500 

        tamanio_total_mb = total_kb / 1024
        
        # Costos (Basados solo en consumo de estudiantes)
        costo_rekognition = (total_evidencias / 1000) * 1.0
        costo_almacenamiento = (tamanio_total_mb / 1024) * 0.023
        
        # 4. Solicitudes pendientes
        c.execute("SELECT COUNT(*) as total FROM Solicitudes WHERE Estado = 'PENDIENTE'")
        fila_solicitudes = c.fetchone()
        solicitudes_pendientes = fila_solicitudes['total'] if fila_solicitudes else 0
        
        conn.close()
        
        return {
            "usuarios_activos": usuarios_activos,
            "total_evidencias": total_evidencias,
            "almacenamiento_mb": round(tamanio_total_mb, 2),
            "almacenamiento_gb": round(tamanio_total_mb / 1024, 4),
            "costo_estimado_usd": {
                "rekognition": round(costo_rekognition, 2),
                "almacenamiento": round(costo_almacenamiento, 4),
                "total": round(costo_rekognition + costo_almacenamiento, 2)
            },
            "solicitudes_pendientes": solicitudes_pendientes,
            "nota": nota_almacenamiento
        }
    except Exception as e:
        print(f"Error estadisticas: {e}")
        return {
            "usuarios_activos": 0, "total_evidencias": 0, 
            "almacenamiento_mb": 0, "almacenamiento_gb": 0,
            "solicitudes_pendientes": 0
        }

# =========================================================================
# 4. CONFIGURACI√ìN FASTAPI
# =========================================================================
app = FastAPI(title="Sistema Educativo Despertar", version="7.0")

# Lista de dominios permitidos para conectar con el backend
origins = [
    "https://www.uepdespertar-evidencias.work",  # Tu nuevo dominio principal
    "https://uepdespertar-evidencias.work",      # Versi√≥n sin www
    "https://proyecto-grado-karlos.vercel.app",  # Tu dominio antiguo de Vercel
    "http://localhost:5500",                     # Pruebas locales
    "http://127.0.0.1:5500"                      # Pruebas locales
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins, # <--- Usamos la lista de arriba
    allow_credentials=True,
    allow_methods=["*"],   # Permite GET, POST, DELETE, etc.
    allow_headers=["*"],   # Permite todos los encabezados
)

@app.on_event("startup")
async def startup_event():
    """
    V8.1 - INICIO LIMPIO CORREGIDO
    Se cambi√≥ 'init_db' por 'init_db_completa' para que coincida con tu c√≥digo.
    """
    print("\n" + "="*50)
    print("üöÄ INICIANDO SERVIDOR - MODO PRODUCCI√ìN LIMPIO")
    print("="*50)
    
    try:
        # ‚úÖ CORRECCI√ìN: El nombre correcto de tu funci√≥n es init_db_completa
        init_db_completa() 
        print("‚úÖ Base de datos conectada y estructura verificada.")

        # Protocolo de mantenimiento silenciado para evitar restauraciones autom√°ticas
        
        print("‚úÖ Servidor listo. No se restauraron evidencias antiguas.")
        print("="*50 + "\n")

    except Exception as e:
        print(f"‚ùå Error cr√≠tico en el inicio: {e}")

# =========================================================================
# 5. ENDPOINTS PRINCIPALES
# =========================================================================

@app.get("/")
def home():
    """Endpoint ra√≠z del sistema"""
    return {
        "status": "online", 
        "backend": "Sistema Educativo Despertar V7.0",
        "cors_enabled": True,
        "zona_horaria": "America/Guayaquil (UTC-5)",
        "timestamp": ahora_ecuador().isoformat()
    }

@app.get("/health")
async def health_check():
    """Verifica salud del sistema"""
    try:
        conn = get_db_connection()
        conn.execute("SELECT 1")
        
        # Verificar tablas principales
        c = conn.cursor()
        c.execute("SELECT COUNT(*) as count FROM Usuarios")
        usuarios = c.fetchone()['count']
        
        c.execute("SELECT COUNT(*) as count FROM Evidencias")
        evidencias = c.fetchone()['count']
        
        conn.close()
        
        return JSONResponse(content={
            "status": "healthy",
            "timestamp": ahora_ecuador().isoformat(),
            "database": "connected",
            "estadisticas": {
                "usuarios": usuarios,
                "evidencias": evidencias
            },
            "aws_rekognition": "available" if rekog else "unavailable",
            "s3_storage": "available" if s3_client else "unavailable"
        })
    except Exception as e:
        return JSONResponse(content={
            "status": "unhealthy",
            "error": str(e)
        })

# =========================================================================
# 6. ENDPOINTS DE AUTENTICACI√ìN
# =========================================================================

class TemaRequest(BaseModel):
    cedula: str
    tema: int # 0 = Claro, 1 = Oscuro

@app.post("/actualizar_tema")
async def actualizar_tema(datos: TemaRequest):
    """Guarda si el usuario prefiere modo oscuro o claro"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        c.execute("UPDATE Usuarios SET Tema = %s WHERE CI = %s", (datos.tema, datos.cedula))
        conn.commit()
        conn.close()
        return {"status": "ok", "mensaje": "Tema actualizado"}
    except Exception as e:
        return {"status": "error", "mensaje": str(e)}

@app.post("/iniciar_sesion")
async def iniciar_sesion(cedula: str = Form(...), contrasena: str = Form(...)):
    """Inicio de sesi√≥n corregido que incluye el TEMA del usuario"""
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        c.execute("SELECT * FROM Usuarios WHERE CI = %s", (cedula.strip(),))
        u = c.fetchone()
        
        pass_db = u.get('password') or u.get('Password') if u else None
        
        if u and pass_db == contrasena.strip():
            # Log de auditor√≠a
            nombre_completo = f"{u.get('Nombre') or u.get('nombre')} {u.get('Apellido') or u.get('apellido')}"
            rol_num = u.get('Tipo') if u.get('Tipo') is not None else u.get('tipo')
            rol_texto = "Administrador" if rol_num == 0 else "Estudiante"
            
            registrar_auditoria("INICIO_SESION", f"Ingreso exitoso ({rol_texto})", nombre_completo)
            
            # Datos para la p√°gina web
            datos_para_front = {
                "id": u.get('id') or u.get('ID'),
                "cedula": u.get('ci') or u.get('CI'),
                "nombre": u.get('nombre') or u.get('Nombre'),
                "apellido": u.get('apellido') or u.get('Apellido'),
                "url_foto": u.get('url_foto') or u.get('Url_Foto') or "",
                "email": u.get('email') or u.get('Email') or "",
                "tipo": rol_num,
                "tema": u.get('Tema') or u.get('tema') or 0, # <--- ¬°AQU√ç VA EL TEMA!
                "tutorial_visto": u.get('tutorial_visto') or u.get('TutorialVisto') or 0
            }
            
            return JSONResponse({"autenticado": True, "datos": jsonable_encoder(datos_para_front)})
        
        return JSONResponse({"autenticado": False, "mensaje": "C√©dula o contrase√±a incorrectos."})
    except Exception as e:
        print(f"‚ùå Error login: {e}")
        return JSONResponse({"autenticado": False, "mensaje": str(e)})
    finally:
        if conn: conn.close()

@app.post("/buscar_estudiante")
async def buscar_estudiante(cedula: str = Form(...)):
    """
    Versi√≥n √önica y Corregida:
    Trae los datos del estudiante Y su galer√≠a de evidencias.
    """
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # Usamos SELECT * para asegurar que traiga la columna 'Tema' nueva
        c.execute("SELECT * FROM Usuarios WHERE CI = %s", (cedula.strip(),))
        u = c.fetchone()
        
        if u:
            # Construir respuesta asegurando que 'tema' vaya en los datos
            datos = {
                "id": u.get('id') or u.get('ID'),
                "cedula": u.get('ci') or u.get('CI'),
                "nombre": u.get('nombre') or u.get('Nombre'),
                "apellido": u.get('apellido') or u.get('Apellido'),
                "url_foto": u.get('url_foto') or u.get('Url_Foto') or "",
                "email": u.get('email') or u.get('Email') or "",
                "tipo": u.get('tipo') or u.get('Tipo'),
                "tema": u.get('Tema') or u.get('tema') or 0, # <--- ESTO ES CRUCIAL
                "galeria": [] # Se llenar√° abajo
            }
            
            # Buscar evidencias (galer√≠a)
            c.execute("SELECT * FROM Evidencias WHERE Cedula_Estudiante = %s ORDER BY Fecha_Subida DESC", (cedula.strip(),))
            evidencias = c.fetchall()
            if evidencias:
                datos['galeria'] = [dict(row) for row in evidencias]

            return JSONResponse({"status": "ok", "encontrado": True, "datos": jsonable_encoder(datos)})
        
        # 3. Empaquetamos todo (jsonable_encoder arregla el error de las fechas)
        datos_completos = jsonable_encoder(user)
        datos_completos["galeria"] = jsonable_encoder(evidencias)
        
        # Compatibilidad de nombres para perfil.html
        datos_completos["Url_Foto"] = user.get('foto') or user.get('Foto') or user.get('url_foto')
        
        return JSONResponse({"status": "ok", "datos": datos_completos})
        
    except Exception as e:
        print(f"‚ùå Error en buscar_estudiante: {e}")
        return JSONResponse({"status": "error", "mensaje": str(e)})
    finally:
        if conn: conn.close()
    
# =========================================================================
# 7. ENDPOINTS DE GESTI√ìN DE USUARIOS
# =========================================================================

@app.post("/registrar_usuario")
async def registrar_usuario(
    nombre: str = Form(...),
    apellido: str = Form(...),
    cedula: str = Form(...),
    contrasena: str = Form(...),
    tipo_usuario: int = Form(...),
    email: Optional[str] = Form(None),
    telefono: Optional[str] = Form(None),
    foto: UploadFile = File(...)
):
    """Registra un nuevo usuario con zona horaria Ecuador"""
    try:
        cedula = cedula.strip()
        contrasena = contrasena.strip()
        
        # Validaciones b√°sicas
        if not cedula or not contrasena:
            return JSONResponse(content={
                "error": "La c√©dula y contrase√±a son requeridas"
            })
        
        conn = get_db_connection()
        c = conn.cursor()
        
        # Verificar si usuario ya existe
        c.execute("SELECT CI FROM Usuarios WHERE CI=%s", (cedula,))
        if c.fetchone():
            conn.close()
            return JSONResponse(content={
                "error": "Usuario ya existe en el sistema"
            })
        
        # Manejar archivo de foto
        temp_dir = tempfile.mkdtemp()
        foto_path = os.path.join(temp_dir, foto.filename)
        
        with open(foto_path, "wb") as f:
            shutil.copyfileobj(foto.file, f)
        
        # Subir a almacenamiento
        nombre_nube = f"perfiles/{cedula}_{int(ahora_ecuador().timestamp())}_{foto.filename}"
        url_foto = ""
        
        if s3_client:
            try:
                s3_client.upload_file(
                    foto_path, 
                    BUCKET_NAME, 
                    nombre_nube,
                    ExtraArgs={'ACL': 'public-read'}
                )
                url_foto = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{nombre_nube}"
                print(f"‚úÖ Foto subida a S3: {url_foto}")
            except Exception as e:
                print(f"‚ö†Ô∏è Error subiendo a S3: {e}")
                url_foto = f"/local/perfiles/{foto.filename}"
        else:
            url_foto = f"/local/perfiles/{foto.filename}"
        
        # Insertar usuario con fecha de Ecuador
        fecha_registro = ahora_ecuador()
        
        # üëá CAMBIO CLAVE: Convertimos la fecha a texto simple para evitar errores
        fecha_str = fecha_registro.strftime("%Y-%m-%d %H:%M:%S") 
        
        c.execute("""
            INSERT INTO Usuarios 
            (Nombre, Apellido, CI, Password, Tipo, Foto, Activo, Email, Telefono, Fecha_Registro)
            VALUES (%s,%s,%s,%s,%s,%s,1,%s,%s,%s)
        """, (
            nombre.strip(),
            apellido.strip(),
            cedula,
            contrasena,
            tipo_usuario,
            url_foto,
            email,
            telefono,
            fecha_str  # <--- Usamos la versi√≥n texto, no el objeto fecha
        ))
        
        # Si es estudiante, agregar a colecci√≥n de rostros AWS
        if tipo_usuario == 1 and rekog:
            try:
                with open(foto_path, 'rb') as image_file:
                    image_bytes = image_file.read()
                
                rekog.index_faces(
                    CollectionId=COLLECTION_ID,
                    Image={'Bytes': image_bytes},
                    ExternalImageId=cedula,
                    MaxFaces=1,
                    QualityFilter='AUTO'
                )
                print(f"‚úÖ Rostro indexado en AWS para estudiante {cedula}")
            except Exception as e:
                print(f"‚ö†Ô∏è Error indexando rostro en AWS: {e}")
        
        conn.commit()
        conn.close()
        
        # Limpiar archivos temporales
        shutil.rmtree(temp_dir)
        
        tipo_txt = "Administrador" if int(tipo_usuario) == 0 else "Estudiante"
        registrar_auditoria(
            "REGISTRO_USUARIO", 
            f"El Admin cre√≥ al usuario: {nombre} {apellido} (CI: {cedula}) como {tipo_txt}",
            "Administrador"
        )

    except Exception as e:
        print(f"‚ùå Error en registrar_usuario: {e}")
        return JSONResponse(content={"error": str(e)})
    
@app.post("/cambiar_estado_usuario")
async def cambiar_estado_usuario(datos: EstadoUsuarioRequest):
    """Activa/desactiva un usuario en un solo paso (Optimizado)"""
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor) 
        
        fecha_desactivacion = ahora_ecuador() if datos.activo == 0 else None
        
        # ‚úÖ OPTIMIZACI√ìN: 'RETURNING' nos devuelve los datos sin hacer un segundo SELECT
        c.execute("""
            UPDATE Usuarios 
            SET Activo = %s, Fecha_Desactivacion = %s
            WHERE CI = %s
            RETURNING Nombre, Apellido
        """, (datos.activo, fecha_desactivacion, datos.cedula))
        
        user = c.fetchone()
        conn.commit()
        
        # L√≥gica de reporte
        nombre = f"{user['nombre']} {user['apellido']}" if user else "Usuario"
        estado_texto = "activada" if datos.activo == 1 else "desactivada"
        
        registrar_auditoria("CAMBIO_ESTADO", f"Cuenta de {nombre} {estado_texto}", "Admin")
        
        return JSONResponse(content={"mensaje": "OK", "nombre": nombre})
        
    except Exception as e:
        if conn: conn.rollback()
        return JSONResponse(content={"error": str(e)}, status_code=500)
    finally:
        if conn: conn.close()


@app.delete("/eliminar_usuario/{cedula}")
async def eliminar_usuario(cedula: str):
    """Elimina usuario y todos sus datos (Blindado contra errores de may√∫sculas)"""
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. PRIMERO: Obtener y borrar evidencias asociadas (Nube + BD)
        c.execute("SELECT Url_Archivo FROM Evidencias WHERE CI_Estudiante = %s", (cedula,))
        evidencias = c.fetchall()
        
        if s3_client and BUCKET_NAME:
            for ev in evidencias:
                # üõ°Ô∏è CORRECCI√ìN: Buscamos URL con seguridad (May√∫s/Min√∫s)
                url = ev.get('Url_Archivo') or ev.get('url_archivo')
                
                if url and "backblazeb2.com" in url:
                    try:
                        partes = url.split(f"/file/{BUCKET_NAME}/")
                        if len(partes) > 1:
                            s3_client.delete_object(Bucket=BUCKET_NAME, Key=partes[1])
                    except Exception as e:
                        print(f"‚ö†Ô∏è No se pudo borrar archivo B2: {e}")

        # Borrar registros de evidencias
        c.execute("DELETE FROM Evidencias WHERE CI_Estudiante = %s", (cedula,))
        
        # 2. SEGUNDO: Obtener y borrar foto de perfil (Nube)
        c.execute("SELECT Foto FROM Usuarios WHERE CI = %s", (cedula,))
        usuario = c.fetchone()
        
        # üõ°Ô∏è CORRECCI√ìN: Buscamos Foto con seguridad
        if usuario:
            url_foto = usuario.get('Foto') or usuario.get('foto')
            
            if url_foto and s3_client and BUCKET_NAME and "backblazeb2.com" in url_foto:
                try:
                    partes = url_foto.split(f"/file/{BUCKET_NAME}/")
                    if len(partes) > 1:
                        s3_client.delete_object(Bucket=BUCKET_NAME, Key=partes[1])
                except Exception as e:
                     print(f"‚ö†Ô∏è No se pudo borrar foto perfil B2: {e}")

        # 3. TERCERO: Borrar el usuario
        c.execute("DELETE FROM Usuarios WHERE CI = %s", (cedula,))
        
        conn.commit()
        conn.close()
        
        return JSONResponse({"mensaje": "Usuario y todos sus datos eliminados correctamente"})
        
    except Exception as e:
        print(f"‚ùå Error eliminando usuario completo: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
# =========================================================================
# 8. ENDPOINTS DE EVIDENCIAS
# =========================================================================

def garantizar_limite_storage(ruta_archivo, limite_mb=1000):
    """
    Si el archivo supera el limite_mb (ej: 1GB), lo comprime para ahorrar espacio.
    Si no lo supera, lo deja intacto (Calidad Original).
    """
    try:
        peso_actual_mb = os.path.getsize(ruta_archivo) / (1024 * 1024)
        
        # CASO 1: El archivo est√° dentro del l√≠mite (Ej: 500MB) -> NO TOCAR
        if peso_actual_mb <= limite_mb:
            return ruta_archivo # Devolvemos la ruta original
            
        # CASO 2: El archivo es gigante (Ej: 2GB) -> COMPRIMIR
        print(f"‚ö†Ô∏è Archivo gigante ({peso_actual_mb:.2f} MB). Comprimiendo para cumplir cuota de 1GB...")
        
        # Nombre para el archivo comprimido
        dir_name = os.path.dirname(ruta_archivo)
        base_name = os.path.basename(ruta_archivo)
        ruta_comprimida = os.path.join(dir_name, f"compressed_{base_name}")
        
        # Detectar si es VIDEO
        ext = os.path.splitext(ruta_archivo)[1].lower()
        if ext in ['.mp4', '.avi', '.mov', '.mkv']:
            # Usamos OpenCV para reducir resoluci√≥n y bitrate
            cap = cv2.VideoCapture(ruta_archivo)
            
            # Calculamos nueva resoluci√≥n (HD 720p suele ser suficiente y ligero)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            # Si es 4K, lo bajamos a 720p. Si es menor, lo bajamos un 30%
            scale = 0.5 if width > 1920 else 0.7
            new_w, new_h = int(width * scale), int(height * scale)
            
            # Configurar el escritor de video
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(ruta_comprimida, fourcc, 24, (new_w, new_h))
            
            while True:
                ret, frame = cap.read()
                if not ret: break
                # Redimensionar frame
                frame_b = cv2.resize(frame, (new_w, new_h))
                out.write(frame_b)
                
            cap.release()
            out.release()
            
            # Reemplazar archivo original con el comprimido
            if os.path.exists(ruta_comprimida):
                shutil.move(ruta_comprimida, ruta_archivo) # Sobrescribimos el original
                nuevo_peso = os.path.getsize(ruta_archivo) / (1024 * 1024)
                print(f"‚úÖ Compresi√≥n exitosa. Nuevo peso: {nuevo_peso:.2f} MB")
                return ruta_archivo
                
    except Exception as e:
        print(f"‚ö†Ô∏è Error intentando comprimir video storage: {e}")
    
    # Si algo falla o no es video, devolvemos el original
    return ruta_archivo

@app.post("/subir_evidencia_ia")
async def subir_evidencia_ia(archivo: UploadFile = File(...)):
    temp_dir = None
    try:
        # 1. Preparaci√≥n de archivo y c√°lculo de Hash inicial
        temp_dir = tempfile.mkdtemp()
        path = os.path.join(temp_dir, archivo.filename)
        with open(path, "wb") as f: shutil.copyfileobj(archivo.file, f)
        file_hash = calcular_hash(path)
        
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)

        # 2. Identificaci√≥n de tipo y procesamiento con IA (Rostros y Texto)
        ext = os.path.splitext(archivo.filename)[1].lower()
        es_imagen = ext in ['.jpg', '.jpeg', '.png', '.bmp', '.webp', '.avif']
        es_video = ext in ['.mp4', '.avi', '.mov', '.mkv']
        tipo_archivo = "video" if es_video else ("imagen" if es_imagen else "documento")
        
        cedulas_detectadas = set() 
        
        if rekog:
            if es_imagen:
                # Mantiene Rostros + Texto (OCR)
                rostros = identificar_varios_rostros_aws(path)
                cedulas_detectadas.update(rostros)
                textos_ceds, _ = buscar_estudiantes_por_texto(path, c) 
                cedulas_detectadas.update(textos_ceds)
            elif es_video:
                # Mantiene an√°lisis de fotogramas de video con OpenCV
                cap = cv2.VideoCapture(path)
                frame_count = 0
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret or frame_count > 1800: break
                    if frame_count % 60 == 0:
                        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp:
                            _, buffer = cv2.imencode('.jpg', frame)
                            tmp.write(buffer.tobytes())
                            tmp_path = tmp.name
                        rostros_f = identificar_varios_rostros_aws(tmp_path)
                        cedulas_detectadas.update(rostros_f)
                        if os.path.exists(tmp_path): os.remove(tmp_path)
                    frame_count += 1
                cap.release()

        # 3. Verificar existencia f√≠sica (Para no resubir a Backblaze innecesariamente)
        c.execute("SELECT Url_Archivo, Tamanio_KB FROM Evidencias WHERE Hash = %s LIMIT 1", (file_hash,))
        evidencia_existente = c.fetchone()
        
        url_final = ""
        tamanio_kb = 0
        
        if evidencia_existente:
            # Si el archivo ya est√° en el sistema, usamos su URL actual
            url_final = evidencia_existente.get('Url_Archivo') or evidencia_existente.get('url_archivo')
            tamanio_kb = evidencia_existente.get('Tamanio_KB') or evidencia_existente.get('tamanio_kb') or 0
        else:
            # Si es nuevo, subimos a Backblaze
            path_procesado = garantizar_limite_storage(path)
            tamanio_kb = os.path.getsize(path_procesado) / 1024
            url_final = f"/local/{archivo.filename}"
            if s3_client:
                try:
                    nube = f"evidencias/{int(ahora_ecuador().timestamp())}_{archivo.filename}"
                    s3_client.upload_file(path_procesado, BUCKET_NAME, nube, ExtraArgs={'ACL':'public-read'})
                    url_final = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{nube}"
                except: pass

        # 4. ASIGNACI√ìN INTELIGENTE Y REPORTE DETALLADO (Lo que solicitaste)
        asignados_nuevos = []
        ya_tenian = []
        
        if cedulas_detectadas:
            for ced in cedulas_detectadas:
                c.execute("SELECT Nombre, Apellido, Tipo FROM Usuarios WHERE CI=%s", (ced,))
                u = c.fetchone()
                
                if u and (u.get('Tipo') or u.get('tipo')) == 1:
                    nombre_completo = f"{u.get('Nombre') or u.get('nombre')} {u.get('Apellido') or u.get('apellido')}"
                    
                    # Verificamos si ESE estudiante espec√≠fico ya tiene la evidencia
                    c.execute("SELECT id FROM Evidencias WHERE CI_Estudiante = %s AND Hash = %s", (ced, file_hash))
                    if c.fetchone():
                        ya_tenian.append(nombre_completo)
                    else:
                        # Se asigna solo al perfil que no lo tiene
                        c.execute("""
                            INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente) 
                            VALUES (%s, %s, %s, 1, %s, %s, 1)
                        """, (ced, url_final, file_hash, tipo_archivo, tamanio_kb))
                        asignados_nuevos.append(nombre_completo)

            # Construcci√≥n del mensaje de respuesta inteligente
            msg_parts = []
            if asignados_nuevos:
                msg_parts.append(f"‚úÖ Evidencia asignada correctamente a: {', '.join(asignados_nuevos)}.")
            if ya_tenian:
                msg_parts.append(f"‚ÑπÔ∏è Omitiendo a: {', '.join(ya_tenian)} (ya la ten√≠an en su perfil).")
            
            # Caso donde todos ya la ten√≠an
            if not asignados_nuevos and ya_tenian:
                msg = f"‚ö†Ô∏è Todos los usuarios detectados ({', '.join(ya_tenian)}) ya contaban con esta evidencia."
                status = "alerta"
            else:
                msg = " ".join(msg_parts)
                status = "exito"
        else:
            # Nadie detectado -> Se guarda una sola vez en Pendientes si no existe ya
            c.execute("SELECT id FROM Evidencias WHERE Hash = %s AND CI_Estudiante = 'PENDIENTE'", (file_hash,))
            if not c.fetchone():
                c.execute("""
                    INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente) 
                    VALUES ('PENDIENTE', %s, %s, 1, %s, %s, 0)
                """, (url_final, file_hash, tipo_archivo, tamanio_kb))
                msg, status = "‚ö†Ô∏è No se identific√≥ a nadie. Guardado en 'Pendientes'.", "alerta"
            else:
                msg, status = "‚ö†Ô∏è El archivo ya se encuentra en la bandeja de 'Pendientes'.", "alerta"

            if asignados_nuevos:
                registrar_auditoria(
                    "SUBIDA_IA_AUTO", 
                    f"IA asign√≥ '{archivo.filename}' a: {', '.join(asignados_nuevos)}", 
                    "Sistema IA"
                )
            elif status == "alerta":
                 registrar_auditoria(
                    "SUBIDA_IA_PENDIENTE", 
                    f"Archivo '{archivo.filename}' enviado a Pendientes (Sin rostro/Duplicado)", 
                    "Sistema IA"
                )

        conn.commit()
        conn.close()
        if temp_dir: shutil.rmtree(temp_dir)
        
        return JSONResponse({"status": status, "mensaje": msg})

    except Exception as e:
        if temp_dir: shutil.rmtree(temp_dir)
        print(f"‚ùå Error IA: {e}")
        return JSONResponse({"status": "error", "mensaje": f"Error procesando {archivo.filename}: {str(e)}"})

@app.post("/subir_manual")
async def subir_manual(
    cedulas: str = Form(...), 
    archivo: UploadFile = File(...)
):
    """Sube una evidencia manualmente asignada a una lista de c√©dulas."""
    temp_dir = None
    conn = None
    try:
        # 1. Validar que existan c√©dulas
        lista_cedulas = [c.strip() for c in cedulas.split(",") if c.strip()]
        if not lista_cedulas:
            return JSONResponse(content={"status": "error", "mensaje": "Debe especificar al menos una c√©dula"})
        
        # 2. Guardar archivo temporalmente
        temp_dir = tempfile.mkdtemp()
        path = os.path.join(temp_dir, archivo.filename)
        with open(path, "wb") as f:
            shutil.copyfileobj(archivo.file, f)
        
        file_hash = calcular_hash(path)
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor) # Cursor obligatorio para Postgres
        
        # 3. Verificar si el archivo ya existe globalmente
        c.execute("SELECT id FROM Evidencias WHERE Hash = %s LIMIT 1", (file_hash,))
        if c.fetchone():
            return JSONResponse({"status": "error", "mensaje": "‚ö†Ô∏è ARCHIVO DUPLICADO: Esta evidencia ya existe en el sistema."})
            
        # 4. Procesar y subir a la nube
        path_procesado = garantizar_limite_storage(path)
        tamanio_kb = os.path.getsize(path_procesado) / 1024
        url_final = f"/local/{archivo.filename}"
        
        if s3_client:
            try:
                nombre_nube = f"evidencias/manual_{int(ahora_ecuador().timestamp())}_{archivo.filename}"
                s3_client.upload_file(path_procesado, BUCKET_NAME, nombre_nube, ExtraArgs={'ACL': 'public-read'})
                url_final = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{nombre_nube}"
            except: pass
            
        # 5. Asignar a cada estudiante de la lista
        count = 0
        for ced in lista_cedulas:
            c.execute("SELECT CI FROM Usuarios WHERE CI=%s", (ced,))
            if c.fetchone():
                c.execute("""
                    INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                    VALUES (%s, %s, %s, 1, 'documento', %s, 0)
                """, (ced, url_final, file_hash, tamanio_kb))
                count += 1
        
        conn.commit()
        registrar_auditoria(
            "SUBIDA_MANUAL", 
            f"El Admin subi√≥ el archivo '{archivo.filename}' y lo asign√≥ a {count} estudiantes.", 
            "Administrador"
        )

        return JSONResponse({"status": "ok", "mensaje": f"‚úÖ √âxito: Archivo asignado a {count} estudiantes."})

    except Exception as e:
        if conn: conn.rollback()
        print(f"‚ùå Error en subir_manual: {e}")
        return JSONResponse({"status": "error", "mensaje": str(e)})
    finally:
        if conn: conn.close()
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
    
# =========================================================================
# 9. ENDPOINTS DE BACKUP Y MANTENIMIENTO
# =========================================================================

@app.get("/crear_backup")
async def crear_backup():
    """Genera un archivo SQL con los datos REALES de Supabase"""
    try:
        conn = get_db_connection()
        
        # üî• ESTA ES LA L√çNEA M√ÅGICA QUE FALTABA
        # Desactivamos el "Modo Diccionario" para que nos de los valores reales (tuplas)
        conn.cursor_factory = None 
        
        c = conn.cursor()
        
        # Buffer en memoria
        output = io.StringIO()
        output.write(f"-- RESPALDO SISTEMA DESPERTAR --\n")
        output.write(f"-- FECHA: {ahora_ecuador()} --\n\n")
        
        tablas = ['Usuarios', 'Evidencias', 'Solicitudes', 'Auditoria', 'Metricas_Sistema']
        
        for tabla in tablas:
            try:
                # 1. Obtener datos
                c.execute(f"SELECT * FROM {tabla}")
                filas = c.fetchall()
                
                # 2. Obtener nombres de columnas
                if c.description:
                    columnas = [desc[0] for desc in c.description]
                    cols_str = ", ".join(columnas)
                    
                    output.write(f"\n-- DATA TABLE: {tabla} --\n")
                    
                    for fila in filas:
                        vals = []
                        # Ahora 'fila' es una lista de valores reales ('Juan', 'Perez'...), no de llaves.
                        for val in fila: 
                            if val is None:
                                vals.append("NULL")
                            elif isinstance(val, (int, float)):
                                vals.append(str(val))
                            elif isinstance(val, bool):
                                vals.append("TRUE" if val else "FALSE")
                            else:
                                # Escapar comillas simples para SQL
                                clean_val = str(val).replace("'", "''")
                                vals.append(f"'{clean_val}'")
                        
                        vals_str = ", ".join(vals)
                        output.write(f"INSERT INTO {tabla} ({cols_str}) VALUES ({vals_str});\n")
            except Exception as e_tab:
                output.write(f"-- Error exportando tabla {tabla}: {e_tab} --\n")

        conn.close()
        
        # Preparar descarga
        fecha_str = ahora_ecuador().strftime("%Y%m%d_%H%M")
        nombre_archivo = f"backup_completo_{fecha_str}.sql"
        
        mem_bytes = io.BytesIO(output.getvalue().encode('utf-8'))
        output.close()
        mem_bytes.seek(0)
        
        return StreamingResponse(
            mem_bytes,
            media_type="application/sql",
            headers={"Content-Disposition": f"attachment; filename={nombre_archivo}"}
        )
        
    except Exception as e:
        print(f"‚ùå Error backup SQL: {e}")
        return JSONResponse(content={"error": str(e)}, status_code=500)

@app.get("/descargar_multimedia_zip")
async def descargar_multimedia_zip():
    """
    Descarga evidencias S3 en un ZIP.
    V3.0 - FINAL: Sin reportes de texto y con nombres de archivo corregidos 
    para evitar errores de 'archivo da√±ado' en Windows/Word.
    """
    try:
        from urllib.parse import unquote
        import re # Importante para limpiar los nombres

        if not s3_client or not BUCKET_NAME:
            return JSONResponse({"error": "S3 no configurado"}, status_code=500)

        # 1. ESPIAR EL BUCKET (Mapa de Realidad)
        mapa_nube = {} 
        try:
            print("üïµÔ∏è Escaneando bucket real para descarga limpia...")
            paginator = s3_client.get_paginator('list_objects_v2')
            for page in paginator.paginate(Bucket=BUCKET_NAME):
                if 'Contents' in page:
                    for obj in page['Contents']:
                        full_key = obj['Key']
                        # Guardamos el nombre limpio para buscarlo despu√©s
                        nombre_limpio = full_key.split('/')[-1]
                        mapa_nube[nombre_limpio] = full_key
        except Exception as e_scan:
            return JSONResponse({"error": f"Error escaneando bucket: {str(e_scan)}"}, status_code=500)

        # 2. OBTENER DATOS DE LA BD
        conn = get_db_connection()
        conn.cursor_factory = None 
        c = conn.cursor()
        
        # Truco para leer r√°pido y luego cerrar
        conn.close()
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        c.execute("SELECT * FROM Evidencias")
        evidencias = c.fetchall()
        conn.close()

        if not evidencias:
            return JSONResponse({"error": "Tabla Evidencias vac√≠a"}, status_code=404)

        # 3. EMPAREJAR Y DESCARGAR (SIN LOGS DE TEXTO)
        zip_buffer = io.BytesIO()

        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            
            for ev in evidencias:
                url = ev.get('Url_Archivo') or ev.get('url_archivo') or ""
                id_ev = ev.get('id') or ev.get('ID')
                
                if not url: continue

                # Nombre original de la BD
                nombre_buscado = url.split('/')[-1]
                nombre_buscado = unquote(nombre_buscado)
                
                # BUSCAMOS EN EL MAPA REAL
                real_key = mapa_nube.get(nombre_buscado)
                
                if real_key:
                    try:
                        # Descargar desde la nube
                        file_obj = s3_client.get_object(Bucket=BUCKET_NAME, Key=real_key)
                        file_content = file_obj['Body'].read()
                        
                        # --- SANITIZACI√ìN DE NOMBRE (SOLUCI√ìN AL DOCX CORRUPTO) ---
                        # 1. Quitamos espacios y par√©ntesis que rompen los ZIPs a veces
                        nombre_seguro = re.sub(r'[^\w\.-]', '_', nombre_buscado)
                        
                        # 2. Construimos el nombre final dentro del ZIP
                        # Quedar√° algo como: evidencia_123_Proyecto_Grado_Oficial.docx
                        nombre_zip = f"evidencia_{id_ev}_{nombre_seguro}"
                        
                        # Guardar en ZIP
                        zip_file.writestr(nombre_zip, file_content)
                        
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error silencioso descargando {id_ev}: {e}")
                        # Ya no agregamos archivos .txt con errores al ZIP, solo lo saltamos.

        zip_buffer.seek(0)
        fecha_str = ahora_ecuador().strftime("%Y%m%d_%H%M")
        
        return StreamingResponse(
            zip_buffer, 
            media_type="application/zip", 
            headers={"Content-Disposition": f"attachment; filename=multimedia_limpio_{fecha_str}.zip"}
        )

    except Exception as e:
        print(f"‚ùå Error cr√≠tico multimedia: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)

from urllib.parse import urlparse
import re
import os

@app.post("/optimizar_sistema")
async def optimizar_sistema(tipo: str = "full"):
    """
    V6.0 - Mantenimiento Inteligente: 
    - Solo borra duplicados si pertenecen AL MISMO ESTUDIANTE.
    - Reporta espacio recuperado con precisi√≥n.
    """
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        mensaje_resultado = []
        
        # ==========================================
        # 1. ANALIZAR DUPLICADOS (POR ESTUDIANTE)
        # ==========================================
        if tipo == "duplicados" or tipo == "full":
            print("üßπ [1/4] Buscando duplicados por estudiante...")
            # Nueva l√≥gica: Agrupamos por Hash Y CI_Estudiante
            c.execute("""
                SELECT Hash, CI_Estudiante, COUNT(*) as cantidad 
                FROM Evidencias 
                WHERE Hash NOT IN ('PENDIENTE', '', 'RECUPERADO') 
                GROUP BY Hash, CI_Estudiante 
                HAVING COUNT(*) > 1
            """)
            grupos = c.fetchall()
            elim_dups = 0
            espacio_kb = 0
            
            for g in grupos:
                hash_val = g.get('Hash') or g.get('hash')
                cedula = g.get('CI_Estudiante') or g.get('ci_estudiante')
                
                # Obtenemos todas las copias de ESE estudiante para ESE archivo
                c.execute("""
                    SELECT id, Url_Archivo, Tamanio_KB 
                    FROM Evidencias 
                    WHERE Hash = %s AND CI_Estudiante = %s 
                    ORDER BY id ASC
                """, (hash_val, cedula))
                copias = c.fetchall()
                
                # Dejamos el primer registro (original del alumno) y borramos el resto
                for copia in copias[1:]:
                    copia_id = copia.get('id')
                    copia_kb = copia.get('Tamanio_KB') or copia.get('tamanio_kb') or 0
                    
                    # NOTA: No borramos de la nube aqu√≠ porque otros alumnos 
                    # podr√≠an estar usando el mismo archivo f√≠sico. Solo borramos el registro.
                    c.execute("DELETE FROM Evidencias WHERE id = %s", (copia_id,))
                    elim_dups += 1
                    espacio_kb += copia_kb
            
            if elim_dups > 0:
                mb_recuperados = round(espacio_kb / 1024, 2)
                mensaje_resultado.append(f"Se eliminaron {elim_dups} duplicados internos. Espacio optimizado: {mb_recuperados} MB.")
            elif tipo == "duplicados":
                mensaje_resultado.append("No se encontraron evidencias repetidas en un mismo perfil.")

        # ==========================================
        # 2. LIMPIAR HU√âRFANOS (VERSION PROTEGIDA)
        # ==========================================
        if tipo == "huerfanos" or tipo == "full":
            print("üëª [2/4] Analizando archivos fantasma con protecci√≥n...")
            c.execute("SELECT id, Url_Archivo FROM Evidencias")
            todas = c.fetchall()
            elim_huerfanos = 0
            
            for ev in todas:
                url = ev.get('Url_Archivo') or ev.get('url_archivo')
                ev_id = ev.get('id')
                
                # SEGURIDAD: Si la URL est√° vac√≠a, no la borramos por si es un error de carga
                if not url: continue 

                existe = True
                if url and "backblazeb2.com" in url and s3_client:
                    try:
                        key = url.split(f"/file/{BUCKET_NAME}/")[1]
                        # Verificamos existencia f√≠sica
                        s3_client.head_object(Bucket=BUCKET_NAME, Key=key)
                    except Exception as e:
                        # üõ°Ô∏è PROTECCI√ìN CR√çTICA: Solo borramos si el error es "404 Not Found"
                        # Si es un error de red o timeout (500, 403), NO BORRAMOS nada.
                        error_str = str(e)
                        if "404" in error_str or "Not Found" in error_str:
                            existe = False
                        else:
                            print(f"‚ö†Ô∏è Salto de seguridad: Error de conexi√≥n con la nube para ID {ev_id}. No se borrar√°.")
                            existe = True 
                
                if not existe:
                    c.execute("DELETE FROM Evidencias WHERE id = %s", (ev_id,))
                    elim_huerfanos += 1
            
            if elim_huerfanos > 0:
                mensaje_resultado.append(f"Limpieza completada: {elim_huerfanos} registros inexistentes eliminados.")

        # ==========================================
        # 3. AUTO-REASIGNACI√ìN (SOLO EN MODO FULL)
        # ==========================================
        if tipo == "full":
            print("üîÑ [3/4] Auto-reasignando evidencias perdidas...")
            c.execute("SELECT CI FROM Usuarios")
            cedulas = [u.get('CI') or u.get('ci') for u in c.fetchall()]
            
            c.execute("SELECT id, Url_Archivo, CI_Estudiante FROM Evidencias")
            evidencias = c.fetchall()
            reasignadas = 0
            
            for ev in evidencias:
                url = ev.get('Url_Archivo') or ev.get('url_archivo')
                ev_id = ev.get('id')
                ev_ci = ev.get('CI_Estudiante') or ev.get('ci_estudiante')
                
                for ci in cedulas:
                    if ci in url and len(ci) >= 10:
                        if ev_ci != ci:
                            c.execute("UPDATE Evidencias SET CI_Estudiante = %s WHERE id = %s", (ci, ev_id))
                            reasignadas += 1
                        break
            
            if reasignadas > 0:
                mensaje_resultado.append(f"Reasignadas {reasignadas} evidencias a sus due√±os correctos.")

        # ==========================================
        # 4. LIMPIAR CACH√â
        # ==========================================
        if tipo == "cache" or tipo == "full":
            print("üöÄ [4/4] Compactando base de datos...")
            conn.commit()
            conn.autocommit = True
            with conn.cursor() as c_vac:
                c_vac.execute("VACUUM")
                c_vac.execute("ANALYZE")
            if tipo == "cache":
                mensaje_resultado.append("Base de datos compactada y optimizada.")

        conn.close()
        
        texto_final = " ".join(mensaje_resultado) if mensaje_resultado else "Mantenimiento completado. Todo en orden."
        return JSONResponse({"status": "ok", "mensaje": texto_final})

    except Exception as e:
        print(f"‚ùå Error en mantenimiento: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
# =========================================================================
# 10. ENDPOINTS DE ESTAD√çSTICAS Y REPORTES
# =========================================================================

@app.get("/estadisticas_almacenamiento")
def estadisticas_almacenamiento():
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Contar Usuarios (Ignorando al admin tipo 0)
        c.execute("SELECT COUNT(*) FROM Usuarios WHERE Tipo != 0")
        usuarios_activos = c.fetchone()['count']
        
        # 2. Contar Evidencias Totales
        c.execute("SELECT COUNT(*) FROM Evidencias")
        total_evidencias = c.fetchone()['count']
        
        # 3. üî• SOLICITUDES PENDIENTES (CORREGIDO)
        # Usamos UPPER() para que 'Pendiente', 'pendiente' y 'PENDIENTE' cuenten igual.
        c.execute("SELECT COUNT(*) FROM Solicitudes WHERE UPPER(Estado) = 'PENDIENTE'")
        solicitudes_pendientes = c.fetchone()['count']

        # 4. üî• ALMACENAMIENTO (CORREGIDO - USANDO BASE DE DATOS)
        # Sumamos la columna Tamanio_KB. Si es null, devuelve 0.
        c.execute("SELECT COALESCE(SUM(Tamanio_KB), 0) as total_kb FROM Evidencias")
        total_kb = c.fetchone()['total_kb']
        
        # Convertimos KB a GB (1 GB = 1024*1024 KB)
        gb_usados = float(total_kb) / (1024 * 1024)
        
        # 5. Costos Estimados
        costo_storage = gb_usados * 0.023
        costo_ia = total_evidencias * 0.001
        
        return JSONResponse({
            "usuarios_activos": usuarios_activos,
            "total_evidencias": total_evidencias,
            "solicitudes_pendientes": solicitudes_pendientes, # Dato exacto
            "almacenamiento_gb": gb_usados,                   # Dato exacto
            "costo_estimado_usd": {
                "storage": costo_storage,
                "rekognition": costo_ia,
                "total": costo_storage + costo_ia
            }
        })
        
    except Exception as e:
        print(f"Error estadisticas: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    finally:
        if conn: conn.close()

@app.get("/datos_graficos_dashboard")
async def datos_graficos_dashboard():
    """Provee datos para gr√°ficos del dashboard (Versi√≥n PostgreSQL)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # 1. Evoluci√≥n de registros por mes (TO_CHAR en lugar de strftime)
        c.execute("""
            SELECT TO_CHAR(Fecha_Registro, 'YYYY-MM') as mes,
                   COUNT(*) as cantidad
            FROM Usuarios 
            WHERE Fecha_Registro IS NOT NULL
            GROUP BY mes
            ORDER BY mes DESC
            LIMIT 12
        """)
        evolucion_usuarios = [dict(row) for row in c.fetchall()]
        
        # 2. Distribuci√≥n de tipos de archivo
        c.execute("""
            SELECT Tipo_Archivo, COUNT(*) as cantidad
            FROM Evidencias
            GROUP BY Tipo_Archivo
        """)
        distribucion_archivos = [dict(row) for row in c.fetchall()]
        
        # 3. Solicitudes por estado
        c.execute("""
            SELECT Estado, COUNT(*) as cantidad
            FROM Solicitudes
            GROUP BY Estado
        """)
        solicitudes_estado = [dict(row) for row in c.fetchall()]
        
        # 4. Top 5 estudiantes
        c.execute("""
            SELECT u.Nombre, u.Apellido, u.CI, COUNT(e.id) as total
            FROM Usuarios u
            LEFT JOIN Evidencias e ON u.CI = e.CI_Estudiante
            WHERE u.Tipo = 1
            GROUP BY u.CI
            ORDER BY total DESC
            LIMIT 5
        """)
        top_estudiantes = [dict(row) for row in c.fetchall()]
        
        # 5. Actividad por hora (TO_CHAR y sintaxis de intervalo Postgres)
        c.execute("""
            SELECT TO_CHAR(Fecha, 'HH24') as hora,
                   COUNT(*) as actividades
            FROM Auditoria
            WHERE Fecha >= NOW() - INTERVAL '7 days'
            GROUP BY hora
            ORDER BY hora
        """)
        actividad_horaria = [dict(row) for row in c.fetchall()]
        
        conn.close()
        
        return JSONResponse(content={
            "evolucion_usuarios": evolucion_usuarios,
            "distribucion_archivos": distribucion_archivos,
            "solicitudes_estado": solicitudes_estado,
            "top_estudiantes": top_estudiantes,
            "actividad_horaria": actividad_horaria,
            "fecha_consulta": ahora_ecuador().isoformat()
        })
        
    except Exception as e:
        return JSONResponse(content={"error": str(e)})

# =========================================================================
# 11. ENDPOINTS DE SOLICITUDES Y GESTI√ìN
# =========================================================================
@app.get("/obtener_solicitudes")
def obtener_solicitudes(limit: int = 100):
    try:
        conn = get_db_connection()
        # 1. RESTAURADO: RealDictCursor es OBLIGATORIO para que el Frontend entienda los datos
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 2. RESTAURADO: El LEFT JOIN es vital para ver las fotos/videos en el Admin
        query = """
            SELECT 
                s.*, 
                e.Url_Archivo, 
                e.Tipo_Archivo
            FROM Solicitudes s
            LEFT JOIN Evidencias e ON s.Id_Evidencia = e.id
            ORDER BY s.Fecha DESC 
            LIMIT %s
        """
        c.execute(query, (limit,))
        solicitudes = c.fetchall()
        conn.close()
        
        # ‚úÖ TU CORRECCI√ìN M√ÅGICA (Funciona perfecto, la dejamos)
        sol_serializables = json.loads(json.dumps(solicitudes, default=str))
        
        return JSONResponse(sol_serializables)
        
    except Exception as e:
        print(f"‚ùå Error obteniendo solicitudes: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
# =========================================================================
# 1. ENDPOINTS DE SOLICITUDES (LADO ESTUDIANTE) - ¬°ESTO ES LO QUE TE FALTA!
# =========================================================================

@app.post("/solicitar_recuperacion")
async def solicitar_recuperacion(
    background_tasks: BackgroundTasks,
    cedula: str = Form(...),
    email: Optional[str] = Form(None),
    mensaje: Optional[str] = Form(None),
    tipo: str = Form("RECUPERACION_CONTRASENA")
):
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Buscar al usuario
        c.execute("SELECT Nombre, Apellido, Email FROM Usuarios WHERE CI=%s", (cedula.strip(),))
        user = c.fetchone()
        
        if not user:
            return JSONResponse({"status": "error", "mensaje": "La c√©dula no est√° registrada."})
            
        email_final = email if email else user.get('email') or user.get('Email') or "Sin correo"
        nombre_completo = f"{user.get('nombre') or user.get('Nombre')} {user.get('apellido') or user.get('Apellido')}"
        
        detalle = f"{tipo.replace('_', ' ')}. "
        if mensaje: detalle += f"Mensaje: {mensaje}"
        
        # 2. Guardar en Base de Datos
        c.execute("""
            INSERT INTO Solicitudes (Tipo, CI_Solicitante, Email, Detalle, Estado, Fecha)
            VALUES (%s, %s, %s, %s, 'PENDIENTE', %s)
        """, (tipo, cedula.strip(), email_final, detalle, ahora_ecuador()))
        
        conn.commit()

        # 3. L√ìGICA DE CORREOS (CORREGIDA)
        # A) Al ADMIN siempre le avisamos que lleg√≥ algo
        asunto_admin = f"üö® Nuevo mensaje de {tipo}"
        cuerpo_admin = f"Usuario: {nombre_completo} ({cedula}).\nTipo: {tipo}\nMensaje: {mensaje}"
        background_tasks.add_task(enviar_correo_real, "karlos.ayala.lopez.1234@gmail.com", asunto_admin, cuerpo_admin)
        
        # B) Al ESTUDIANTE solo le enviamos correo si es RECUPERACI√ìN (confirmaci√≥n)
        # Si es SOPORTE, no le enviamos nada para no saturarlo (es interno)
        if tipo == 'RECUPERACION_CONTRASENA':
             asunto_user = "Solicitud Recibida - U.E. Despertar"
             cuerpo_user = f"Hola {nombre_completo}, hemos recibido tu solicitud de recuperaci√≥n. Te contactaremos pronto."
             background_tasks.add_task(enviar_correo_real, email_final, asunto_user, cuerpo_user)
        
        return JSONResponse({"status": "ok", "mensaje": "Solicitud enviada correctamente."})
    except Exception as e:
        return JSONResponse({"status": "error", "mensaje": str(e)})
    finally:
        if conn: conn.close()

@app.post("/solicitar_subida")
async def solicitar_subida(
    cedula: str = Form(...),
    archivo: UploadFile = File(...)
):
    """
    Sube el archivo pero lo deja OCULTO (Estado 0) y crea una solicitud
    para que el admin lo revise.
    """
    conn = None
    temp_dir = None
    try:
        # 1. Guardar archivo f√≠sico
        temp_dir = tempfile.mkdtemp()
        path = os.path.join(temp_dir, archivo.filename)
        with open(path, "wb") as f:
            shutil.copyfileobj(archivo.file, f)
            
        file_hash = calcular_hash(path)
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)

        # 2. Subir a la Nube (S3/Backblaze)
        path_procesado = garantizar_limite_storage(path)
        tamanio_kb = os.path.getsize(path_procesado) / 1024
        
        # Nombre √∫nico
        nombre_nube = f"evidencias/pendiente_{int(ahora_ecuador().timestamp())}_{archivo.filename}"
        url_final = f"/local/{archivo.filename}" # Fallback local
        
        if s3_client:
            s3_client.upload_file(path_procesado, BUCKET_NAME, nombre_nube, ExtraArgs={'ACL': 'public-read'})
            url_final = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{nombre_nube}"

        # 3. Insertar Evidencia en BD con ESTADO = 0 (Oculta/Pendiente)
        # Tipo: Determinamos si es imagen o video
        ext = os.path.splitext(archivo.filename)[1].lower()
        tipo_archivo = "video" if ext in ['.mp4', '.mov', '.avi'] else "imagen"

        c.execute("""
            INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
            VALUES (%s, %s, %s, 0, %s, %s, 0) RETURNING id
        """, (cedula, url_final, file_hash, tipo_archivo, tamanio_kb))
        
        id_evidencia = c.fetchone()['id']

        # 4. Crear la Solicitud para el Admin
        # Obtenemos nombre para el correo
        c.execute("SELECT Nombre, Apellido, Email FROM Usuarios WHERE CI=%s", (cedula,))
        user = c.fetchone()
        email = user['email'] if user else 'Sin correo'
        
        c.execute("""
            INSERT INTO Solicitudes (Tipo, CI_Solicitante, Email, Detalle, Id_Evidencia, Estado, Fecha)
            VALUES ('SUBIR_EVIDENCIA', %s, %s, 'Estudiante solicita subir este archivo.', %s, 'PENDIENTE', %s)
        """, (cedula, email, id_evidencia, ahora_ecuador()))

        conn.commit()
        return JSONResponse({"status": "ok", "mensaje": "Archivo enviado a revisi√≥n del administrador."})

    except Exception as e:
        if conn: conn.rollback()
        return JSONResponse({"status": "error", "mensaje": str(e)})
    finally:
        if conn: conn.close()
        if temp_dir and os.path.exists(temp_dir): shutil.rmtree(temp_dir)

@app.post("/reportar_evidencia")
async def reportar_evidencia(
    background_tasks: BackgroundTasks,
    id_evidencia: int = Form(...),
    motivo: str = Form(...),
    cedula: str = Form(...) # ‚úÖ CORREGIDO: Ahora coincide con tu HTML
):
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Obtener datos del usuario (para registro interno)
        c.execute("SELECT * FROM Usuarios WHERE CI = %s", (cedula.strip(),))
        usuario = c.fetchone()
        email_usuario = usuario.get('email') if usuario else 'Sin correo'
        
        # 2. Crear la Solicitud en la Base de Datos
        # Esto hace que aparezca en tu Panel de Admin
        detalle_reporte = f"Reporte de evidencia ID {id_evidencia}. Motivo: {motivo}"
        
        c.execute("""
            INSERT INTO Solicitudes (Tipo, CI_Solicitante, Email, Detalle, Id_Evidencia, Estado, Fecha)
            VALUES ('REPORTE_EVIDENCIA', %s, %s, %s, %s, 'PENDIENTE', %s)
        """, (cedula, email_usuario, detalle_reporte, id_evidencia, ahora_ecuador()))
        
        conn.commit()
        
        # ‚ùå SIN CORREO: Hemos quitado la l√≠nea que enviaba emails para evitar SPAM.
        
        return JSONResponse({"status": "ok", "mensaje": "Reporte enviado al administrador."})

    except Exception as e:
        if conn: conn.rollback()
        print(f"Error en reporte: {e}")
        return JSONResponse({"status": "error", "mensaje": str(e)})
    finally:
        if conn: conn.close()

@app.get("/obtener_solicitudes_por_cedula")
async def obtener_solicitudes_por_cedula(cedula: str):
    """Obtiene el historial de solicitudes de un estudiante con respuestas del admin"""
    conn = None
    try:
        conn = get_db_connection()
        # Usamos cursor para evitar errores en Postgres
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        c.execute("""
            SELECT * FROM Solicitudes 
            WHERE CI_Solicitante = %s 
            ORDER BY Fecha DESC
        """, (cedula.strip(),))
        
        rows = c.fetchall()
        # Convertimos fechas a formato JSON seguro
        return JSONResponse(jsonable_encoder(rows))
    except Exception as e:
        print(f"‚ùå Error historial estudiante: {e}")
        return JSONResponse([])
    finally:
        if conn: conn.close()

# =========================================================================
# AQUI DEBER√çA SEGUIR TU FUNCI√ìN @app.post("/gestionar_solicitud") ...
# =========================================================================

@app.post("/gestionar_solicitud")
async def gestionar_solicitud(
    background_tasks: BackgroundTasks,
    id_solicitud: int = Form(...),
    accion: str = Form(...), # 'APROBADA' o 'RECHAZADA'
    mensaje: str = Form(...),
    id_admin: str = Form("Administrador")
):
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Obtener datos de la solicitud
        c.execute("SELECT * FROM Solicitudes WHERE ID = %s", (id_solicitud,))
        sol = c.fetchone()
        
        if not sol:
            return JSONResponse({"status": "error", "mensaje": "Solicitud no encontrada"})

        # Recuperar datos clave (Soporta may√∫sculas/min√∫sculas de la BD)
        tipo = sol.get('tipo') or sol.get('Tipo')
        id_evidencia = sol.get('id_evidencia') or sol.get('Id_Evidencia')
        email_usuario = sol.get('email') or sol.get('Email')

        # ---------------------------------------------------------
        # 2. L√ìGICA DE GESTI√ìN (BORRADO INTELIGENTE)
        # ---------------------------------------------------------

        # --- CASO A: REPORTE "NO SOY YO" ---
        if tipo == 'REPORTE_EVIDENCIA':
            if accion == 'APROBADA':
                if id_evidencia:
                    # PASO 1: Obtener datos de la evidencia (URL y Hash) antes de tocar nada
                    c.execute("SELECT Url_Archivo, Hash FROM Evidencias WHERE id = %s", (id_evidencia,))
                    ev_data = c.fetchone()
                    
                    if ev_data:
                        # A) DESVINCULAR: Borramos el registro espec√≠fico de ESTE usuario
                        c.execute("DELETE FROM Evidencias WHERE id = %s", (id_evidencia,))
                        print(f"‚úÖ Evidencia {id_evidencia} eliminada del perfil del usuario (Desvinculaci√≥n).")
                        
                        # B) VERIFICACI√ìN DE SEGURIDAD (¬øAlguien m√°s la usa?)
                        file_hash = ev_data.get('Hash') or ev_data.get('hash')
                        url = ev_data.get('Url_Archivo') or ev_data.get('url_archivo')
                        
                        # Contamos cu√°ntas veces queda ese Hash en la tabla
                        c.execute("SELECT COUNT(*) as total FROM Evidencias WHERE Hash = %s", (file_hash,))
                        count_res = c.fetchone()
                        total_restantes = count_res['total'] if count_res else 0
                        
                        # C) LIMPIEZA DE NUBE CONDICIONAL
                        # Solo borramos el archivo f√≠sico si el contador llega a 0 (Nadie m√°s lo tiene)
                        if total_restantes == 0:
                            if url and s3_client and BUCKET_NAME and "backblazeb2.com" in url:
                                try:
                                    if f"/file/{BUCKET_NAME}/" in url:
                                        file_key = url.split(f"/file/{BUCKET_NAME}/")[1]
                                        s3_client.delete_object(Bucket=BUCKET_NAME, Key=file_key)
                                        print(f"üóëÔ∏è Archivo f√≠sico eliminado de la nube (Ya no lo usa nadie): {file_key}")
                                except Exception as e:
                                    print(f"‚ö†Ô∏è Error intentando borrar de S3 (No cr√≠tico): {e}")
                        else:
                            print(f"‚ÑπÔ∏è Archivo f√≠sico conservado. A√∫n lo usan {total_restantes} estudiantes m√°s.")
                    else:
                        print("‚ö†Ô∏è La evidencia ya no exist√≠a en la base de datos (Posiblemente ya borrada).")

            else:
                # Si rechazamos el reporte, no hacemos nada (la evidencia se queda)
                pass

        # --- CASO B: SUBIR EVIDENCIA ---
        elif tipo == 'SUBIR_EVIDENCIA':
            if accion == 'APROBADA':
                if id_evidencia:
                    # Hacemos visible la evidencia (Estado 1)
                    c.execute("UPDATE Evidencias SET Estado = 1 WHERE id = %s", (id_evidencia,))
            else:
                # Si rechazamos, borramos el archivo pendiente para no ocupar espacio
                # Aqu√≠ S√ç borramos f√≠sico porque est√° en "Pendientes" y no pertenece a nadie m√°s a√∫n
                if id_evidencia:
                    c.execute("SELECT Url_Archivo FROM Evidencias WHERE id = %s", (id_evidencia,))
                    ev_data = c.fetchone()
                    if ev_data:
                        url = ev_data.get('Url_Archivo')
                        if url and s3_client and BUCKET_NAME and f"/file/{BUCKET_NAME}/" in url:
                            try:
                                key = url.split(f"/file/{BUCKET_NAME}/")[1]
                                s3_client.delete_object(Bucket=BUCKET_NAME, Key=key)
                            except: pass
                    
                    c.execute("DELETE FROM Evidencias WHERE id = %s", (id_evidencia,))

        # --- CASO C: RECUPERACI√ìN DE CONTRASE√ëA ---
        elif tipo == 'RECUPERACION_CONTRASENA':
            if accion == 'APROBADA':
                asunto = "üîê Recuperaci√≥n de Acceso - U.E. Despertar"
                cuerpo = f"""
                <h3>Hola, hemos procesado tu solicitud.</h3>
                <p>El administrador ha revisado tu caso.</p>
                <p><strong>Tu contrase√±a/respuesta es:</strong></p>
                <h2 style="color:#6A0DAD;">{mensaje}</h2>
                <hr>
                <p>Intenta ingresar nuevamente.</p>
                """
                if email_usuario and '@' in email_usuario:
                    background_tasks.add_task(enviar_correo_real, email_usuario, asunto, cuerpo)

        # ---------------------------------------------------------
        # 3. ACTUALIZAR HISTORIAL DE LA SOLICITUD
        # ---------------------------------------------------------
        c.execute("""
            UPDATE Solicitudes 
            SET Estado = %s, Respuesta = %s, Id_Admin = %s, Fecha_Resolucion = %s
            WHERE ID = %s
        """, (accion, mensaje, id_admin, ahora_ecuador(), id_solicitud))
        
        tipo_sol = sol.get('tipo') or sol.get('Tipo')
        registrar_auditoria(
            "GESTION_SOLICITUD", 
            f"Admin {accion} la solicitud de {tipo_sol} con respuesta: '{mensaje}'", 
            id_admin # Aqu√≠ usamos el nombre real del admin que arreglamos antes
        )

        conn.commit()
        return JSONResponse({"status": "ok", "mensaje": "Acci√≥n ejecutada correctamente."})

    except Exception as e:
        if conn: conn.rollback()
        print(f"Error gestionando solicitud: {e}")
        return JSONResponse({"status": "error", "mensaje": str(e)})
    finally:
        if conn: conn.close()
        
# =========================================================================
# 12. ENDPOINTS DE LOGS Y AUDITOR√çA
# =========================================================================

@app.get("/obtener_logs")
def obtener_logs():
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # ‚úÖ AUMENTAMOS EL L√çMITE A 5000 (Suficiente para meses de historial)
        # Si pones sin l√≠mite (quitas el LIMIT), podr√≠a ponerse lento si tienes 1 mill√≥n de registros.
        # 5000 es un buen equilibrio.
        c.execute("SELECT * FROM Auditoria ORDER BY Fecha DESC LIMIT 5000")
        
        logs = c.fetchall()
        conn.close()
        
        # Convertir a JSON seguro
        logs_serializables = json.loads(json.dumps(logs, default=str))
        
        return JSONResponse(logs_serializables)
    except Exception as e:
        print(f"Error logs: {e}")
        return JSONResponse([])
    
# =========================================================================
# 13. ENDPOINTS EXISTENTES MANTENIDOS
# =========================================================================

@app.get("/listar_usuarios")
def listar_usuarios():
    """Versi√≥n OPTIMIZADA: Lista usuarios r√°pidamente"""
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # Traemos solo los campos necesarios, ordenados alfab√©ticamente
        c.execute("""
            SELECT ID, Nombre, Apellido, CI, Password, Tipo, Foto, Activo, Email, Telefono 
            FROM Usuarios 
            ORDER BY Apellido ASC, Nombre ASC
        """)
        usuarios = c.fetchall()
        conn.close()
        
        # Serializaci√≥n segura de fechas y datos
        return JSONResponse(json.loads(json.dumps(usuarios, default=str)))
        
    except Exception as e:
        print(f"‚ùå Error listando usuarios: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
@app.get("/resumen_estudiantes_con_evidencias")
def resumen_estudiantes():
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # Consulta segura
        query = """
            SELECT 
                u.Nombre, u.Apellido, u.CI, u.Foto,
                COUNT(e.id) as total_evidencias,
                COALESCE(SUM(e.Tamanio_KB), 0) as total_kb
            FROM Usuarios u
            LEFT JOIN Evidencias e ON u.CI = e.CI_Estudiante
            WHERE u.Tipo = 1
            GROUP BY u.CI, u.Nombre, u.Apellido, u.Foto
            ORDER BY u.Apellido ASC
        """
        c.execute(query)
        data = c.fetchall()
        conn.close()
        
        # ‚úÖ CORRECCI√ìN: Convertir fechas y datos raros a texto
        import json
        data_serializable = json.loads(json.dumps(data, default=str))
        
        return JSONResponse(data_serializable)
    except Exception as e:
        print(f"‚ùå Error resumen: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
@app.get("/todas_evidencias")
def todas_evidencias(cedula: str):
    try:
        conn = get_db_connection()
        c = conn.cursor()
        # Buscamos por la c√©dula del estudiante
        c.execute("SELECT * FROM Evidencias WHERE CI_Estudiante = %s ORDER BY id DESC", (cedula,))
        evs = c.fetchall()
        conn.close()
        
        # ‚úÖ CORRECCI√ìN: Convertir fechas a texto para que no falle
        import json
        evs_serializables = json.loads(json.dumps(evs, default=str))
        
        return JSONResponse(evs_serializables)
    except Exception as e:
        print(f"‚ùå Error evidencias estudiante: {e}")
        return JSONResponse([])

@app.delete("/eliminar_evidencia/{id}")
async def eliminar_evidencia(id: int):
    try:
        conn = get_db_connection()
        # Usamos RealDictCursor para obtener un diccionario
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Buscar la evidencia
        c.execute("SELECT * FROM Evidencias WHERE id = %s", (id,))
        evidencia = c.fetchone()
        
        if not evidencia:
            conn.close()
            raise HTTPException(status_code=404, detail="Evidencia no encontrada")
            
        # üõ°Ô∏è CORRECCI√ìN: Buscamos la URL con seguridad (may√∫sculas o min√∫sculas)
        url = evidencia.get('Url_Archivo') or evidencia.get('url_archivo')
        
        # 2. Borrar de la Nube (Si tiene URL v√°lida)
        if url and s3_client and BUCKET_NAME and "backblazeb2.com" in url:
            try:
                # Extraer la clave del archivo
                partes = url.split(f"/file/{BUCKET_NAME}/")
                if len(partes) > 1:
                    file_key = partes[1]
                    print(f"üóëÔ∏è Eliminando de B2: {file_key}")
                    s3_client.delete_object(Bucket=BUCKET_NAME, Key=file_key)
            except Exception as e_b2:
                print(f"‚ö†Ô∏è Alerta: Se borr√≥ de BD pero fall√≥ en B2: {e_b2}")

        # 3. Borrar de la Base de Datos
        c.execute("DELETE FROM Evidencias WHERE id = %s", (id,))
        conn.commit()
        conn.close()
        
        return JSONResponse({"mensaje": "Evidencia eliminada correctamente"})
        
    except Exception as e:
        # Imprimimos el error exacto en los logs de Railway
        print(f"‚ùå Error CR√çTICO eliminando evidencia {id}: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
@app.get("/diagnostico_usuario/{cedula}")
async def diagnostico_usuario(cedula: str):
    """Diagn√≥stico completo de un usuario (Versi√≥n PostgreSQL)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # CORRECCI√ìN: Usamos information_schema en lugar de PRAGMA
        c.execute("""
            SELECT column_name, data_type 
            FROM information_schema.columns 
            WHERE table_name = 'usuarios'
        """)
        columnas = c.fetchall()
        
        # Buscar usuario
        c.execute("SELECT * FROM Usuarios WHERE CI = %s", (cedula,))
        usuario = c.fetchone()
        
        # Evidencias del usuario
        c.execute("""
            SELECT COUNT(*) as total, 
                   SUM(Tamanio_KB) as total_kb,
                   Tipo_Archivo,
                   COUNT(*) as cantidad
            FROM Evidencias
            WHERE CI_Estudiante = %s
            GROUP BY Tipo_Archivo
        """, (cedula,))
        estadisticas_evidencias = [dict(r) for r in c.fetchall()]
        
        # Solicitudes del usuario
        c.execute("""
            SELECT Estado, COUNT(*) as cantidad
            FROM Solicitudes
            WHERE CI_Solicitante = %s
            GROUP BY Estado
        """, (cedula,))
        estadisticas_solicitudes = [dict(r) for r in c.fetchall()]
        
        conn.close()
        
        return JSONResponse(content={
            "cedula_buscada": cedula,
            "usuario_encontrado": bool(usuario),
            "usuario": dict(usuario) if usuario else None,
            "estructura_tabla": [dict(r) for r in columnas],
            "estadisticas_evidencias": estadisticas_evidencias,
            "estadisticas_solicitudes": estadisticas_solicitudes,
            "fecha_diagnostico": ahora_ecuador().isoformat(),
            "zona_horaria": "America/Guayaquil (UTC-5)"
        })
        
    except Exception as e:
        return JSONResponse(content={"error": str(e)})

@app.get("/reset-db")
async def reset_database():
    """Reinicia la base de datos (SOLO DESARROLLO)"""
    try:
        init_db_completa()
        return JSONResponse(content={
            "status": "ok",
            "mensaje": "Base de datos reinicializada",
            "fecha": ahora_ecuador().isoformat()
        })
    except Exception as e:
        return JSONResponse(content={"error": str(e)})

# =========================================================================
# 14. ENDPOINTS CORS Y UTILIDADES
# =========================================================================

@app.options("/{rest_of_path:path}")
async def preflight_handler(request: Request, rest_of_path: str):
    """Manejador de preflight CORS"""
    response = JSONResponse(content={"message": "Preflight OK"})
    response.headers["Access-Control-Allow-Origin"] = "*"
    response.headers["Access-Control-Allow-Credentials"] = "true"
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS, PATCH"
    response.headers["Access-Control-Allow-Headers"] = "*"
    return response

@app.get("/cors-debug")
async def cors_debug():
    """Endpoint para debug de CORS"""
    return JSONResponse(content={
        "message": "CORS Debug Endpoint",
        "allow_origin": "*",
        "allow_methods": "GET, POST, PUT, DELETE, OPTIONS, PATCH",
        "allow_headers": "*",
        "allow_credentials": "true",
        "timestamp": ahora_ecuador().isoformat(),
        "zona_horaria": "America/Guayaquil (UTC-5)"
    })

# =========================================================================
# 15. INICIO DE LA APLICACI√ìN
# =========================================================================

class PasswordRequest(BaseModel):
    cedula: str
    nueva_contrasena: str

@app.post("/cambiar_contrasena")
async def cambiar_contrasena(datos: PasswordRequest):
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor) # Necesitamos leer datos
        
        # 1. Obtener nombre del usuario antes de cambiar la clave (para el log)
        c.execute("SELECT Nombre, Apellido FROM Usuarios WHERE CI = %s", (datos.cedula,))
        u = c.fetchone()
        nombre_usuario = f"{u['nombre']} {u['apellido']}" if u else datos.cedula

        # 2. Ejecutar el cambio
        c.execute("UPDATE Usuarios SET Password = %s WHERE CI = %s", (datos.nueva_contrasena, datos.cedula))
        conn.commit()
        
        # 3. ‚úÖ LOG DETALLADO
        registrar_auditoria(
            "CAMBIO_PASSWORD", 
            f"El Admin cambi√≥ la contrase√±a del usuario: {nombre_usuario} (CI: {datos.cedula})", 
            "Administrador"
        )
        
        return JSONResponse({"mensaje": "Contrase√±a actualizada correctamente"})
    except Exception as e:
        return JSONResponse({"error": str(e)})
    finally:
        if conn: conn.close()
    
@app.post("/descargar_evidencias_zip")
async def descargar_evidencias_zip(ids: str = Form(...)):
    try:
        lista_ids = ids.split(',')
        if not lista_ids:
            return JSONResponse({"error": "No hay IDs"}, status_code=400)
            
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # Consultar archivos
        placeholders = ','.join(['%s'] * len(lista_ids))
        c.execute(f"SELECT Url_Archivo FROM Evidencias WHERE id IN ({placeholders})", tuple(lista_ids))
        resultados = c.fetchall()
        conn.close()
        
        if not resultados:
            return JSONResponse({"error": "No se encontraron archivos"}, status_code=404)

        # Crear ZIP en memoria
        zip_buffer = io.BytesIO()
        
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for i, item in enumerate(resultados):
                url = item['Url_Archivo']
                nombre_archivo = f"evidencia_{i+1}_{os.path.basename(url)}"
                
                # CASO 1: Archivo en Nube (Backblaze/S3)
                if "backblazeb2.com" in url or "s3" in url:
                    if s3_client and BUCKET_NAME:
                        try:
                            # Extraer key de la URL
                            partes = url.split(f"/file/{BUCKET_NAME}/")
                            if len(partes) > 1:
                                file_key = partes[1]
                                # Descargar de S3 a memoria
                                file_obj = s3_client.get_object(Bucket=BUCKET_NAME, Key=file_key)
                                file_content = file_obj['Body'].read()
                                zip_file.writestr(nombre_archivo, file_content)
                                print(f"üì¶ Agregado al ZIP (Nube): {nombre_archivo}")
                        except Exception as e:
                            print(f"‚ö†Ô∏è Error bajando de nube {url}: {e}")
                            # Crear archivo de texto de error en el zip
                            zip_file.writestr(f"ERROR_{nombre_archivo}.txt", f"No se pudo descargar: {str(e)}")
                
                # CASO 2: Archivo Local (Legado)
                elif os.path.exists(url):
                    try:
                        zip_file.write(url, nombre_archivo)
                        print(f"üì¶ Agregado al ZIP (Local): {nombre_archivo}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error archivo local: {e}")

        zip_buffer.seek(0)
        
        # Nombre del ZIP con fecha
        fecha_str = datetime.datetime.now().strftime("%Y%m%d_%H%M")
        nombre_zip = f"evidencias_seleccion_{fecha_str}.zip"
        
        return StreamingResponse(
            zip_buffer, 
            media_type="application/zip",
            headers={"Content-Disposition": f"attachment; filename={nombre_zip}"}
        )

    except Exception as e:
        print(f"‚ùå Error generando ZIP: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)


from urllib.parse import urlparse 

def limpieza_duplicados_startup():
    """
    V5.4 - CORREGIDA PARA POSTGRESQL (Fix HAVING y Lowercase)
    """
    print("üßπ INICIANDO PROTOCOLO DE LIMPIEZA Y MANTENIMIENTO...")
    
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # ---------------------------------------------------------
        # FASE 0: LIMPIEZA POR URL EXACTA
        # ---------------------------------------------------------
        print("üîç FASE 0: Buscando URLs id√©nticas...")
        # CORRECCI√ìN: Usamos COUNT(*) > 1 en vez de 'cantidad'
        c.execute("""
            SELECT Url_Archivo, COUNT(*) as cantidad FROM Evidencias 
            GROUP BY Url_Archivo HAVING COUNT(*) > 1
        """)
        urls_repetidas = c.fetchall()
        
        eliminados_0 = 0
        for row in urls_repetidas:
            # PostgreSQL devuelve claves en min√∫scula: row['url_archivo']
            url = row['url_archivo'] if 'url_archivo' in row else row['Url_Archivo']
            
            c.execute("SELECT id FROM Evidencias WHERE Url_Archivo = %s ORDER BY id ASC", (url,))
            copias = c.fetchall()
            for copia in copias[1:]: # Borrar todos menos el primero
                c.execute("DELETE FROM Evidencias WHERE id = %s", (copia['id'],))
                eliminados_0 += 1
        
        if eliminados_0 > 0: print(f"   ‚ú® Fase 0: {eliminados_0} registros eliminados.")

        # ---------------------------------------------------------
        # FASE 1: REPARAR ARCHIVOS ANTIGUOS
        # ---------------------------------------------------------
        print("‚è≥ FASE 1: Verificando huellas digitales...")
        c.execute("SELECT id, Url_Archivo FROM Evidencias WHERE Hash = 'PENDIENTE' OR Hash IS NULL")
        pendientes = c.fetchall()
        
        count_hashed = 0
        for row in pendientes:
            try:
                # Soporte para min√∫sculas/may√∫sculas
                url = row.get('Url_Archivo') or row.get('url_archivo')
                id_ev = row.get('id')
                
                temp_path = None
                file_hash = None
                
                if "http" in url and s3_client:
                    try:
                        parsed = urlparse(url)
                        key = parsed.path.lstrip('/')
                        with tempfile.NamedTemporaryFile(delete=False) as tmp:
                            s3_client.download_fileobj(BUCKET_NAME, key, tmp)
                            temp_path = tmp.name
                        file_hash = calcular_hash(temp_path)
                    except: pass 
                elif "/local/" in url:
                    ruta_local = url.replace("/local/", "./")
                    if not os.path.exists(ruta_local):
                         ruta_local = os.path.join(BASE_DIR, url.replace("/local/", "").lstrip("/"))
                    if os.path.exists(ruta_local):
                        file_hash = calcular_hash(ruta_local)

                if file_hash:
                    c.execute("UPDATE Evidencias SET Hash = %s WHERE id = %s", (file_hash, id_ev))
                    count_hashed += 1
                
                if temp_path and os.path.exists(temp_path): os.remove(temp_path)
            except: pass
            
        conn.commit() 

        # (Mant√©n el resto de las fases igual, el error cr√≠tico era la Fase 0)
        # ... Para ahorrar espacio, asumo que dejas las Fases 2, 3 y 4 como estaban
        # pero recuerda que si acceden a columnas deben buscar la versi√≥n en min√∫scula.
        
        conn.close()
        print(f"‚úÖ MANTENIMIENTO FINALIZADO (Fase 0 y 1 completas).")

    except Exception as e:
        print(f"‚ùå Error en limpieza startup: {e}")

        # ---------------------------------------------------------
        # FASE 2: ELIMINAR POR HASH
        # ---------------------------------------------------------
        print("üîç FASE 2: Buscando contenido id√©ntico (Hash)...")
        c.execute("""
            SELECT Hash, COUNT(*) as cantidad FROM Evidencias 
            WHERE Hash NOT IN ('PENDIENTE', '', 'RECUPERADO') GROUP BY Hash HAVING cantidad > 1
        """)
        grupos_hash = c.fetchall()
        
        eliminados_2 = 0
        for grupo in grupos_hash:
            c.execute("SELECT id, Url_Archivo FROM Evidencias WHERE Hash = %s ORDER BY id ASC", (grupo['Hash'],))
            copias = c.fetchall()
            original = copias[0]
            for copia in copias[1:]:
                if s3_client and copia['Url_Archivo'] != original['Url_Archivo'] and BUCKET_NAME in copia['Url_Archivo']:
                    try:
                        parsed = urlparse(copia['Url_Archivo'])
                        key = parsed.path.lstrip('/')
                        s3_client.delete_object(Bucket=BUCKET_NAME, Key=key)
                    except: pass
                
                c.execute("DELETE FROM Evidencias WHERE id = %s", (copia['id'],))
                eliminados_2 += 1
        
        if eliminados_2 > 0: print(f"   ‚ú® Fase 2: {eliminados_2} duplicados exactos eliminados.")

        # ---------------------------------------------------------
        # FASE 3: ELIMINAR POR NOMBRE + ESTUDIANTE
        # ---------------------------------------------------------
        print("üîç FASE 3: Buscando duplicados por nombre de archivo...")
        c.execute("SELECT id, CI_Estudiante, Url_Archivo FROM Evidencias")
        todas = c.fetchall()
        agrupados = {}
        
        for ev in todas:
            url = ev['Url_Archivo']
            cedula = ev['CI_Estudiante']
            filename = os.path.basename(url)
            clean_name = re.sub(r'^\d+_', '', filename)
            clave = f"{cedula}|{clean_name}"
            
            if clave not in agrupados: agrupados[clave] = []
            agrupados[clave].append(ev)
            
        eliminados_3 = 0
        for clave, lista in agrupados.items():
            if len(lista) > 1:
                lista.sort(key=lambda x: x['id'])
                duplicados = lista[1:] 
                for dup in duplicados:
                    c.execute("DELETE FROM Evidencias WHERE id = %s", (dup['id'],))
                    if s3_client and BUCKET_NAME in dup['Url_Archivo']:
                        try:
                            parsed = urlparse(dup['Url_Archivo'])
                            key = parsed.path.lstrip('/')
                            s3_client.delete_object(Bucket=BUCKET_NAME, Key=key)
                        except: pass
                    eliminados_3 += 1

        if eliminados_3 > 0: print(f"   ‚ú® Fase 3: {eliminados_3} archivos eliminados por nombre.")

        # ---------------------------------------------------------
        # FASE 4: SINCRONIZACI√ìN SEGURA CON NUBE
        # ---------------------------------------------------------
        print("‚òÅÔ∏è FASE 4: Auditando existencia real en la nube...")
        conn.commit()
        c.execute("SELECT id, Url_Archivo FROM Evidencias")
        evidencias = c.fetchall()
        
        actualizados_peso = 0
        eliminados_nube = 0
        
        for ev in evidencias:
            url = ev['Url_Archivo']
            existe = False
            peso_kb = 0
            
            if s3_client and BUCKET_NAME in url:
                try:
                    parsed = urlparse(url)
                    key = parsed.path.lstrip('/')
                    meta = s3_client.head_object(Bucket=BUCKET_NAME, Key=key)
                    peso_kb = meta['ContentLength'] / 1024
                    existe = True
                except Exception as e:
                    if "404" in str(e) or "Not Found" in str(e): existe = False
                    else: existe = True 
            elif "/local/" in url:
                existe = True 
            
            if existe:
                c.execute("UPDATE Evidencias SET Tamanio_KB = %s WHERE id = %s", (peso_kb, ev['id']))
                actualizados_peso += 1
            else:
                c.execute("DELETE FROM Evidencias WHERE id = %s", (ev['id'],))
                eliminados_nube += 1
        
        conn.commit()
        print(f"‚úÖ FASE 4 COMPLETADA: {actualizados_peso} actualizados, {eliminados_nube} eliminados.")
        
        # Actualizar m√©tricas
        try:
            stats = calcular_estadisticas_reales()
            fecha_hoy = ahora_ecuador().date().isoformat()
            
            # Usar conexi√≥n nueva para m√©tricas para evitar conflictos
            conn_metricas = get_db_connection()
            c_met = conn_metricas.cursor()
            c_met.execute("""
                INSERT INTO Metricas_Sistema 
                (Fecha, Total_Usuarios, Total_Evidencias, Solicitudes_Pendientes, Almacenamiento_MB)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (Fecha) DO UPDATE SET
                Total_Usuarios = EXCLUDED.Total_Usuarios,
                Total_Evidencias = EXCLUDED.Total_Evidencias,
                Solicitudes_Pendientes = EXCLUDED.Solicitudes_Pendientes,
                Almacenamiento_MB = EXCLUDED.Almacenamiento_MB
            """, (fecha_hoy, stats.get("usuarios_activos",0), stats.get("total_evidencias",0), 
                  stats.get("solicitudes_pendientes",0), stats.get("almacenamiento_mb",0)))
            conn_metricas.commit()
            conn_metricas.close()
        except Exception as e:
            print(f"‚ö†Ô∏è Error menor actualizando m√©tricas: {e}")
        
        conn.close()
        print(f"‚úÖ MANTENIMIENTO TOTAL FINALIZADO.")

    except Exception as e:
        print(f"‚ùå Error en limpieza startup: {e}")
@app.post("/recuperar_evidencias_nube")
async def recuperar_evidencias_nube(background_tasks: BackgroundTasks):
    """
    Escanea TODO el bucket de Backblaze, encuentra los archivos que faltan en la BD
    y los restaura autom√°ticamente (intentando usar IA para re-asignarlos).
    """
    def tarea_rescate():
        print("üöë INICIANDO OPERACI√ìN RESCATE DE EVIDENCIAS...")
        if not s3_client:
            print("‚ùå No hay conexi√≥n S3 para el rescate.")
            return

        conn = get_db_connection()
        c = conn.cursor() # <--- IMPORTANTE: Creamos el cursor aqu√≠
        restaurados = 0
        
        try:
            # 1. Listar TODOS los objetos en la carpeta 'evidencias/' de la nube
            paginator = s3_client.get_paginator('list_objects_v2')
            pages = paginator.paginate(Bucket=BUCKET_NAME, Prefix='evidencias/')
            
            for page in pages:
                if 'Contents' not in page: continue
                
                for obj in page['Contents']:
                    key = obj['Key'] # Ejemplo: evidencias/123_foto.jpg
                    
                    # Ignoramos carpetas vac√≠as
                    if key.endswith('/'): continue
                    
                    # Construimos la URL que deber√≠a tener
                    url_archivo = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{key}"
                    
                    # 2. Verificar si ya existe en la BD (Usando el cursor 'c')
                    c.execute("SELECT id FROM Evidencias WHERE Url_Archivo = %s", (url_archivo,))
                    existe = c.fetchone()
                    
                    if not existe:
                        print(f"   üì• Recuperando: {key}...")
                        
                        # Descargar para an√°lisis IA (si es imagen)
                        temp_path = None
                        ci_detectada = '9999999990' # Por defecto a bandeja recuperados
                        asignado_auto = 0
                        
                        try:
                            # Descargar archivo temporal
                            with tempfile.NamedTemporaryFile(delete=False) as tmp:
                                s3_client.download_fileobj(BUCKET_NAME, key, tmp)
                                temp_path = tmp.name
                            
                            # Intentar reconocer rostros para re-asignar
                            if key.lower().endswith(('.jpg', '.jpeg', '.png', '.webp', '.avif')) and rekog:
                                try:
                                    rostros = identificar_varios_rostros_aws(temp_path)
                                    if rostros:
                                        # Si encuentra rostros, buscamos si son estudiantes
                                        for rostro in rostros:
                                            c.execute("SELECT CI FROM Usuarios WHERE CI=%s", (rostro,))
                                            u = c.fetchone()
                                            if u:
                                                ci_detectada = u['CI']
                                                asignado_auto = 1
                                                break
                                except: pass
                            
                            # Calcular Hash nuevo
                            nuevo_hash = calcular_hash(temp_path)
                            size_kb = obj['Size'] / 1024
                            
                            # Insertar en BD (Usando el cursor 'c')
                            tipo = 'video' if key.lower().endswith(('.mp4', '.avi')) else 'imagen'
                            c.execute("""
                                INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                                VALUES (%s, %s, %s, 1, %s, %s, %s)
                            """, (ci_detectada, url_archivo, nuevo_hash, tipo, size_kb, asignado_auto))
                            
                            restaurados += 1
                            
                            if temp_path and os.path.exists(temp_path): os.remove(temp_path)
                            
                        except Exception as e:
                            print(f"   ‚ö†Ô∏è Error parcial recuperando {key}: {e}")
                            # Intentamos insertar aunque sea sin IA
                            try:
                                c.execute("""
                                    INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                                    VALUES ('9999999990', %s, 'RECUPERADO', 1, 'desconocido', 0, 0)
                                """, (url_archivo,))
                                restaurados += 1
                            except: pass

            conn.commit()
            print(f"‚úÖ OPERACI√ìN RESCATE FINALIZADA: {restaurados} evidencias restauradas.")
            
            # Actualizar estad√≠sticas (Usando el cursor 'c')
            try:
                stats = calcular_estadisticas_reales()
                fecha = ahora_ecuador().date().isoformat()
                c.execute("""
                    INSERT INTO Metricas_Sistema (Fecha, Total_Evidencias, Almacenamiento_MB) 
                    VALUES (%s, %s, %s)
                    ON CONFLICT (Fecha) DO UPDATE SET
                    Total_Evidencias = EXCLUDED.Total_Evidencias,
                    Almacenamiento_MB = EXCLUDED.Almacenamiento_MB
                """, (fecha, stats.get('total_evidencias',0), stats.get('almacenamiento_mb',0)))
                conn.commit()
            except Exception as e:
                print(f"‚ö†Ô∏è Error actualizando m√©tricas tras rescate: {e}")

        except Exception as e:
            print(f"‚ùå Error cr√≠tico en rescate: {e}")
        finally:
            conn.close()

    background_tasks.add_task(tarea_rescate)
    return JSONResponse({"mensaje": "üöë Rescate iniciado. Revisa los logs en 2 minutos."})

class ReasignarRequest(BaseModel):
    ids: str
    cedula_destino: str


    # --- AGREGA ESTE NUEVO ENDPOINT PARA RECUPERAR TUS DATOS ---

@app.post("/reasignar_evidencias")
async def reasignar_evidencias(datos: ReasignarRequest):
    """
    V2.0 - Reasignaci√≥n Multi-Destino:
    - Permite enviar una lista de c√©dulas destino (separadas por comas).
    - Al primer destino le MUEVE el archivo.
    - A los siguientes destinos les crea una COPIA (Clon) en la base de datos.
    """
    try:
        if not datos.ids or not datos.cedula_destino:
            return JSONResponse({"error": "Faltan datos"})
            
        ids_evidencias = [id.strip() for id in datos.ids.split(',') if id.strip()]
        cedulas_destino = [ced.strip() for ced in datos.cedula_destino.split(',') if ced.strip()]
        
        if not ids_evidencias or not cedulas_destino:
             return JSONResponse({"error": "Selecci√≥n inv√°lida"})

        conn = get_db_connection()
        c = conn.cursor()
        
        movidos = 0
        clonados = 0
        
        # 1. Obtener datos originales de las evidencias antes de moverlas
        placeholders = ','.join(['%s'] * len(ids_evidencias))
        evidencias_originales = c.execute(f"SELECT * FROM Evidencias WHERE id IN ({placeholders})", ids_evidencias).fetchall()

        # 2. PROCESAR CADA EVIDENCIA
        for ev in evidencias_originales:
            # A) Mover al PRIMER estudiante de la lista (UPDATE)
            primer_destino = cedulas_destino[0]
            c.execute("UPDATE Evidencias SET CI_Estudiante = %s, Asignado_Automaticamente = 0 WHERE id = %s", (primer_destino, ev['id']))
            movidos += 1
            
            # B) Clonar para el RESTO de estudiantes (INSERT)
            if len(cedulas_destino) > 1:
                for otro_destino in cedulas_destino[1:]:
                    c.execute("""
                        INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                        VALUES (%s, %s, %s, %s, %s, %s, 0)
                    """, (otro_destino, ev['Url_Archivo'], ev['Hash'], ev['Estado'], ev['Tipo_Archivo'], ev['Tamanio_KB']))
                    clonados += 1

        conn.commit()
        conn.close()
        
        mensaje = f"‚úÖ Archivos movidos a 1 estudiante."
        if clonados > 0:
            mensaje += f" Y se crearon copias para {len(cedulas_destino)-1} estudiantes m√°s."
        
        return JSONResponse({"mensaje": mensaje})
        
    except Exception as e:
        return JSONResponse({"error": str(e)})

# --- ENDPOINT DE EMERGENCIA PARA CORREGIR ADMIN ---
@app.get("/reparar_admin")
async def reparar_admin():
    """Fuerza al usuario 9999999999 a ser Administrador (Tipo 0)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # 1. Verificar si existe
        c.execute("SELECT * FROM Usuarios WHERE CI = '9999999999'")
        user = c.fetchone()
        
        if not user:
            # Si no existe, lo creamos de cero
            c.execute("""
                INSERT INTO Usuarios (Nombre, Apellido, CI, Password, Tipo, Activo) 
                VALUES ('Admin', 'Sistema', '9999999999', 'admin123', 0, 1)
            """)
            mensaje = "Usuario Admin no exist√≠a. CREADO exitosamente."
        else:
            # Si existe, LO FORZAMOS a ser Tipo 0
            c.execute("UPDATE Usuarios SET Tipo = 0, Activo = 1 WHERE CI = '9999999999'")
            mensaje = "Usuario 9999999999 actualizado: AHORA ES ADMIN (Tipo 0)."
            
        conn.commit()
        conn.close()
        return JSONResponse({"status": "ok", "mensaje": mensaje})
        
    except Exception as e:
        return JSONResponse({"error": str(e)})

    # --- ENDPOINT PARA ACTUALIZAR LA TABLA USUARIOS (EJECUTAR UNA VEZ) ---
@app.get("/actualizar_tabla_usuarios")
async def actualizar_tabla_usuarios():
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # Agregamos TEMA a la lista de columnas nuevas
        comandos = [
            "ALTER TABLE Usuarios ADD COLUMN IF NOT EXISTS Email TEXT;",
            "ALTER TABLE Usuarios ADD COLUMN IF NOT EXISTS Telefono TEXT;",
            "ALTER TABLE Usuarios ADD COLUMN IF NOT EXISTS Fecha_Registro TIMESTAMP DEFAULT NOW();",
            "ALTER TABLE Usuarios ADD COLUMN IF NOT EXISTS Tema INTEGER DEFAULT 0;" # <--- ESTO ES LO NUEVO
        ]
        
        for cmd in comandos:
            c.execute(cmd)
            
        conn.commit()
        conn.close()
        return {"mensaje": "‚úÖ Base de datos actualizada: Se agreg√≥ columna Tema."}
    except Exception as e:
        return {"error": str(e)}

if __name__ == "__main__":
    import uvicorn
    
    # Configuraci√≥n del puerto
    port = int(os.environ.get("PORT", 8000))
    
    print("=" * 60)
    print("üöÄ SISTEMA EDUCATIVO DESPERTAR - BACKEND V7.0")
    print("=" * 60)
    print(f"üìÅ Base de datos: {DB_NAME}")
    print(f"üåç Zona horaria: America/Guayaquil (UTC-5)")
    print(f"ü§ñ AWS Rekognition: {'‚úÖ Disponible' if rekog else '‚ùå No disponible'}")
    print(f"üíæ S3 Storage: {'‚úÖ Disponible' if s3_client else '‚ùå No disponible'}")
    print(f"üìß Servidor SMTP: {'‚úÖ Configurado' if SMTP_EMAIL and 'tu_correo' not in SMTP_EMAIL else '‚ö†Ô∏è Simulado'}")
    print(f"üîê Usuario admin: 9999999999 / admin123")
    
    # üëáüëáüëá ESTA L√çNEA ES LA CLAVE QUE TE FALTABA üëáüëáüëá
    limpieza_duplicados_startup()
    # üëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜ
    
    print(f"üåê Servidor iniciado en: http://0.0.0.0:{port}")
    print("=" * 60)
    
    uvicorn.run(app, host="0.0.0.0", port=port)