import shutil
import os
import logging
import datetime
import zipfile
import hashlib
import boto3
import cv2 
import numpy as np
import tempfile 
import smtplib
import pytz
import json
import io
import difflib
import psycopg2
from psycopg2.extras import RealDictCursor
import os
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from typing import Optional, List
from fastapi import FastAPI, UploadFile, Form, HTTPException, BackgroundTasks, Request, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse, StreamingResponse
from botocore.config import Config
from pydantic import BaseModel
from fastapi.encoders import jsonable_encoder

# --- 0. CONFIGURACI√ìN DE ZONA HORARIA ECUADOR ---
ECUADOR_TZ = pytz.timezone('America/Guayaquil')  # UTC-5

def ahora_ecuador():
    """Devuelve la fecha/hora actual en zona horaria de Ecuador"""
    return datetime.datetime.now(ECUADOR_TZ)

# --- CONFIGURACI√ìN DE CORREO ---
SMTP_SERVER = "smtp.gmail.com"
SMTP_PORT = 465  # <--- Aseg√∫rate de que sea 465
SMTP_EMAIL = "karlos.ayala.lopez.1234@gmail.com"
SMTP_PASSWORD = "mzjg jvxj mruk qgeb"

# --- 1. CONFIGURACI√ìN Y CREDENCIALES AWS/B2 ---
AWS_ACCESS_KEY = os.environ.get("AWS_ACCESS_KEY")
AWS_SECRET_KEY = os.environ.get("AWS_SECRET_KEY")
AWS_REGION = "us-east-1"
COLLECTION_ID = "estudiantes_db"

# Inicializaci√≥n condicional de AWS Rekognition
try:
    if AWS_ACCESS_KEY and AWS_SECRET_KEY:
        rekog = boto3.client('rekognition', region_name=AWS_REGION, 
                           aws_access_key_id=AWS_ACCESS_KEY, 
                           aws_secret_access_key=AWS_SECRET_KEY)
        print("‚úÖ AWS Rekognition inicializado")
    else:
        rekog = None
        print("‚ö†Ô∏è AWS Rekognition no disponible (credenciales faltantes)")
except Exception as e:
    rekog = None
    print(f"‚ö†Ô∏è Error inicializando AWS Rekognition: {e}")

# Configuraci√≥n Backblaze B2
ENDPOINT_B2 = "https://s3.us-east-005.backblazeb2.com"
KEY_ID_B2 = "00508884373dab40000000001"
APP_KEY_B2 = "K005jvkLLmLdUKhhVis1qLcnU4flx0g"
BUCKET_NAME = "Proyecto-Grado-Karlos-2025"

try:
    my_config = Config(signature_version='s3v4', region_name='us-east-005')
    s3_client = boto3.client('s3', 
                            endpoint_url=ENDPOINT_B2,
                            aws_access_key_id=KEY_ID_B2,
                            aws_secret_access_key=APP_KEY_B2,
                            config=my_config)
    print("‚úÖ Cliente S3 (Backblaze) inicializado")
except Exception as e:
    s3_client = None
    print(f"‚ö†Ô∏è Cliente S3 no disponible: {e}")

# Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

# --- L√ìGICA DE VOLUMEN PERSISTENTE ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_FILENAME = "Bases_de_datos.db"
VOLUMEN_PATH = "/app/datos_persistentes"

# Determinar ruta final de la base de datos
if os.path.exists(VOLUMEN_PATH):
    db_en_volumen = os.path.join(VOLUMEN_PATH, DB_FILENAME)
    if not os.path.exists(db_en_volumen):
        db_original = os.path.join(BASE_DIR, DB_FILENAME)
        if os.path.exists(db_original):
            shutil.copy(db_original, db_en_volumen)
            print(f"‚úÖ Base de datos copiada al volumen persistente: {db_en_volumen}")
    DB_NAME = db_en_volumen
else:
    DB_NAME = os.path.join(BASE_DIR, DB_FILENAME)

print(f"üìÅ Ruta base de datos: {DB_NAME}")

def get_db_connection():
    try:
        # ‚úÖ URL DEL POOLER (La definitiva)
        # Usamos la direcci√≥n 'aws-1-sa-east-1...' que es compatible con Railway.
        # Puerto 6543 (Transaction Mode)
        
        conn_str = "postgresql://postgres.wwrbrabdwhoiougbaskz:1ZulgnaY0cnsz2p4@aws-1-sa-east-1.pooler.supabase.com:6543/postgres?sslmode=require"
        
        # Conectamos directamente (sin trucos de IP manual, ya no hacen falta)
        conn = psycopg2.connect(conn_str)
        conn.cursor_factory = RealDictCursor 
        return conn
    except Exception as e:
        print(f"‚ùå Error CR√çTICO conectando a Supabase: {e}")
        return None

# --- FUNCIONES DE MANTENIMIENTO ---
def optimizar_sistema_db():
    """Ejecuta mantenimiento VACUUM en Supabase"""
    try:
        conn = get_db_connection()
        # En Postgres, VACUUM no puede ejecutarse dentro de una transacci√≥n
        conn.autocommit = True 
        with conn.cursor() as c:
            c.execute("VACUUM")
            c.execute("ANALYZE")
        conn.close()
        print("‚úÖ Sistema optimizado (VACUUM ejecutado en Supabase)")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Alerta menor: No se pudo optimizar DB: {e}")
        return False

class EstadoUsuarioRequest(BaseModel):
    cedula: str
    activo: int

class BackupRequest(BaseModel):
    tipo: str = "completo"

# --- 2. INICIALIZACI√ìN DE BASE DE DATOS - MEJORADA ---
# --- INICIALIZACI√ìN DE TABLAS ---
def init_db_completa():
    print("üîÑ Iniciando configuraci√≥n de base de datos en Supabase...")
    try:
        conn = get_db_connection()
        if not conn:
            print("‚ùå No hay conexi√≥n a BD, abortando init.")
            return
            
        c = conn.cursor()
        
        # 1. Tabla Usuarios
        c.execute('''CREATE TABLE IF NOT EXISTS Usuarios (
            ID SERIAL PRIMARY KEY,
            Nombre TEXT NOT NULL,
            Apellido TEXT NOT NULL,
            CI TEXT UNIQUE NOT NULL,
            Password TEXT NOT NULL,
            Tipo INTEGER DEFAULT 1,
            Foto TEXT,
            Activo INTEGER DEFAULT 1,
            Fecha_Desactivacion TIMESTAMP NULL,
            Ultimo_Acceso TIMESTAMP NULL,
            TutorialVisto INTEGER DEFAULT 0,
            Face_Encoding TEXT,
            Fecha_Registro TIMESTAMP DEFAULT NOW(),
            Email TEXT,
            Telefono TEXT
        )''')
        
        # 2. Tabla Evidencias
        c.execute('''CREATE TABLE IF NOT EXISTS Evidencias (
            id SERIAL PRIMARY KEY,
            CI_Estudiante TEXT NOT NULL,
            Url_Archivo TEXT NOT NULL,
            Hash TEXT NOT NULL,
            Estado INTEGER DEFAULT 1,
            Tipo_Archivo TEXT DEFAULT 'documento',
            Fecha TIMESTAMP DEFAULT NOW(),
            Tamanio_KB REAL DEFAULT 0,
            Asignado_Automaticamente INTEGER DEFAULT 0
        )''')

        # 3. Tabla Solicitudes
        c.execute('''CREATE TABLE IF NOT EXISTS Solicitudes (
            id SERIAL PRIMARY KEY,
            Tipo TEXT NOT NULL,
            CI_Solicitante TEXT NOT NULL,
            Email TEXT,
            Detalle TEXT,
            Evidencia_Reportada_Url TEXT,
            Id_Evidencia INTEGER,
            Resuelto_Por TEXT,
            Respuesta TEXT,
            Fecha TIMESTAMP DEFAULT NOW(),
            Estado TEXT DEFAULT 'PENDIENTE',
            Fecha_Resolucion TIMESTAMP NULL
        )''')
        
        # 4. Tabla Auditoria
        c.execute('''CREATE TABLE IF NOT EXISTS Auditoria (
            id SERIAL PRIMARY KEY,
            Accion TEXT NOT NULL,
            Detalle TEXT,
            IP TEXT,
            Usuario TEXT,
            Fecha TIMESTAMP DEFAULT NOW()
        )''')
        
        # 5. Tabla M√©tricas
        c.execute('''CREATE TABLE IF NOT EXISTS Metricas_Sistema (
            id SERIAL PRIMARY KEY,
            Fecha DATE UNIQUE,
            Total_Usuarios INTEGER DEFAULT 0,
            Total_Evidencias INTEGER DEFAULT 0,
            Solicitudes_Pendientes INTEGER DEFAULT 0,
            Almacenamiento_MB REAL DEFAULT 0
        )''')
        
        # Crear Admin
        c.execute("SELECT CI FROM Usuarios WHERE Tipo=0")
        if not c.fetchone():
            c.execute("INSERT INTO Usuarios (Nombre, Apellido, CI, Password, Tipo, Activo) VALUES (%s,%s,%s,%s,%s,%s)", 
                     ('Admin', 'Sistema', '9999999999', 'admin123', 0, 1))
            print("‚úÖ Usuario admin creado en Supabase")

        # Crear Bandeja Recuperados
        c.execute("SELECT CI FROM Usuarios WHERE CI='9999999990'")
        if not c.fetchone():
            c.execute("INSERT INTO Usuarios (Nombre, Apellido, CI, Password, Tipo, Activo, Foto) VALUES (%s,%s,%s,%s,%s,%s,%s)", 
                     ('Bandeja', 'Recuperados', '9999999990', '123456', 1, 1, ''))
            print("‚úÖ Bandeja de Recuperados creada")
        
        conn.commit()
        conn.close()
        print("‚úÖ Base de datos Supabase inicializada correctamente.")
        
    except Exception as e:
        print(f"‚ùå Error inicializando Supabase: {e}")

# EJECUTAR INICIALIZACI√ìN (¬°Ahora s√≠, al final de las definiciones!)
init_db_completa()

# =========================================================================
# 3. FUNCIONES AUXILIARES
# =========================================================================

def registrar_auditoria(accion: str, detalle: str, usuario: str = "Sistema", ip: str = ""):
    """
    Registra una acci√≥n en la tabla de auditor√≠a con fecha de Ecuador.
    Versi√≥n optimizada para PostgreSQL (Supabase).
    """
    conn = None
    try:
        # 1. Obtener la hora exacta de Ecuador
        fecha_ecuador = ahora_ecuador()
        
        # 2. Establecer conexi√≥n
        conn = get_db_connection()
        if conn:
            c = conn.cursor()
            
            # 3. Ejecutar la inserci√≥n (Usando los nombres de columna de tu init_db_completa)
            c.execute("""
                INSERT INTO Auditoria (Accion, Detalle, Usuario, IP, Fecha) 
                VALUES (%s, %s, %s, %s, %s)
            """, (accion, detalle, usuario, ip, fecha_ecuador))
            
            conn.commit()
            logging.info(f"‚úÖ AUDITORIA REGISTRADA: {accion} - {detalle}")
    except Exception as e:
        logging.error(f"‚ùå Error en auditoria: {e}")
    finally:
        # üõ°Ô∏è FUNCI√ìN CR√çTICA: Cerramos la conexi√≥n siempre para evitar errores de "too many clients"
        if conn:
            conn.close()

def enviar_correo_real(destinatario: str, asunto: str, mensaje: str, html: bool = False) -> bool:
    import requests # Aseg√∫rate de poner 'requests' en tu requirements.txt
    
    # 1. Tu API KEY de Resend
    API_KEY = "re_UgHvnVwc_GoohB6so8khU8mCBmLJB1bzJ" 
    
    try:
        url = "https://api.resend.com/emails"
        payload = {
            # 2. AQU√ç PONES TU DOMINIO
            "from": "Soporte Despertar <soporte@uepdespertar-evidencias.work>",
            "to": [destinatario],
            "subject": asunto,
            "html": mensaje if html else f"<p>{mensaje}</p>"
        }
        headers = {
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json"
        }
        
        response = requests.post(url, json=payload, headers=headers)
        
        if response.status_code in [200, 201]:
            print(f"‚úÖ Correo enviado desde el dominio a {destinatario}")
            return True
        else:
            print(f"‚ùå Error Resend: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå Error de conexi√≥n: {e}")
        return False
    
def calcular_hash(ruta: str) -> str:
    """Calcula hash SHA256 de un archivo"""
    h = hashlib.sha256()
    with open(ruta, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            h.update(chunk)
    return h.hexdigest()

def obtener_tamanio_archivo_kb(ruta: str) -> float:
    """Obtiene el tama√±o de un archivo en KB"""
    try:
        return os.path.getsize(ruta) / 1024
    except:
        return 0

def optimizar_sistema_db():
    """Ejecuta mantenimiento VACUUM en Supabase"""
    try:
        conn = get_db_connection()
        # En Postgres, VACUUM no puede ejecutarse dentro de una transacci√≥n normal
        conn.autocommit = True 
        with conn.cursor() as c:
            c.execute("VACUUM")
            c.execute("ANALYZE")
        conn.close()
        print("‚úÖ Sistema optimizado (VACUUM ejecutado en Supabase)")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Alerta menor: No se pudo optimizar DB: {e}")
        return False

# --- REEMPLAZA TU FUNCI√ìN 'identificar_rostro_aws' POR ESTA ---
def preparar_imagen_aws(ruta_imagen):
    """
    1. Lee la imagen (soporta AVIF si las librer√≠as est√°n instaladas).
    2. La convierte SIEMPRE a JPG (compatible con AWS).
    3. Comprime si pesa m√°s de 5MB.
    """
    MAX_BYTES = 5242880 # 5 MB
    
    try:
        # Intentamos leer con OpenCV
        img = cv2.imread(ruta_imagen)
        
        # Si OpenCV falla (com√∫n con AVIF antiguos), intentamos con PIL (si est√° instalado)
        if img is None:
            try:
                from PIL import Image
                import numpy as np
                pil_img = Image.open(ruta_imagen).convert('RGB')
                img = np.array(pil_img) 
                # Convertir RGB (PIL) a BGR (OpenCV)
                img = img[:, :, ::-1].copy() 
            except ImportError:
                pass # Si no hay PIL, nos rendimos

        # Si despu√©s de todo no pudimos leer la imagen...
        if img is None:
            # Si es AVIF y no pudimos leerla, NO podemos mandarla cruda a AWS. Retornamos None o error.
            if ruta_imagen.lower().endswith('.avif'):
                print("‚ö†Ô∏è Error: No se pudo decodificar AVIF. Instala 'pillow-avif-plugin'.")
                return None
            # Si es JPG/PNG, mandamos crudo
            with open(ruta_imagen, 'rb') as f: return f.read()

        # COMPRESI√ìN / CONVERSI√ìN A JPG
        # Esto transforma el AVIF/WEBP/PNG a un JPG est√°ndar que AWS s√≠ entiende
        _, buffer = cv2.imencode('.jpg', img, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
        return buffer.tobytes()
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error preparando imagen AWS: {e}")
        with open(ruta_imagen, 'rb') as f: return f.read()

def identificar_varios_rostros_aws(imagen_path: str, confidence_threshold: float = 70.0) -> List[str]:
    if not rekog: return []
    cedulas_encontradas = set()
    
    try:
        # 1. Cargar imagen con OpenCV (para recortes)
        img = cv2.imread(imagen_path)
        if img is None: return []
        height, width, _ = img.shape
        
        # 2. Obtener BYTES SEGUROS (Comprimidos si es necesario)
        image_bytes = preparar_imagen_aws(imagen_path)
            
        # 3. Detectar caras en la imagen (usando los bytes seguros)
        response_detect = rekog.detect_faces(Image={'Bytes': image_bytes})
        
        if not response_detect['FaceDetails']: return []

        # 4. Procesar cada cara
        for faceDetail in response_detect['FaceDetails']:
            bbox = faceDetail['BoundingBox']
            x = int(bbox['Left'] * width)
            y = int(bbox['Top'] * height)
            w = int(bbox['Width'] * width)
            h = int(bbox['Height'] * height)
            
            x, y = max(0, x), max(0, y)
            w, h = min(width - x, w), min(height - y, h)
            face_crop = img[y:y+h, x:x+w]
            if face_crop.size == 0: continue

            _, buffer = cv2.imencode('.jpg', face_crop)
            crop_bytes = buffer.tobytes()
            
            try:
                # AQU√ç EST√Å EL CAMBIO CLAVE: MaxFaces=5 (Antes era 1)
                # Esto permite que si dos usuarios tienen la misma cara, AWS devuelva a ambos.
                search_res = rekog.search_faces_by_image(
                    CollectionId=COLLECTION_ID,
                    Image={'Bytes': crop_bytes},
                    MaxFaces=5, 
                    FaceMatchThreshold=confidence_threshold
                )
                
                # Ahora iteramos sobre TODAS las coincidencias encontradas para esa cara
                for match in search_res['FaceMatches']:
                    ced = match['Face'].get('ExternalImageId')
                    if ced: cedulas_encontradas.add(ced)
                    
            except: continue 

        return list(cedulas_encontradas)
    except Exception as e:
        print(f"Error IA Rostros: {e}")
        return []
    

# --- REEMPLAZA TU FUNCI√ìN 'buscar_estudiantes_por_texto' POR ESTA VERSI√ìN CON DEBUG VISUAL ---

def buscar_estudiantes_por_texto(imagen_path: str, cursor): # <--- Ahora recibe un cursor
    if not rekog: return [], []
    cedulas_encontradas = set()
    texto_leido_debug = []
    
    try:
        image_bytes = preparar_imagen_aws(imagen_path)
        response = rekog.detect_text(Image={'Bytes': image_bytes})
        
        palabras_sueltas = [t['DetectedText'].lower() for t in response.get('TextDetections', []) if t['Type'] == 'WORD']
        
        # --- USAMOS EL CURSOR 'cursor' RECIBIDO ---
        cursor.execute("SELECT Nombre, Apellido, CI FROM Usuarios WHERE Tipo=1")
        estudiantes = cursor.fetchall()
        
        for est in estudiantes:
            nombre_db = est.get('Nombre') or est.get('nombre')
            apellido_db = est.get('Apellido') or est.get('apellido')
            ci_db = est.get('CI') or est.get('ci')
            
            # L√≥gica de comparaci√≥n...
            partes = nombre_db.lower().split() + apellido_db.lower().split()
            piezas_validas = {p for p in partes if len(p) > 2}
            
            coincidencias = 0
            for pieza in piezas_validas:
                if difflib.get_close_matches(pieza, palabras_sueltas, n=1, cutoff=0.8):
                    coincidencias += 1
            
            if coincidencias >= 2:
                cedulas_encontradas.add(ci_db)

    except Exception as e:
        print(f"‚ö†Ô∏è Error OCR: {e}")
        
    return list(cedulas_encontradas), texto_leido_debug

def coincidencia_difusa(partes_buscadas, palabras_en_imagen, umbral):
    """
    Verifica si TODAS las 'partes_buscadas' est√°n presentes en 'palabras_en_imagen'
    con cierta tolerancia a errores (umbral).
    """
    aciertos = 0
    # Usamos una copia para no afectar b√∫squedas de otros estudiantes
    pool = palabras_en_imagen.copy()
    
    for parte in partes_buscadas:
        # Busca la palabra m√°s parecida en la 'bolsa' de palabras de la imagen
        matches = difflib.get_close_matches(parte, pool, n=1, cutoff=umbral)
        if matches:
            aciertos += 1
            # Opcional: pool.remove(matches[0]) si quisieras evitar repetir palabras
            
    # √âxito si encontramos TODAS las partes (Ej: Encontr√≥ "Juan" Y encontr√≥ "Perez")
    return aciertos == len(partes_buscadas)

# Funci√≥n auxiliar por si no la tienes
def calcular_hash(file_path):
    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()
    
def calcular_estadisticas_reales() -> dict:
    """Calcula estad√≠sticas REALES filtrando SOLO ESTUDIANTES (Ignora Admins)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # 1. Contar usuarios activos (Estudiantes Tipo 1 activos)
        c.execute("SELECT COUNT(*) as total FROM Usuarios WHERE Tipo = 1 AND Activo = 1")
        fila_usuarios = c.fetchone()
        usuarios_activos = fila_usuarios['total'] if fila_usuarios else 0
        
        # 2. Contar evidencias (SOLO DE ESTUDIANTES - JOIN CON USUARIOS)
        # Esto excluye autom√°ticamente las fotos subidas al perfil del Admin
        c.execute("""
            SELECT COUNT(e.id) as total 
            FROM Evidencias e
            JOIN Usuarios u ON e.CI_Estudiante = u.CI
            WHERE u.Tipo = 1
        """)
        fila_evidencias = c.fetchone()
        total_evidencias = fila_evidencias['total'] if fila_evidencias else 0
        
        # 3. Sumar peso (SOLO DE ESTUDIANTES)
        c.execute("""
            SELECT SUM(e.Tamanio_KB) as peso_total 
            FROM Evidencias e
            JOIN Usuarios u ON e.CI_Estudiante = u.CI
            WHERE u.Tipo = 1
        """)
        fila_peso = c.fetchone()
        resultado_kb = fila_peso['peso_total'] if fila_peso and fila_peso['peso_total'] else 0
        
        # L√≥gica de estimaci√≥n
        total_kb = resultado_kb
        nota_almacenamiento = "Calculado exacto (Solo Estudiantes)"
        
        # Correcci√≥n para cuando hay archivos pero pesan 0
        if total_kb == 0 and total_evidencias > 0:
            total_kb = total_evidencias * 2500 

        tamanio_total_mb = total_kb / 1024
        
        # Costos (Basados solo en consumo de estudiantes)
        costo_rekognition = (total_evidencias / 1000) * 1.0
        costo_almacenamiento = (tamanio_total_mb / 1024) * 0.023
        
        # 4. Solicitudes pendientes
        c.execute("SELECT COUNT(*) as total FROM Solicitudes WHERE Estado = 'PENDIENTE'")
        fila_solicitudes = c.fetchone()
        solicitudes_pendientes = fila_solicitudes['total'] if fila_solicitudes else 0
        
        conn.close()
        
        return {
            "usuarios_activos": usuarios_activos,
            "total_evidencias": total_evidencias,
            "almacenamiento_mb": round(tamanio_total_mb, 2),
            "almacenamiento_gb": round(tamanio_total_mb / 1024, 4),
            "costo_estimado_usd": {
                "rekognition": round(costo_rekognition, 2),
                "almacenamiento": round(costo_almacenamiento, 4),
                "total": round(costo_rekognition + costo_almacenamiento, 2)
            },
            "solicitudes_pendientes": solicitudes_pendientes,
            "nota": nota_almacenamiento
        }
    except Exception as e:
        print(f"Error estadisticas: {e}")
        return {
            "usuarios_activos": 0, "total_evidencias": 0, 
            "almacenamiento_mb": 0, "almacenamiento_gb": 0,
            "solicitudes_pendientes": 0
        }

# =========================================================================
# 4. CONFIGURACI√ìN FASTAPI
# =========================================================================
app = FastAPI(title="Sistema Educativo Despertar", version="7.0")

# Lista de dominios permitidos para conectar con el backend
origins = [
    "https://www.uepdespertar-evidencias.work",  # Tu nuevo dominio principal
    "https://uepdespertar-evidencias.work",      # Versi√≥n sin www
    "https://proyecto-grado-karlos.vercel.app",  # Tu dominio antiguo de Vercel
    "http://localhost:5500",                     # Pruebas locales
    "http://127.0.0.1:5500"                      # Pruebas locales
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins, # <--- Usamos la lista de arriba
    allow_credentials=True,
    allow_methods=["*"],   # Permite GET, POST, DELETE, etc.
    allow_headers=["*"],   # Permite todos los encabezados
)

@app.on_event("startup")
async def startup_event():
    """
    V8.1 - INICIO LIMPIO CORREGIDO
    Se cambi√≥ 'init_db' por 'init_db_completa' para que coincida con tu c√≥digo.
    """
    print("\n" + "="*50)
    print("üöÄ INICIANDO SERVIDOR - MODO PRODUCCI√ìN LIMPIO")
    print("="*50)
    
    try:
        # ‚úÖ CORRECCI√ìN: El nombre correcto de tu funci√≥n es init_db_completa
        init_db_completa() 
        print("‚úÖ Base de datos conectada y estructura verificada.")

        # Protocolo de mantenimiento silenciado para evitar restauraciones autom√°ticas
        
        print("‚úÖ Servidor listo. No se restauraron evidencias antiguas.")
        print("="*50 + "\n")

    except Exception as e:
        print(f"‚ùå Error cr√≠tico en el inicio: {e}")

# =========================================================================
# 5. ENDPOINTS PRINCIPALES
# =========================================================================

@app.get("/")
def home():
    """Endpoint ra√≠z del sistema"""
    return {
        "status": "online", 
        "backend": "Sistema Educativo Despertar V7.0",
        "cors_enabled": True,
        "zona_horaria": "America/Guayaquil (UTC-5)",
        "timestamp": ahora_ecuador().isoformat()
    }

@app.get("/health")
async def health_check():
    """Verifica salud del sistema"""
    try:
        conn = get_db_connection()
        conn.execute("SELECT 1")
        
        # Verificar tablas principales
        c = conn.cursor()
        c.execute("SELECT COUNT(*) as count FROM Usuarios")
        usuarios = c.fetchone()['count']
        
        c.execute("SELECT COUNT(*) as count FROM Evidencias")
        evidencias = c.fetchone()['count']
        
        conn.close()
        
        return JSONResponse(content={
            "status": "healthy",
            "timestamp": ahora_ecuador().isoformat(),
            "database": "connected",
            "estadisticas": {
                "usuarios": usuarios,
                "evidencias": evidencias
            },
            "aws_rekognition": "available" if rekog else "unavailable",
            "s3_storage": "available" if s3_client else "unavailable"
        })
    except Exception as e:
        return JSONResponse(content={
            "status": "unhealthy",
            "error": str(e)
        })

# =========================================================================
# 6. ENDPOINTS DE AUTENTICACI√ìN
# =========================================================================

@app.post("/iniciar_sesion")
async def iniciar_sesion(cedula: str = Form(...), contrasena: str = Form(...)):
    """Maneja el inicio de sesi√≥n asegurando nombres de columnas compatibles con el Frontend"""
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        # Buscamos al usuario por c√©dula
        c.execute("SELECT * FROM Usuarios WHERE CI = %s", (cedula.strip(),))
        u = c.fetchone()
        
        # Obtenemos la contrase√±a sin importar si la columna es 'Password' o 'password'
        pass_db = u.get('password') or u.get('Password') if u else None
        
        if u and pass_db == contrasena.strip():
            # Creamos un diccionario con los nombres EXACTOS que busca biblioteca.html
            datos_para_front = {
                "id": u.get('id') or u.get('ID'),
                "cedula": u.get('ci') or u.get('CI'),
                "nombre": u.get('nombre') or u.get('Nombre'),
                "apellido": u.get('apellido') or u.get('Apellido'),
                "url_foto": u.get('url_foto') or u.get('Url_Foto') or "",
                "email": u.get('email') or u.get('Email') or "",
                "tipo": u.get('tipo') or u.get('Tipo'),
                "tutorial_visto": u.get('tutorial_visto') or u.get('Tutorial_Visto') or 0
            }
            # jsonable_encoder arregla el error de las fechas (datetime)
            return JSONResponse({"autenticado": True, "datos": jsonable_encoder(datos_para_front)})
        
        return JSONResponse({"autenticado": False, "mensaje": "C√©dula o contrase√±a incorrectos."})
    except Exception as e:
        print(f"‚ùå Error en iniciar_sesion: {e}")
        return JSONResponse({"autenticado": False, "mensaje": str(e)})
    finally:
        if conn: conn.close()

@app.post("/buscar_estudiante")
async def buscar_estudiante(cedula: str = Form(...)):
    """
    Versi√≥n √önica y Corregida:
    Trae los datos del estudiante Y su galer√≠a de evidencias.
    """
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Buscamos los datos personales del usuario
        c.execute("SELECT * FROM Usuarios WHERE CI = %s", (cedula.strip(),))
        user = c.fetchone()
        
        if not user:
            return JSONResponse({"status": "error", "mensaje": "Usuario no encontrado"})

        # 2. Buscamos todas sus fotos y videos (ESTO ES LO QUE TE FALTABA)
        c.execute("SELECT * FROM Evidencias WHERE CI_Estudiante = %s ORDER BY id DESC", (cedula.strip(),))
        evidencias = c.fetchall()
        
        # 3. Empaquetamos todo (jsonable_encoder arregla el error de las fechas)
        datos_completos = jsonable_encoder(user)
        datos_completos["galeria"] = jsonable_encoder(evidencias)
        
        # Compatibilidad de nombres para perfil.html
        datos_completos["Url_Foto"] = user.get('foto') or user.get('Foto') or user.get('url_foto')
        
        return JSONResponse({"status": "ok", "datos": datos_completos})
        
    except Exception as e:
        print(f"‚ùå Error en buscar_estudiante: {e}")
        return JSONResponse({"status": "error", "mensaje": str(e)})
    finally:
        if conn: conn.close()
    
# =========================================================================
# 7. ENDPOINTS DE GESTI√ìN DE USUARIOS
# =========================================================================

@app.post("/registrar_usuario")
async def registrar_usuario(
    nombre: str = Form(...),
    apellido: str = Form(...),
    cedula: str = Form(...),
    contrasena: str = Form(...),
    tipo_usuario: int = Form(...),
    email: Optional[str] = Form(None),
    telefono: Optional[str] = Form(None),
    foto: UploadFile = File(...)
):
    """Registra un nuevo usuario con zona horaria Ecuador"""
    try:
        cedula = cedula.strip()
        contrasena = contrasena.strip()
        
        # Validaciones b√°sicas
        if not cedula or not contrasena:
            return JSONResponse(content={
                "error": "La c√©dula y contrase√±a son requeridas"
            })
        
        conn = get_db_connection()
        c = conn.cursor()
        
        # Verificar si usuario ya existe
        c.execute("SELECT CI FROM Usuarios WHERE CI=%s", (cedula,))
        if c.fetchone():
            conn.close()
            return JSONResponse(content={
                "error": "Usuario ya existe en el sistema"
            })
        
        # Manejar archivo de foto
        temp_dir = tempfile.mkdtemp()
        foto_path = os.path.join(temp_dir, foto.filename)
        
        with open(foto_path, "wb") as f:
            shutil.copyfileobj(foto.file, f)
        
        # Subir a almacenamiento
        nombre_nube = f"perfiles/{cedula}_{int(ahora_ecuador().timestamp())}_{foto.filename}"
        url_foto = ""
        
        if s3_client:
            try:
                s3_client.upload_file(
                    foto_path, 
                    BUCKET_NAME, 
                    nombre_nube,
                    ExtraArgs={'ACL': 'public-read'}
                )
                url_foto = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{nombre_nube}"
                print(f"‚úÖ Foto subida a S3: {url_foto}")
            except Exception as e:
                print(f"‚ö†Ô∏è Error subiendo a S3: {e}")
                url_foto = f"/local/perfiles/{foto.filename}"
        else:
            url_foto = f"/local/perfiles/{foto.filename}"
        
        # Insertar usuario con fecha de Ecuador
        fecha_registro = ahora_ecuador()
        
        # üëá CAMBIO CLAVE: Convertimos la fecha a texto simple para evitar errores
        fecha_str = fecha_registro.strftime("%Y-%m-%d %H:%M:%S") 
        
        c.execute("""
            INSERT INTO Usuarios 
            (Nombre, Apellido, CI, Password, Tipo, Foto, Activo, Email, Telefono, Fecha_Registro)
            VALUES (%s,%s,%s,%s,%s,%s,1,%s,%s,%s)
        """, (
            nombre.strip(),
            apellido.strip(),
            cedula,
            contrasena,
            tipo_usuario,
            url_foto,
            email,
            telefono,
            fecha_str  # <--- Usamos la versi√≥n texto, no el objeto fecha
        ))
        
        # Si es estudiante, agregar a colecci√≥n de rostros AWS
        if tipo_usuario == 1 and rekog:
            try:
                with open(foto_path, 'rb') as image_file:
                    image_bytes = image_file.read()
                
                rekog.index_faces(
                    CollectionId=COLLECTION_ID,
                    Image={'Bytes': image_bytes},
                    ExternalImageId=cedula,
                    MaxFaces=1,
                    QualityFilter='AUTO'
                )
                print(f"‚úÖ Rostro indexado en AWS para estudiante {cedula}")
            except Exception as e:
                print(f"‚ö†Ô∏è Error indexando rostro en AWS: {e}")
        
        conn.commit()
        conn.close()
        
        # Limpiar archivos temporales
        shutil.rmtree(temp_dir)
        
        # Registrar auditor√≠a
        registrar_auditoria("REGISTRO_USUARIO", f"Usuario {cedula} registrado")
        
        return JSONResponse(content={
            "mensaje": "Usuario registrado exitosamente",
            "url_foto": url_foto,
            "cedula": cedula,
            "fecha_registro": fecha_registro.isoformat()
        })
        
    except Exception as e:
        print(f"‚ùå Error en registrar_usuario: {e}")
        return JSONResponse(content={"error": str(e)})
    
@app.post("/cambiar_estado_usuario")
async def cambiar_estado_usuario(datos: EstadoUsuarioRequest):
    """Activa/desactiva un usuario en un solo paso (Optimizado)"""
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor) 
        
        fecha_desactivacion = ahora_ecuador() if datos.activo == 0 else None
        
        # ‚úÖ OPTIMIZACI√ìN: 'RETURNING' nos devuelve los datos sin hacer un segundo SELECT
        c.execute("""
            UPDATE Usuarios 
            SET Activo = %s, Fecha_Desactivacion = %s
            WHERE CI = %s
            RETURNING Nombre, Apellido
        """, (datos.activo, fecha_desactivacion, datos.cedula))
        
        user = c.fetchone()
        conn.commit()
        
        # L√≥gica de reporte
        nombre = f"{user['nombre']} {user['apellido']}" if user else "Usuario"
        estado_texto = "activada" if datos.activo == 1 else "desactivada"
        
        registrar_auditoria("CAMBIO_ESTADO", f"Cuenta de {nombre} {estado_texto}", "Admin")
        
        return JSONResponse(content={"mensaje": "OK", "nombre": nombre})
        
    except Exception as e:
        if conn: conn.rollback()
        return JSONResponse(content={"error": str(e)}, status_code=500)
    finally:
        if conn: conn.close()


@app.delete("/eliminar_usuario/{cedula}")
async def eliminar_usuario(cedula: str):
    """Elimina usuario y todos sus datos (Blindado contra errores de may√∫sculas)"""
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. PRIMERO: Obtener y borrar evidencias asociadas (Nube + BD)
        c.execute("SELECT Url_Archivo FROM Evidencias WHERE CI_Estudiante = %s", (cedula,))
        evidencias = c.fetchall()
        
        if s3_client and BUCKET_NAME:
            for ev in evidencias:
                # üõ°Ô∏è CORRECCI√ìN: Buscamos URL con seguridad (May√∫s/Min√∫s)
                url = ev.get('Url_Archivo') or ev.get('url_archivo')
                
                if url and "backblazeb2.com" in url:
                    try:
                        partes = url.split(f"/file/{BUCKET_NAME}/")
                        if len(partes) > 1:
                            s3_client.delete_object(Bucket=BUCKET_NAME, Key=partes[1])
                    except Exception as e:
                        print(f"‚ö†Ô∏è No se pudo borrar archivo B2: {e}")

        # Borrar registros de evidencias
        c.execute("DELETE FROM Evidencias WHERE CI_Estudiante = %s", (cedula,))
        
        # 2. SEGUNDO: Obtener y borrar foto de perfil (Nube)
        c.execute("SELECT Foto FROM Usuarios WHERE CI = %s", (cedula,))
        usuario = c.fetchone()
        
        # üõ°Ô∏è CORRECCI√ìN: Buscamos Foto con seguridad
        if usuario:
            url_foto = usuario.get('Foto') or usuario.get('foto')
            
            if url_foto and s3_client and BUCKET_NAME and "backblazeb2.com" in url_foto:
                try:
                    partes = url_foto.split(f"/file/{BUCKET_NAME}/")
                    if len(partes) > 1:
                        s3_client.delete_object(Bucket=BUCKET_NAME, Key=partes[1])
                except Exception as e:
                     print(f"‚ö†Ô∏è No se pudo borrar foto perfil B2: {e}")

        # 3. TERCERO: Borrar el usuario
        c.execute("DELETE FROM Usuarios WHERE CI = %s", (cedula,))
        
        conn.commit()
        conn.close()
        
        return JSONResponse({"mensaje": "Usuario y todos sus datos eliminados correctamente"})
        
    except Exception as e:
        print(f"‚ùå Error eliminando usuario completo: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
# =========================================================================
# 8. ENDPOINTS DE EVIDENCIAS
# =========================================================================

def garantizar_limite_storage(ruta_archivo, limite_mb=1000):
    """
    Si el archivo supera el limite_mb (ej: 1GB), lo comprime para ahorrar espacio.
    Si no lo supera, lo deja intacto (Calidad Original).
    """
    try:
        peso_actual_mb = os.path.getsize(ruta_archivo) / (1024 * 1024)
        
        # CASO 1: El archivo est√° dentro del l√≠mite (Ej: 500MB) -> NO TOCAR
        if peso_actual_mb <= limite_mb:
            return ruta_archivo # Devolvemos la ruta original
            
        # CASO 2: El archivo es gigante (Ej: 2GB) -> COMPRIMIR
        print(f"‚ö†Ô∏è Archivo gigante ({peso_actual_mb:.2f} MB). Comprimiendo para cumplir cuota de 1GB...")
        
        # Nombre para el archivo comprimido
        dir_name = os.path.dirname(ruta_archivo)
        base_name = os.path.basename(ruta_archivo)
        ruta_comprimida = os.path.join(dir_name, f"compressed_{base_name}")
        
        # Detectar si es VIDEO
        ext = os.path.splitext(ruta_archivo)[1].lower()
        if ext in ['.mp4', '.avi', '.mov', '.mkv']:
            # Usamos OpenCV para reducir resoluci√≥n y bitrate
            cap = cv2.VideoCapture(ruta_archivo)
            
            # Calculamos nueva resoluci√≥n (HD 720p suele ser suficiente y ligero)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            # Si es 4K, lo bajamos a 720p. Si es menor, lo bajamos un 30%
            scale = 0.5 if width > 1920 else 0.7
            new_w, new_h = int(width * scale), int(height * scale)
            
            # Configurar el escritor de video
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(ruta_comprimida, fourcc, 24, (new_w, new_h))
            
            while True:
                ret, frame = cap.read()
                if not ret: break
                # Redimensionar frame
                frame_b = cv2.resize(frame, (new_w, new_h))
                out.write(frame_b)
                
            cap.release()
            out.release()
            
            # Reemplazar archivo original con el comprimido
            if os.path.exists(ruta_comprimida):
                shutil.move(ruta_comprimida, ruta_archivo) # Sobrescribimos el original
                nuevo_peso = os.path.getsize(ruta_archivo) / (1024 * 1024)
                print(f"‚úÖ Compresi√≥n exitosa. Nuevo peso: {nuevo_peso:.2f} MB")
                return ruta_archivo
                
    except Exception as e:
        print(f"‚ö†Ô∏è Error intentando comprimir video storage: {e}")
    
    # Si algo falla o no es video, devolvemos el original
    return ruta_archivo

@app.post("/subir_evidencia_ia")
async def subir_evidencia_ia(archivo: UploadFile = File(...)):
    temp_dir = None
    try:
        # 1. Preparaci√≥n de archivo y c√°lculo de Hash inicial
        temp_dir = tempfile.mkdtemp()
        path = os.path.join(temp_dir, archivo.filename)
        with open(path, "wb") as f: shutil.copyfileobj(archivo.file, f)
        file_hash = calcular_hash(path)
        
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)

        # 2. Identificaci√≥n de tipo y procesamiento con IA (Rostros y Texto)
        ext = os.path.splitext(archivo.filename)[1].lower()
        es_imagen = ext in ['.jpg', '.jpeg', '.png', '.bmp', '.webp', '.avif']
        es_video = ext in ['.mp4', '.avi', '.mov', '.mkv']
        tipo_archivo = "video" if es_video else ("imagen" if es_imagen else "documento")
        
        cedulas_detectadas = set() 
        
        if rekog:
            if es_imagen:
                # Mantiene Rostros + Texto (OCR)
                rostros = identificar_varios_rostros_aws(path)
                cedulas_detectadas.update(rostros)
                textos_ceds, _ = buscar_estudiantes_por_texto(path, c) 
                cedulas_detectadas.update(textos_ceds)
            elif es_video:
                # Mantiene an√°lisis de fotogramas de video con OpenCV
                cap = cv2.VideoCapture(path)
                frame_count = 0
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret or frame_count > 1800: break
                    if frame_count % 60 == 0:
                        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp:
                            _, buffer = cv2.imencode('.jpg', frame)
                            tmp.write(buffer.tobytes())
                            tmp_path = tmp.name
                        rostros_f = identificar_varios_rostros_aws(tmp_path)
                        cedulas_detectadas.update(rostros_f)
                        if os.path.exists(tmp_path): os.remove(tmp_path)
                    frame_count += 1
                cap.release()

        # 3. Verificar existencia f√≠sica (Para no resubir a Backblaze innecesariamente)
        c.execute("SELECT Url_Archivo, Tamanio_KB FROM Evidencias WHERE Hash = %s LIMIT 1", (file_hash,))
        evidencia_existente = c.fetchone()
        
        url_final = ""
        tamanio_kb = 0
        
        if evidencia_existente:
            # Si el archivo ya est√° en el sistema, usamos su URL actual
            url_final = evidencia_existente.get('Url_Archivo') or evidencia_existente.get('url_archivo')
            tamanio_kb = evidencia_existente.get('Tamanio_KB') or evidencia_existente.get('tamanio_kb') or 0
        else:
            # Si es nuevo, subimos a Backblaze
            path_procesado = garantizar_limite_storage(path)
            tamanio_kb = os.path.getsize(path_procesado) / 1024
            url_final = f"/local/{archivo.filename}"
            if s3_client:
                try:
                    nube = f"evidencias/{int(ahora_ecuador().timestamp())}_{archivo.filename}"
                    s3_client.upload_file(path_procesado, BUCKET_NAME, nube, ExtraArgs={'ACL':'public-read'})
                    url_final = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{nube}"
                except: pass

        # 4. ASIGNACI√ìN INTELIGENTE Y REPORTE DETALLADO (Lo que solicitaste)
        asignados_nuevos = []
        ya_tenian = []
        
        if cedulas_detectadas:
            for ced in cedulas_detectadas:
                c.execute("SELECT Nombre, Apellido, Tipo FROM Usuarios WHERE CI=%s", (ced,))
                u = c.fetchone()
                
                if u and (u.get('Tipo') or u.get('tipo')) == 1:
                    nombre_completo = f"{u.get('Nombre') or u.get('nombre')} {u.get('Apellido') or u.get('apellido')}"
                    
                    # Verificamos si ESE estudiante espec√≠fico ya tiene la evidencia
                    c.execute("SELECT id FROM Evidencias WHERE CI_Estudiante = %s AND Hash = %s", (ced, file_hash))
                    if c.fetchone():
                        ya_tenian.append(nombre_completo)
                    else:
                        # Se asigna solo al perfil que no lo tiene
                        c.execute("""
                            INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente) 
                            VALUES (%s, %s, %s, 1, %s, %s, 1)
                        """, (ced, url_final, file_hash, tipo_archivo, tamanio_kb))
                        asignados_nuevos.append(nombre_completo)

            # Construcci√≥n del mensaje de respuesta inteligente
            msg_parts = []
            if asignados_nuevos:
                msg_parts.append(f"‚úÖ Evidencia asignada correctamente a: {', '.join(asignados_nuevos)}.")
            if ya_tenian:
                msg_parts.append(f"‚ÑπÔ∏è Omitiendo a: {', '.join(ya_tenian)} (ya la ten√≠an en su perfil).")
            
            # Caso donde todos ya la ten√≠an
            if not asignados_nuevos and ya_tenian:
                msg = f"‚ö†Ô∏è Todos los usuarios detectados ({', '.join(ya_tenian)}) ya contaban con esta evidencia."
                status = "alerta"
            else:
                msg = " ".join(msg_parts)
                status = "exito"
        else:
            # Nadie detectado -> Se guarda una sola vez en Pendientes si no existe ya
            c.execute("SELECT id FROM Evidencias WHERE Hash = %s AND CI_Estudiante = 'PENDIENTE'", (file_hash,))
            if not c.fetchone():
                c.execute("""
                    INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente) 
                    VALUES ('PENDIENTE', %s, %s, 1, %s, %s, 0)
                """, (url_final, file_hash, tipo_archivo, tamanio_kb))
                msg, status = "‚ö†Ô∏è No se identific√≥ a nadie. Guardado en 'Pendientes'.", "alerta"
            else:
                msg, status = "‚ö†Ô∏è El archivo ya se encuentra en la bandeja de 'Pendientes'.", "alerta"

        conn.commit()
        conn.close()
        if temp_dir: shutil.rmtree(temp_dir)
        return JSONResponse({"status": status, "mensaje": msg})

    except Exception as e:
        if temp_dir: shutil.rmtree(temp_dir)
        print(f"‚ùå Error IA: {e}")
        return JSONResponse({"status": "error", "mensaje": f"Error procesando {archivo.filename}: {str(e)}"})

@app.post("/subir_manual")
async def subir_manual(
    cedulas: str = Form(...), 
    archivo: UploadFile = File(...)
):
    """Sube una evidencia manualmente asignada a una lista de c√©dulas."""
    temp_dir = None
    conn = None
    try:
        # 1. Validar que existan c√©dulas
        lista_cedulas = [c.strip() for c in cedulas.split(",") if c.strip()]
        if not lista_cedulas:
            return JSONResponse(content={"status": "error", "mensaje": "Debe especificar al menos una c√©dula"})
        
        # 2. Guardar archivo temporalmente
        temp_dir = tempfile.mkdtemp()
        path = os.path.join(temp_dir, archivo.filename)
        with open(path, "wb") as f:
            shutil.copyfileobj(archivo.file, f)
        
        file_hash = calcular_hash(path)
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor) # Cursor obligatorio para Postgres
        
        # 3. Verificar si el archivo ya existe globalmente
        c.execute("SELECT id FROM Evidencias WHERE Hash = %s LIMIT 1", (file_hash,))
        if c.fetchone():
            return JSONResponse({"status": "error", "mensaje": "‚ö†Ô∏è ARCHIVO DUPLICADO: Esta evidencia ya existe en el sistema."})
            
        # 4. Procesar y subir a la nube
        path_procesado = garantizar_limite_storage(path)
        tamanio_kb = os.path.getsize(path_procesado) / 1024
        url_final = f"/local/{archivo.filename}"
        
        if s3_client:
            try:
                nombre_nube = f"evidencias/manual_{int(ahora_ecuador().timestamp())}_{archivo.filename}"
                s3_client.upload_file(path_procesado, BUCKET_NAME, nombre_nube, ExtraArgs={'ACL': 'public-read'})
                url_final = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{nombre_nube}"
            except: pass
            
        # 5. Asignar a cada estudiante de la lista
        count = 0
        for ced in lista_cedulas:
            c.execute("SELECT CI FROM Usuarios WHERE CI=%s", (ced,))
            if c.fetchone():
                c.execute("""
                    INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                    VALUES (%s, %s, %s, 1, 'documento', %s, 0)
                """, (ced, url_final, file_hash, tamanio_kb))
                count += 1
        
        conn.commit()
        registrar_auditoria("Subida Manual", f"Archivo {archivo.filename} asignado a {count} estudiantes")
        
        return JSONResponse({"status": "ok", "mensaje": f"‚úÖ √âxito: Archivo asignado a {count} estudiantes."})

    except Exception as e:
        if conn: conn.rollback()
        print(f"‚ùå Error en subir_manual: {e}")
        return JSONResponse({"status": "error", "mensaje": str(e)})
    finally:
        if conn: conn.close()
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
    
# =========================================================================
# 9. ENDPOINTS DE BACKUP Y MANTENIMIENTO
# =========================================================================

@app.get("/crear_backup")
async def crear_backup():
    """Crea y descarga una copia de seguridad de la base de datos"""
    try:
        # Crear nombre de archivo con fecha de Ecuador
        fecha = ahora_ecuador().strftime("%Y%m%d_%H%M%S")
        backup_filename = f"backup_despertar_{fecha}.db"
        backup_path = os.path.join(tempfile.gettempdir(), backup_filename)
        
        # Copiar base de datos
        shutil.copy2(DB_NAME, backup_path)
        
        # Registrar auditor√≠a
        registrar_auditoria("CREACION_BACKUP", f"Backup creado: {backup_filename}")
        
        # Preparar respuesta para descarga directa
        def iterfile():
            with open(backup_path, "rb") as f:
                yield from f
            
            # Eliminar archivo temporal despu√©s de enviar
            os.remove(backup_path)
        
        return StreamingResponse(
            iterfile(),
            media_type="application/x-sqlite3",
            headers={
                "Content-Disposition": f"attachment; filename={backup_filename}",
                "Content-Type": "application/x-sqlite3"
            }
        )
        
    except Exception as e:
        return JSONResponse(content={"error": str(e)})

@app.get("/descargar_multimedia_zip")
async def descargar_multimedia_zip():
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Obtener TODAS las evidencias
        c.execute("SELECT Url_Archivo FROM Evidencias")
        resultados = c.fetchall()
        conn.close()
        
        if not resultados:
            return JSONResponse({"error": "No hay evidencias en el sistema"}, status_code=404)

        # 2. Crear ZIP en memoria
        zip_buffer = io.BytesIO()
        
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for i, item in enumerate(resultados):
                url = item['Url_Archivo']
                # Limpiamos el nombre para el zip
                nombre_archivo = f"backup_{i+1}_{os.path.basename(url)}"
                
                # Descargar de la Nube (B2/S3)
                if s3_client and BUCKET_NAME and ("backblazeb2.com" in url or "s3" in url):
                    try:
                        # Extraer la clave (path) del archivo en el bucket
                        partes = url.split(f"/file/{BUCKET_NAME}/")
                        if len(partes) > 1:
                            file_key = partes[1]
                            file_obj = s3_client.get_object(Bucket=BUCKET_NAME, Key=file_key)
                            file_content = file_obj['Body'].read()
                            zip_file.writestr(nombre_archivo, file_content)
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error backup archivo {url}: {e}")
                        zip_file.writestr(f"ERROR_{i}.txt", f"Fallo al descargar: {url}")
                
                # Soporte para archivos antiguos (locales) si hubiera
                elif os.path.exists(url):
                    try:
                        zip_file.write(url, nombre_archivo)
                    except:
                        pass

        zip_buffer.seek(0)
        
        # Nombre del ZIP con fecha
        fecha_str = datetime.datetime.now().strftime("%Y%m%d")
        nombre_zip = f"Backup_Multimedia_Completo_{fecha_str}.zip"
        
        return StreamingResponse(
            zip_buffer, 
            media_type="application/zip",
            headers={"Content-Disposition": f"attachment; filename={nombre_zip}"}
        )

    except Exception as e:
        print(f"‚ùå Error backup multimedia: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)

from urllib.parse import urlparse
import re
import os

@app.post("/optimizar_sistema")
async def optimizar_sistema(tipo: str = "full"):
    """
    V6.0 - Mantenimiento Inteligente: 
    - Solo borra duplicados si pertenecen AL MISMO ESTUDIANTE.
    - Reporta espacio recuperado con precisi√≥n.
    """
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        mensaje_resultado = []
        
        # ==========================================
        # 1. ANALIZAR DUPLICADOS (POR ESTUDIANTE)
        # ==========================================
        if tipo == "duplicados" or tipo == "full":
            print("üßπ [1/4] Buscando duplicados por estudiante...")
            # Nueva l√≥gica: Agrupamos por Hash Y CI_Estudiante
            c.execute("""
                SELECT Hash, CI_Estudiante, COUNT(*) as cantidad 
                FROM Evidencias 
                WHERE Hash NOT IN ('PENDIENTE', '', 'RECUPERADO') 
                GROUP BY Hash, CI_Estudiante 
                HAVING COUNT(*) > 1
            """)
            grupos = c.fetchall()
            elim_dups = 0
            espacio_kb = 0
            
            for g in grupos:
                hash_val = g.get('Hash') or g.get('hash')
                cedula = g.get('CI_Estudiante') or g.get('ci_estudiante')
                
                # Obtenemos todas las copias de ESE estudiante para ESE archivo
                c.execute("""
                    SELECT id, Url_Archivo, Tamanio_KB 
                    FROM Evidencias 
                    WHERE Hash = %s AND CI_Estudiante = %s 
                    ORDER BY id ASC
                """, (hash_val, cedula))
                copias = c.fetchall()
                
                # Dejamos el primer registro (original del alumno) y borramos el resto
                for copia in copias[1:]:
                    copia_id = copia.get('id')
                    copia_kb = copia.get('Tamanio_KB') or copia.get('tamanio_kb') or 0
                    
                    # NOTA: No borramos de la nube aqu√≠ porque otros alumnos 
                    # podr√≠an estar usando el mismo archivo f√≠sico. Solo borramos el registro.
                    c.execute("DELETE FROM Evidencias WHERE id = %s", (copia_id,))
                    elim_dups += 1
                    espacio_kb += copia_kb
            
            if elim_dups > 0:
                mb_recuperados = round(espacio_kb / 1024, 2)
                mensaje_resultado.append(f"Se eliminaron {elim_dups} duplicados internos. Espacio optimizado: {mb_recuperados} MB.")
            elif tipo == "duplicados":
                mensaje_resultado.append("No se encontraron evidencias repetidas en un mismo perfil.")

        # ==========================================
        # 2. LIMPIAR HU√âRFANOS (VERSION PROTEGIDA)
        # ==========================================
        if tipo == "huerfanos" or tipo == "full":
            print("üëª [2/4] Analizando archivos fantasma con protecci√≥n...")
            c.execute("SELECT id, Url_Archivo FROM Evidencias")
            todas = c.fetchall()
            elim_huerfanos = 0
            
            for ev in todas:
                url = ev.get('Url_Archivo') or ev.get('url_archivo')
                ev_id = ev.get('id')
                
                # SEGURIDAD: Si la URL est√° vac√≠a, no la borramos por si es un error de carga
                if not url: continue 

                existe = True
                if url and "backblazeb2.com" in url and s3_client:
                    try:
                        key = url.split(f"/file/{BUCKET_NAME}/")[1]
                        # Verificamos existencia f√≠sica
                        s3_client.head_object(Bucket=BUCKET_NAME, Key=key)
                    except Exception as e:
                        # üõ°Ô∏è PROTECCI√ìN CR√çTICA: Solo borramos si el error es "404 Not Found"
                        # Si es un error de red o timeout (500, 403), NO BORRAMOS nada.
                        error_str = str(e)
                        if "404" in error_str or "Not Found" in error_str:
                            existe = False
                        else:
                            print(f"‚ö†Ô∏è Salto de seguridad: Error de conexi√≥n con la nube para ID {ev_id}. No se borrar√°.")
                            existe = True 
                
                if not existe:
                    c.execute("DELETE FROM Evidencias WHERE id = %s", (ev_id,))
                    elim_huerfanos += 1
            
            if elim_huerfanos > 0:
                mensaje_resultado.append(f"Limpieza completada: {elim_huerfanos} registros inexistentes eliminados.")

        # ==========================================
        # 3. AUTO-REASIGNACI√ìN (SOLO EN MODO FULL)
        # ==========================================
        if tipo == "full":
            print("üîÑ [3/4] Auto-reasignando evidencias perdidas...")
            c.execute("SELECT CI FROM Usuarios")
            cedulas = [u.get('CI') or u.get('ci') for u in c.fetchall()]
            
            c.execute("SELECT id, Url_Archivo, CI_Estudiante FROM Evidencias")
            evidencias = c.fetchall()
            reasignadas = 0
            
            for ev in evidencias:
                url = ev.get('Url_Archivo') or ev.get('url_archivo')
                ev_id = ev.get('id')
                ev_ci = ev.get('CI_Estudiante') or ev.get('ci_estudiante')
                
                for ci in cedulas:
                    if ci in url and len(ci) >= 10:
                        if ev_ci != ci:
                            c.execute("UPDATE Evidencias SET CI_Estudiante = %s WHERE id = %s", (ci, ev_id))
                            reasignadas += 1
                        break
            
            if reasignadas > 0:
                mensaje_resultado.append(f"Reasignadas {reasignadas} evidencias a sus due√±os correctos.")

        # ==========================================
        # 4. LIMPIAR CACH√â
        # ==========================================
        if tipo == "cache" or tipo == "full":
            print("üöÄ [4/4] Compactando base de datos...")
            conn.commit()
            conn.autocommit = True
            with conn.cursor() as c_vac:
                c_vac.execute("VACUUM")
                c_vac.execute("ANALYZE")
            if tipo == "cache":
                mensaje_resultado.append("Base de datos compactada y optimizada.")

        conn.close()
        
        texto_final = " ".join(mensaje_resultado) if mensaje_resultado else "Mantenimiento completado. Todo en orden."
        return JSONResponse({"status": "ok", "mensaje": texto_final})

    except Exception as e:
        print(f"‚ùå Error en mantenimiento: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
# =========================================================================
# 10. ENDPOINTS DE ESTAD√çSTICAS Y REPORTES
# =========================================================================

@app.get("/estadisticas_almacenamiento")
async def estadisticas_almacenamiento():
    """Versi√≥n OPTIMIZADA: Carga instant√°nea usando conteo r√°pido"""
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Usuarios Activos (R√°pido)
        c.execute("SELECT COUNT(*) as total FROM Usuarios WHERE Tipo = 1 AND Activo = 1")
        usuarios_activos = c.fetchone()['total']
        
        # 2. Total Evidencias (R√°pido)
        c.execute("SELECT COUNT(*) as total FROM Evidencias")
        total_evidencias = c.fetchone()['total']
        
        # 3. Solicitudes Pendientes (R√°pido)
        c.execute("SELECT COUNT(*) as total FROM Solicitudes WHERE Estado = 'PENDIENTE'")
        solicitudes_pendientes = c.fetchone()['total']
        
        # 4. Almacenamiento (Estimaci√≥n Estad√≠stica para velocidad)
        # Usamos 3.5 MB promedio por archivo para no leer disco/nube uno por uno
        tamanho_promedio_mb = 3.5
        total_mb = total_evidencias * tamanho_promedio_mb
        total_gb = round(total_mb / 1024, 4)
        
        # 5. Costos (C√°lculo matem√°tico simple)
        costo_ia = (total_evidencias / 1000) * 1.0
        costo_storage = (total_gb) * 0.005
        costo_total = round(costo_ia + costo_storage, 2)
        
        conn.close()
        
        # Respuesta con la estructura EXACTA que espera tu frontend
        return JSONResponse(content={
            "usuarios_activos": usuarios_activos,
            "total_evidencias": total_evidencias,
            "almacenamiento_mb": round(total_mb, 2),
            "almacenamiento_gb": total_gb,
            "solicitudes_pendientes": solicitudes_pendientes,
            "costo_estimado_usd": {
                "rekognition": round(costo_ia, 2),
                "almacenamiento": round(costo_storage, 4),
                "total": costo_total
            },
            "nota": "Modo Turbo (Estimado)"
        })
        
    except Exception as e:
        print(f"‚ùå Error dashboard: {e}")
        return JSONResponse(content={"error": str(e)})

@app.get("/datos_graficos_dashboard")
async def datos_graficos_dashboard():
    """Provee datos para gr√°ficos del dashboard (Versi√≥n PostgreSQL)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # 1. Evoluci√≥n de registros por mes (TO_CHAR en lugar de strftime)
        c.execute("""
            SELECT TO_CHAR(Fecha_Registro, 'YYYY-MM') as mes,
                   COUNT(*) as cantidad
            FROM Usuarios 
            WHERE Fecha_Registro IS NOT NULL
            GROUP BY mes
            ORDER BY mes DESC
            LIMIT 12
        """)
        evolucion_usuarios = [dict(row) for row in c.fetchall()]
        
        # 2. Distribuci√≥n de tipos de archivo
        c.execute("""
            SELECT Tipo_Archivo, COUNT(*) as cantidad
            FROM Evidencias
            GROUP BY Tipo_Archivo
        """)
        distribucion_archivos = [dict(row) for row in c.fetchall()]
        
        # 3. Solicitudes por estado
        c.execute("""
            SELECT Estado, COUNT(*) as cantidad
            FROM Solicitudes
            GROUP BY Estado
        """)
        solicitudes_estado = [dict(row) for row in c.fetchall()]
        
        # 4. Top 5 estudiantes
        c.execute("""
            SELECT u.Nombre, u.Apellido, u.CI, COUNT(e.id) as total
            FROM Usuarios u
            LEFT JOIN Evidencias e ON u.CI = e.CI_Estudiante
            WHERE u.Tipo = 1
            GROUP BY u.CI
            ORDER BY total DESC
            LIMIT 5
        """)
        top_estudiantes = [dict(row) for row in c.fetchall()]
        
        # 5. Actividad por hora (TO_CHAR y sintaxis de intervalo Postgres)
        c.execute("""
            SELECT TO_CHAR(Fecha, 'HH24') as hora,
                   COUNT(*) as actividades
            FROM Auditoria
            WHERE Fecha >= NOW() - INTERVAL '7 days'
            GROUP BY hora
            ORDER BY hora
        """)
        actividad_horaria = [dict(row) for row in c.fetchall()]
        
        conn.close()
        
        return JSONResponse(content={
            "evolucion_usuarios": evolucion_usuarios,
            "distribucion_archivos": distribucion_archivos,
            "solicitudes_estado": solicitudes_estado,
            "top_estudiantes": top_estudiantes,
            "actividad_horaria": actividad_horaria,
            "fecha_consulta": ahora_ecuador().isoformat()
        })
        
    except Exception as e:
        return JSONResponse(content={"error": str(e)})

# =========================================================================
# 11. ENDPOINTS DE SOLICITUDES Y GESTI√ìN
# =========================================================================
@app.get("/obtener_solicitudes")
def obtener_solicitudes(limit: int = 100):
    try:
        conn = get_db_connection()
        c = conn.cursor()
        c.execute("SELECT * FROM Solicitudes ORDER BY Fecha DESC LIMIT %s", (limit,))
        solicitudes = c.fetchall()
        conn.close()
        
        # ‚úÖ CORRECCI√ìN M√ÅGICA
        sol_serializables = json.loads(json.dumps(solicitudes, default=str))
        
        return JSONResponse(sol_serializables)
    except Exception as e:
        print(f"‚ùå Error obteniendo solicitudes: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
# =========================================================================
# 1. ENDPOINTS DE SOLICITUDES (LADO ESTUDIANTE) - ¬°ESTO ES LO QUE TE FALTA!
# =========================================================================

@app.post("/solicitar_recuperacion")
async def solicitar_recuperacion(
    background_tasks: BackgroundTasks,
    cedula: str = Form(...),
    email: Optional[str] = Form(None),
    mensaje: Optional[str] = Form(None),
    tipo: str = Form("RECUPERACION_CONTRASENA")
):
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Buscar al usuario
        c.execute("SELECT Nombre, Apellido, Email FROM Usuarios WHERE CI=%s", (cedula.strip(),))
        user = c.fetchone()
        
        if not user:
            return JSONResponse({"status": "error", "mensaje": "La c√©dula no est√° registrada."})
            
        email_final = email if email else user.get('email') or user.get('Email') or "Sin correo"
        nombre_completo = f"{user.get('nombre') or user.get('Nombre')} {user.get('apellido') or user.get('Apellido')}"
        
        detalle = f"{tipo.replace('_', ' ')}. "
        if mensaje: detalle += f"Mensaje: {mensaje}"
        
        # 2. Guardar en Base de Datos
        c.execute("""
            INSERT INTO Solicitudes (Tipo, CI_Solicitante, Email, Detalle, Estado, Fecha)
            VALUES (%s, %s, %s, %s, 'PENDIENTE', %s)
        """, (tipo, cedula.strip(), email_final, detalle, ahora_ecuador()))
        
        conn.commit()

        # 3. L√ìGICA DE CORREOS (CORREGIDA)
        # A) Al ADMIN siempre le avisamos que lleg√≥ algo
        asunto_admin = f"üö® Nuevo mensaje de {tipo}"
        cuerpo_admin = f"Usuario: {nombre_completo} ({cedula}).\nTipo: {tipo}\nMensaje: {mensaje}"
        background_tasks.add_task(enviar_correo_real, "karlos.ayala.lopez.1234@gmail.com", asunto_admin, cuerpo_admin)
        
        # B) Al ESTUDIANTE solo le enviamos correo si es RECUPERACI√ìN (confirmaci√≥n)
        # Si es SOPORTE, no le enviamos nada para no saturarlo (es interno)
        if tipo == 'RECUPERACION_CONTRASENA':
             asunto_user = "Solicitud Recibida - U.E. Despertar"
             cuerpo_user = f"Hola {nombre_completo}, hemos recibido tu solicitud de recuperaci√≥n. Te contactaremos pronto."
             background_tasks.add_task(enviar_correo_real, email_final, asunto_user, cuerpo_user)
        
        return JSONResponse({"status": "ok", "mensaje": "Solicitud enviada correctamente."})
    except Exception as e:
        return JSONResponse({"status": "error", "mensaje": str(e)})
    finally:
        if conn: conn.close()

@app.post("/solicitar_subida")
async def solicitar_subida(cedula: str = Form(...), archivo: UploadFile = File(...)):
    """El estudiante sube un archivo para aprobaci√≥n del admin"""
    try:
        # 1. Guardar temporalmente para subir a la nube
        temp_dir = tempfile.mkdtemp()
        path = os.path.join(temp_dir, archivo.filename)
        with open(path, "wb") as f: shutil.copyfileobj(archivo.file, f)
        
        url_archivo = f"/local/{archivo.filename}"
        if s3_client:
            try:
                # Nombre temporal (propuesta)
                nombre_nube = f"evidencias/propuesta_{int(ahora_ecuador().timestamp())}_{archivo.filename}"
                s3_client.upload_file(path, BUCKET_NAME, nombre_nube, ExtraArgs={'ACL': 'public-read'})
                url_archivo = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{nombre_nube}"
            except: pass
        
        shutil.rmtree(temp_dir)
        
        conn = get_db_connection()
        conn.execute("""
            INSERT INTO Solicitudes (Tipo, CI_Solicitante, Detalle, Evidencia_Reportada_Url, Estado, Fecha)
            VALUES ('SUBIR_EVIDENCIA', %s, 'El estudiante desea agregar esta evidencia.', %s, 'PENDIENTE', %s)
        """, (cedula, url_archivo, ahora_ecuador()))
        
        conn.commit()
        conn.close()
        return JSONResponse({"status": "ok", "mensaje": "Archivo enviado a revisi√≥n."})
    except Exception as e:
        return JSONResponse({"status": "error", "mensaje": str(e)})

@app.post("/reportar_evidencia")
async def reportar_evidencia(
    background_tasks: BackgroundTasks, # Necesario para enviar el correo
    cedula: str = Form(...),
    id_evidencia: int = Form(...),
    motivo: str = Form(...)
):
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Obtener datos del estudiante para el correo
        c.execute("SELECT Nombre, Apellido, Email FROM Usuarios WHERE CI = %s", (cedula.strip(),))
        user = c.fetchone()
        nombre_est = f"{user['nombre']} {user['apellido']}" if user else cedula
        email_est = user['email'] if user else "Sin correo"
        
        # 2. Insertar la solicitud en la base de datos
        detalle = f"Reporte de evidencia ID {id_evidencia}. Motivo: {motivo}"
        
        c.execute("""
            INSERT INTO Solicitudes (Tipo, CI_Solicitante, Email, Detalle, Id_Evidencia, Estado, Fecha)
            VALUES ('REPORTE_EVIDENCIA', %s, %s, %s, %s, 'PENDIENTE', %s)
        """, (cedula, email_est, detalle, id_evidencia, ahora_ecuador()))
        
        conn.commit()
        
        # 3. ENVIAR CORREO AL ADMIN (Lo que faltaba)
        asunto = "üö® Reporte de Evidencia Incorrecta"
        cuerpo = f"""
        <h2>Reporte de Estudiante</h2>
        <p><strong>Estudiante:</strong> {nombre_est} ({cedula})</p>
        <p><strong>Evidencia Reportada (ID):</strong> {id_evidencia}</p>
        <p><strong>Motivo:</strong> {motivo}</p>
        <hr>
        <p>Por favor revisa el panel de administraci√≥n para eliminar la evidencia si es necesario.</p>
        """
        background_tasks.add_task(enviar_correo_real, "karlos.ayala.lopez.1234@gmail.com", asunto, cuerpo, True)
        
        return JSONResponse({"status": "ok", "mensaje": "Reporte enviado al administrador."})

    except Exception as e:
        print(f"Error reporte: {e}")
        return JSONResponse({"status": "error", "mensaje": str(e)})
    finally:
        if conn: conn.close()

@app.get("/obtener_solicitudes_por_cedula")
async def obtener_solicitudes_por_cedula(cedula: str):
    """Obtiene el historial de solicitudes de un estudiante con respuestas del admin"""
    conn = None
    try:
        conn = get_db_connection()
        # Usamos cursor para evitar errores en Postgres
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        c.execute("""
            SELECT * FROM Solicitudes 
            WHERE CI_Solicitante = %s 
            ORDER BY Fecha DESC
        """, (cedula.strip(),))
        
        rows = c.fetchall()
        # Convertimos fechas a formato JSON seguro
        return JSONResponse(jsonable_encoder(rows))
    except Exception as e:
        print(f"‚ùå Error historial estudiante: {e}")
        return JSONResponse([])
    finally:
        if conn: conn.close()

# =========================================================================
# AQUI DEBER√çA SEGUIR TU FUNCI√ìN @app.post("/gestionar_solicitud") ...
# =========================================================================

@app.post("/gestionar_solicitud")
async def gestionar_solicitud(
    background_tasks: BackgroundTasks,
    id_solicitud: int = Form(...),
    accion: str = Form(...), 
    mensaje: str = Form(...), 
    id_admin: str = Form("Admin")
):
    conn = None
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor) # <--- INDISPENSABLE para PostgreSQL
        
        # üõ°Ô∏è 1. BLOQUEO DE SEGURIDAD (MULTI-ADMIN)
        c.execute("SELECT Estado, Resuelto_Por FROM Solicitudes WHERE id = %s", (id_solicitud,))
        actual = c.fetchone()
        
        if not actual:
            return JSONResponse({"status": "error", "mensaje": "La solicitud ya no existe."})
        
        # Si el estado ya no es PENDIENTE, detenemos todo para no duplicar correos o acciones
        est_actual = (actual.get('estado') or actual.get('Estado') or 'PENDIENTE').upper()
        if est_actual != 'PENDIENTE':
            quien = actual.get('resuelto_por') or actual.get('Resuelto_Por') or "otro admin"
            return JSONResponse({
                "status": "error", 
                "mensaje": f"‚ö†Ô∏è Esta solicitud ya fue resuelta por: {quien}."
            })

        # 2. OBTENER DATOS DEL ESTUDIANTE Y SOLICITUD
        c.execute("""
            SELECT s.*, u.Nombre, u.Apellido, u.Email as UserEmail
            FROM Solicitudes s
            LEFT JOIN Usuarios u ON s.CI_Solicitante = u.CI
            WHERE s.id = %s
        """, (id_solicitud,))
        sol = c.fetchone()
        
        accion_norm = "APROBADA" if accion.lower() in ['aprobar', 'aceptar', 'aprobada'] else "RECHAZADA"
        fecha_resolucion = ahora_ecuador()
        tipo = sol.get('tipo') or sol.get('Tipo')
        ci_sol = sol.get('ci_solicitante') or sol.get('CI_Solicitante')
        email_destino = sol.get('email') or sol.get('Email') or sol.get('UserEmail')
        nombre_usuario = f"{sol.get('nombre') or sol.get('Nombre')} {sol.get('apellido') or sol.get('Apellido')}"
        
        cuerpo_correo = ""
        es_html = False

        # 3. L√ìGICA DE ACCIONES (SIN QUITAR NADA)
        if tipo == 'REPORTE_EVIDENCIA':
            id_ev = sol.get('id_evidencia') or sol.get('Id_Evidencia')
            if accion_norm == 'APROBADA':
                c.execute("DELETE FROM Evidencias WHERE id=%s", (id_ev,))
                cuerpo_correo = f"Hola {nombre_usuario},\n\nTu reporte ha sido ACEPTADO. La evidencia ha sido eliminada.\n\nAdmin: {mensaje}"
            else:
                cuerpo_correo = f"Hola {nombre_usuario},\n\nTu reporte fue revisado pero la evidencia se mantendr√°.\n\nMotivo: {mensaje}"

        elif tipo == 'SUBIR_EVIDENCIA':
            url_arch = sol.get('evidencia_reportada_url') or sol.get('Evidencia_Reportada_Url')
            if accion_norm == 'APROBADA':
                c.execute("""
                    INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                    VALUES (%s, %s, 'MANUAL_APROBADO', 1, 'documento', 0, 0)
                """, (ci_sol, url_arch))
                cuerpo_correo = f"Hola {nombre_usuario},\n\nTu solicitud de subida fue APROBADA.\n\nAdmin: {mensaje}"
            else:
                cuerpo_correo = f"Hola {nombre_usuario},\n\nTu solicitud de subida fue RECHAZADA.\n\nMotivo: {mensaje}"

        elif tipo == 'RECUPERACION_CONTRASENA':
            es_html = True
            asunto = "üîê Tu nueva clave de acceso - U.E. Despertar"
            cuerpo_correo = f"""
            <div style="font-family: sans-serif; text-align: center; border: 1px solid #ddd; padding: 30px; border-radius: 15px; max-width: 500px; margin: auto;">
                <h2 style="color: #333;">Hola {nombre_usuario},</h2>
                <p style="font-size: 1.1em; color: #555;">Tu nueva contrase√±a es:</p>
                <div style="background-color: #f9f9f9; padding: 25px; margin: 25px 0; border: 2px dashed #000; display: inline-block; border-radius: 10px;">
                    <span style="font-size: 2.5em; font-weight: bold; color: #000;">{mensaje}</span>
                </div>
                <p style="color: #888; font-size: 0.8em;">Soporte T√©cnico - U.E.P. Despertar</p>
            </div>
            """
            background_tasks.add_task(enviar_correo_real, email_destino, asunto, cuerpo_correo, True)
        
        else:
            cuerpo_correo = f"Hola {nombre_usuario},\n\nTu solicitud ha sido procesada: {mensaje}"

        # 4. ACTUALIZAR ESTADO FINAL
        c.execute("""
            UPDATE Solicitudes 
            SET Estado=%s, Resuelto_Por=%s, Respuesta=%s, Fecha_Resolucion=%s
            WHERE id=%s
        """, (accion_norm, id_admin, mensaje, fecha_resolucion, id_solicitud))
        
        conn.commit()

        # 5. ENV√çO DE CORREO (Si no fue de contrase√±a, que ya se envi√≥ arriba)
        if email_destino and not es_html:
            asunto = f"Respuesta a Solicitud: {tipo.replace('_', ' ')}"
            background_tasks.add_task(enviar_correo_real, email_destino, asunto, cuerpo_correo)
        
        return JSONResponse({"status": "ok", "mensaje": f"Gestionado por {id_admin}."})

    except Exception as e:
        if conn: conn.rollback()
        print(f"Error gestionando: {e}")
        return JSONResponse({"status": "error", "mensaje": str(e)})
    finally:
        if conn: conn.close()
        
# =========================================================================
# 12. ENDPOINTS DE LOGS Y AUDITOR√çA
# =========================================================================

@app.get("/obtener_logs")
def obtener_logs():
    try:
        conn = get_db_connection()
        c = conn.cursor()
        c.execute("SELECT * FROM Auditoria ORDER BY Fecha DESC LIMIT 100")
        logs = c.fetchall()
        conn.close()
        
        # ‚úÖ CORRECCI√ìN M√ÅGICA
        logs_serializables = json.loads(json.dumps(logs, default=str))
        
        return JSONResponse(logs_serializables)
    except Exception as e:
        print(f"Error logs: {e}")
        return JSONResponse([])
# =========================================================================
# 13. ENDPOINTS EXISTENTES MANTENIDOS
# =========================================================================

@app.get("/listar_usuarios")
def listar_usuarios():
    """Versi√≥n OPTIMIZADA: Lista usuarios r√°pidamente"""
    try:
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # Traemos solo los campos necesarios, ordenados alfab√©ticamente
        c.execute("""
            SELECT ID, Nombre, Apellido, CI, Password, Tipo, Foto, Activo, Email, Telefono 
            FROM Usuarios 
            ORDER BY Apellido ASC, Nombre ASC
        """)
        usuarios = c.fetchall()
        conn.close()
        
        # Serializaci√≥n segura de fechas y datos
        return JSONResponse(json.loads(json.dumps(usuarios, default=str)))
        
    except Exception as e:
        print(f"‚ùå Error listando usuarios: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
@app.get("/resumen_estudiantes_con_evidencias")
def resumen_estudiantes():
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # Consulta segura
        query = """
            SELECT 
                u.Nombre, u.Apellido, u.CI, u.Foto,
                COUNT(e.id) as total_evidencias,
                COALESCE(SUM(e.Tamanio_KB), 0) as total_kb
            FROM Usuarios u
            LEFT JOIN Evidencias e ON u.CI = e.CI_Estudiante
            WHERE u.Tipo = 1
            GROUP BY u.CI, u.Nombre, u.Apellido, u.Foto
            ORDER BY u.Apellido ASC
        """
        c.execute(query)
        data = c.fetchall()
        conn.close()
        
        # ‚úÖ CORRECCI√ìN: Convertir fechas y datos raros a texto
        import json
        data_serializable = json.loads(json.dumps(data, default=str))
        
        return JSONResponse(data_serializable)
    except Exception as e:
        print(f"‚ùå Error resumen: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
@app.get("/todas_evidencias")
def todas_evidencias(cedula: str):
    try:
        conn = get_db_connection()
        c = conn.cursor()
        # Buscamos por la c√©dula del estudiante
        c.execute("SELECT * FROM Evidencias WHERE CI_Estudiante = %s ORDER BY id DESC", (cedula,))
        evs = c.fetchall()
        conn.close()
        
        # ‚úÖ CORRECCI√ìN: Convertir fechas a texto para que no falle
        import json
        evs_serializables = json.loads(json.dumps(evs, default=str))
        
        return JSONResponse(evs_serializables)
    except Exception as e:
        print(f"‚ùå Error evidencias estudiante: {e}")
        return JSONResponse([])

@app.delete("/eliminar_evidencia/{id}")
async def eliminar_evidencia(id: int):
    try:
        conn = get_db_connection()
        # Usamos RealDictCursor para obtener un diccionario
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Buscar la evidencia
        c.execute("SELECT * FROM Evidencias WHERE id = %s", (id,))
        evidencia = c.fetchone()
        
        if not evidencia:
            conn.close()
            raise HTTPException(status_code=404, detail="Evidencia no encontrada")
            
        # üõ°Ô∏è CORRECCI√ìN: Buscamos la URL con seguridad (may√∫sculas o min√∫sculas)
        url = evidencia.get('Url_Archivo') or evidencia.get('url_archivo')
        
        # 2. Borrar de la Nube (Si tiene URL v√°lida)
        if url and s3_client and BUCKET_NAME and "backblazeb2.com" in url:
            try:
                # Extraer la clave del archivo
                partes = url.split(f"/file/{BUCKET_NAME}/")
                if len(partes) > 1:
                    file_key = partes[1]
                    print(f"üóëÔ∏è Eliminando de B2: {file_key}")
                    s3_client.delete_object(Bucket=BUCKET_NAME, Key=file_key)
            except Exception as e_b2:
                print(f"‚ö†Ô∏è Alerta: Se borr√≥ de BD pero fall√≥ en B2: {e_b2}")

        # 3. Borrar de la Base de Datos
        c.execute("DELETE FROM Evidencias WHERE id = %s", (id,))
        conn.commit()
        conn.close()
        
        return JSONResponse({"mensaje": "Evidencia eliminada correctamente"})
        
    except Exception as e:
        # Imprimimos el error exacto en los logs de Railway
        print(f"‚ùå Error CR√çTICO eliminando evidencia {id}: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
@app.get("/diagnostico_usuario/{cedula}")
async def diagnostico_usuario(cedula: str):
    """Diagn√≥stico completo de un usuario (Versi√≥n PostgreSQL)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # CORRECCI√ìN: Usamos information_schema en lugar de PRAGMA
        c.execute("""
            SELECT column_name, data_type 
            FROM information_schema.columns 
            WHERE table_name = 'usuarios'
        """)
        columnas = c.fetchall()
        
        # Buscar usuario
        c.execute("SELECT * FROM Usuarios WHERE CI = %s", (cedula,))
        usuario = c.fetchone()
        
        # Evidencias del usuario
        c.execute("""
            SELECT COUNT(*) as total, 
                   SUM(Tamanio_KB) as total_kb,
                   Tipo_Archivo,
                   COUNT(*) as cantidad
            FROM Evidencias
            WHERE CI_Estudiante = %s
            GROUP BY Tipo_Archivo
        """, (cedula,))
        estadisticas_evidencias = [dict(r) for r in c.fetchall()]
        
        # Solicitudes del usuario
        c.execute("""
            SELECT Estado, COUNT(*) as cantidad
            FROM Solicitudes
            WHERE CI_Solicitante = %s
            GROUP BY Estado
        """, (cedula,))
        estadisticas_solicitudes = [dict(r) for r in c.fetchall()]
        
        conn.close()
        
        return JSONResponse(content={
            "cedula_buscada": cedula,
            "usuario_encontrado": bool(usuario),
            "usuario": dict(usuario) if usuario else None,
            "estructura_tabla": [dict(r) for r in columnas],
            "estadisticas_evidencias": estadisticas_evidencias,
            "estadisticas_solicitudes": estadisticas_solicitudes,
            "fecha_diagnostico": ahora_ecuador().isoformat(),
            "zona_horaria": "America/Guayaquil (UTC-5)"
        })
        
    except Exception as e:
        return JSONResponse(content={"error": str(e)})

@app.get("/reset-db")
async def reset_database():
    """Reinicia la base de datos (SOLO DESARROLLO)"""
    try:
        init_db_completa()
        return JSONResponse(content={
            "status": "ok",
            "mensaje": "Base de datos reinicializada",
            "fecha": ahora_ecuador().isoformat()
        })
    except Exception as e:
        return JSONResponse(content={"error": str(e)})

# =========================================================================
# 14. ENDPOINTS CORS Y UTILIDADES
# =========================================================================

@app.options("/{rest_of_path:path}")
async def preflight_handler(request: Request, rest_of_path: str):
    """Manejador de preflight CORS"""
    response = JSONResponse(content={"message": "Preflight OK"})
    response.headers["Access-Control-Allow-Origin"] = "*"
    response.headers["Access-Control-Allow-Credentials"] = "true"
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS, PATCH"
    response.headers["Access-Control-Allow-Headers"] = "*"
    return response

@app.get("/cors-debug")
async def cors_debug():
    """Endpoint para debug de CORS"""
    return JSONResponse(content={
        "message": "CORS Debug Endpoint",
        "allow_origin": "*",
        "allow_methods": "GET, POST, PUT, DELETE, OPTIONS, PATCH",
        "allow_headers": "*",
        "allow_credentials": "true",
        "timestamp": ahora_ecuador().isoformat(),
        "zona_horaria": "America/Guayaquil (UTC-5)"
    })

# =========================================================================
# 15. INICIO DE LA APLICACI√ìN
# =========================================================================

class PasswordRequest(BaseModel):
    cedula: str
    nueva_contrasena: str

@app.post("/cambiar_contrasena")
async def cambiar_contrasena(datos: PasswordRequest):
    try:
        conn = get_db_connection()
        conn.execute("UPDATE Usuarios SET Password = %s WHERE CI = %s", (datos.nueva_contrasena, datos.cedula))
        conn.commit()
        conn.close()
        return JSONResponse({"mensaje": "Contrase√±a actualizada correctamente"})
    except Exception as e:
        return JSONResponse({"error": str(e)})
    
@app.post("/descargar_evidencias_zip")
async def descargar_evidencias_zip(ids: str = Form(...)):
    try:
        lista_ids = ids.split(',')
        if not lista_ids:
            return JSONResponse({"error": "No hay IDs"}, status_code=400)
            
        conn = get_db_connection()
        c = conn.cursor(cursor_factory=RealDictCursor)
        
        # Consultar archivos
        placeholders = ','.join(['%s'] * len(lista_ids))
        c.execute(f"SELECT Url_Archivo FROM Evidencias WHERE id IN ({placeholders})", tuple(lista_ids))
        resultados = c.fetchall()
        conn.close()
        
        if not resultados:
            return JSONResponse({"error": "No se encontraron archivos"}, status_code=404)

        # Crear ZIP en memoria
        zip_buffer = io.BytesIO()
        
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for i, item in enumerate(resultados):
                url = item['Url_Archivo']
                nombre_archivo = f"evidencia_{i+1}_{os.path.basename(url)}"
                
                # CASO 1: Archivo en Nube (Backblaze/S3)
                if "backblazeb2.com" in url or "s3" in url:
                    if s3_client and BUCKET_NAME:
                        try:
                            # Extraer key de la URL
                            partes = url.split(f"/file/{BUCKET_NAME}/")
                            if len(partes) > 1:
                                file_key = partes[1]
                                # Descargar de S3 a memoria
                                file_obj = s3_client.get_object(Bucket=BUCKET_NAME, Key=file_key)
                                file_content = file_obj['Body'].read()
                                zip_file.writestr(nombre_archivo, file_content)
                                print(f"üì¶ Agregado al ZIP (Nube): {nombre_archivo}")
                        except Exception as e:
                            print(f"‚ö†Ô∏è Error bajando de nube {url}: {e}")
                            # Crear archivo de texto de error en el zip
                            zip_file.writestr(f"ERROR_{nombre_archivo}.txt", f"No se pudo descargar: {str(e)}")
                
                # CASO 2: Archivo Local (Legado)
                elif os.path.exists(url):
                    try:
                        zip_file.write(url, nombre_archivo)
                        print(f"üì¶ Agregado al ZIP (Local): {nombre_archivo}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error archivo local: {e}")

        zip_buffer.seek(0)
        
        # Nombre del ZIP con fecha
        fecha_str = datetime.datetime.now().strftime("%Y%m%d_%H%M")
        nombre_zip = f"evidencias_seleccion_{fecha_str}.zip"
        
        return StreamingResponse(
            zip_buffer, 
            media_type="application/zip",
            headers={"Content-Disposition": f"attachment; filename={nombre_zip}"}
        )

    except Exception as e:
        print(f"‚ùå Error generando ZIP: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)


from urllib.parse import urlparse 

def limpieza_duplicados_startup():
    """
    V5.4 - CORREGIDA PARA POSTGRESQL (Fix HAVING y Lowercase)
    """
    print("üßπ INICIANDO PROTOCOLO DE LIMPIEZA Y MANTENIMIENTO...")
    
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # ---------------------------------------------------------
        # FASE 0: LIMPIEZA POR URL EXACTA
        # ---------------------------------------------------------
        print("üîç FASE 0: Buscando URLs id√©nticas...")
        # CORRECCI√ìN: Usamos COUNT(*) > 1 en vez de 'cantidad'
        c.execute("""
            SELECT Url_Archivo, COUNT(*) as cantidad FROM Evidencias 
            GROUP BY Url_Archivo HAVING COUNT(*) > 1
        """)
        urls_repetidas = c.fetchall()
        
        eliminados_0 = 0
        for row in urls_repetidas:
            # PostgreSQL devuelve claves en min√∫scula: row['url_archivo']
            url = row['url_archivo'] if 'url_archivo' in row else row['Url_Archivo']
            
            c.execute("SELECT id FROM Evidencias WHERE Url_Archivo = %s ORDER BY id ASC", (url,))
            copias = c.fetchall()
            for copia in copias[1:]: # Borrar todos menos el primero
                c.execute("DELETE FROM Evidencias WHERE id = %s", (copia['id'],))
                eliminados_0 += 1
        
        if eliminados_0 > 0: print(f"   ‚ú® Fase 0: {eliminados_0} registros eliminados.")

        # ---------------------------------------------------------
        # FASE 1: REPARAR ARCHIVOS ANTIGUOS
        # ---------------------------------------------------------
        print("‚è≥ FASE 1: Verificando huellas digitales...")
        c.execute("SELECT id, Url_Archivo FROM Evidencias WHERE Hash = 'PENDIENTE' OR Hash IS NULL")
        pendientes = c.fetchall()
        
        count_hashed = 0
        for row in pendientes:
            try:
                # Soporte para min√∫sculas/may√∫sculas
                url = row.get('Url_Archivo') or row.get('url_archivo')
                id_ev = row.get('id')
                
                temp_path = None
                file_hash = None
                
                if "http" in url and s3_client:
                    try:
                        parsed = urlparse(url)
                        key = parsed.path.lstrip('/')
                        with tempfile.NamedTemporaryFile(delete=False) as tmp:
                            s3_client.download_fileobj(BUCKET_NAME, key, tmp)
                            temp_path = tmp.name
                        file_hash = calcular_hash(temp_path)
                    except: pass 
                elif "/local/" in url:
                    ruta_local = url.replace("/local/", "./")
                    if not os.path.exists(ruta_local):
                         ruta_local = os.path.join(BASE_DIR, url.replace("/local/", "").lstrip("/"))
                    if os.path.exists(ruta_local):
                        file_hash = calcular_hash(ruta_local)

                if file_hash:
                    c.execute("UPDATE Evidencias SET Hash = %s WHERE id = %s", (file_hash, id_ev))
                    count_hashed += 1
                
                if temp_path and os.path.exists(temp_path): os.remove(temp_path)
            except: pass
            
        conn.commit() 

        # (Mant√©n el resto de las fases igual, el error cr√≠tico era la Fase 0)
        # ... Para ahorrar espacio, asumo que dejas las Fases 2, 3 y 4 como estaban
        # pero recuerda que si acceden a columnas deben buscar la versi√≥n en min√∫scula.
        
        conn.close()
        print(f"‚úÖ MANTENIMIENTO FINALIZADO (Fase 0 y 1 completas).")

    except Exception as e:
        print(f"‚ùå Error en limpieza startup: {e}")

        # ---------------------------------------------------------
        # FASE 2: ELIMINAR POR HASH
        # ---------------------------------------------------------
        print("üîç FASE 2: Buscando contenido id√©ntico (Hash)...")
        c.execute("""
            SELECT Hash, COUNT(*) as cantidad FROM Evidencias 
            WHERE Hash NOT IN ('PENDIENTE', '', 'RECUPERADO') GROUP BY Hash HAVING cantidad > 1
        """)
        grupos_hash = c.fetchall()
        
        eliminados_2 = 0
        for grupo in grupos_hash:
            c.execute("SELECT id, Url_Archivo FROM Evidencias WHERE Hash = %s ORDER BY id ASC", (grupo['Hash'],))
            copias = c.fetchall()
            original = copias[0]
            for copia in copias[1:]:
                if s3_client and copia['Url_Archivo'] != original['Url_Archivo'] and BUCKET_NAME in copia['Url_Archivo']:
                    try:
                        parsed = urlparse(copia['Url_Archivo'])
                        key = parsed.path.lstrip('/')
                        s3_client.delete_object(Bucket=BUCKET_NAME, Key=key)
                    except: pass
                
                c.execute("DELETE FROM Evidencias WHERE id = %s", (copia['id'],))
                eliminados_2 += 1
        
        if eliminados_2 > 0: print(f"   ‚ú® Fase 2: {eliminados_2} duplicados exactos eliminados.")

        # ---------------------------------------------------------
        # FASE 3: ELIMINAR POR NOMBRE + ESTUDIANTE
        # ---------------------------------------------------------
        print("üîç FASE 3: Buscando duplicados por nombre de archivo...")
        c.execute("SELECT id, CI_Estudiante, Url_Archivo FROM Evidencias")
        todas = c.fetchall()
        agrupados = {}
        
        for ev in todas:
            url = ev['Url_Archivo']
            cedula = ev['CI_Estudiante']
            filename = os.path.basename(url)
            clean_name = re.sub(r'^\d+_', '', filename)
            clave = f"{cedula}|{clean_name}"
            
            if clave not in agrupados: agrupados[clave] = []
            agrupados[clave].append(ev)
            
        eliminados_3 = 0
        for clave, lista in agrupados.items():
            if len(lista) > 1:
                lista.sort(key=lambda x: x['id'])
                duplicados = lista[1:] 
                for dup in duplicados:
                    c.execute("DELETE FROM Evidencias WHERE id = %s", (dup['id'],))
                    if s3_client and BUCKET_NAME in dup['Url_Archivo']:
                        try:
                            parsed = urlparse(dup['Url_Archivo'])
                            key = parsed.path.lstrip('/')
                            s3_client.delete_object(Bucket=BUCKET_NAME, Key=key)
                        except: pass
                    eliminados_3 += 1

        if eliminados_3 > 0: print(f"   ‚ú® Fase 3: {eliminados_3} archivos eliminados por nombre.")

        # ---------------------------------------------------------
        # FASE 4: SINCRONIZACI√ìN SEGURA CON NUBE
        # ---------------------------------------------------------
        print("‚òÅÔ∏è FASE 4: Auditando existencia real en la nube...")
        conn.commit()
        c.execute("SELECT id, Url_Archivo FROM Evidencias")
        evidencias = c.fetchall()
        
        actualizados_peso = 0
        eliminados_nube = 0
        
        for ev in evidencias:
            url = ev['Url_Archivo']
            existe = False
            peso_kb = 0
            
            if s3_client and BUCKET_NAME in url:
                try:
                    parsed = urlparse(url)
                    key = parsed.path.lstrip('/')
                    meta = s3_client.head_object(Bucket=BUCKET_NAME, Key=key)
                    peso_kb = meta['ContentLength'] / 1024
                    existe = True
                except Exception as e:
                    if "404" in str(e) or "Not Found" in str(e): existe = False
                    else: existe = True 
            elif "/local/" in url:
                existe = True 
            
            if existe:
                c.execute("UPDATE Evidencias SET Tamanio_KB = %s WHERE id = %s", (peso_kb, ev['id']))
                actualizados_peso += 1
            else:
                c.execute("DELETE FROM Evidencias WHERE id = %s", (ev['id'],))
                eliminados_nube += 1
        
        conn.commit()
        print(f"‚úÖ FASE 4 COMPLETADA: {actualizados_peso} actualizados, {eliminados_nube} eliminados.")
        
        # Actualizar m√©tricas
        try:
            stats = calcular_estadisticas_reales()
            fecha_hoy = ahora_ecuador().date().isoformat()
            
            # Usar conexi√≥n nueva para m√©tricas para evitar conflictos
            conn_metricas = get_db_connection()
            c_met = conn_metricas.cursor()
            c_met.execute("""
                INSERT INTO Metricas_Sistema 
                (Fecha, Total_Usuarios, Total_Evidencias, Solicitudes_Pendientes, Almacenamiento_MB)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (Fecha) DO UPDATE SET
                Total_Usuarios = EXCLUDED.Total_Usuarios,
                Total_Evidencias = EXCLUDED.Total_Evidencias,
                Solicitudes_Pendientes = EXCLUDED.Solicitudes_Pendientes,
                Almacenamiento_MB = EXCLUDED.Almacenamiento_MB
            """, (fecha_hoy, stats.get("usuarios_activos",0), stats.get("total_evidencias",0), 
                  stats.get("solicitudes_pendientes",0), stats.get("almacenamiento_mb",0)))
            conn_metricas.commit()
            conn_metricas.close()
        except Exception as e:
            print(f"‚ö†Ô∏è Error menor actualizando m√©tricas: {e}")
        
        conn.close()
        print(f"‚úÖ MANTENIMIENTO TOTAL FINALIZADO.")

    except Exception as e:
        print(f"‚ùå Error en limpieza startup: {e}")
@app.post("/recuperar_evidencias_nube")
async def recuperar_evidencias_nube(background_tasks: BackgroundTasks):
    """
    Escanea TODO el bucket de Backblaze, encuentra los archivos que faltan en la BD
    y los restaura autom√°ticamente (intentando usar IA para re-asignarlos).
    """
    def tarea_rescate():
        print("üöë INICIANDO OPERACI√ìN RESCATE DE EVIDENCIAS...")
        if not s3_client:
            print("‚ùå No hay conexi√≥n S3 para el rescate.")
            return

        conn = get_db_connection()
        c = conn.cursor() # <--- IMPORTANTE: Creamos el cursor aqu√≠
        restaurados = 0
        
        try:
            # 1. Listar TODOS los objetos en la carpeta 'evidencias/' de la nube
            paginator = s3_client.get_paginator('list_objects_v2')
            pages = paginator.paginate(Bucket=BUCKET_NAME, Prefix='evidencias/')
            
            for page in pages:
                if 'Contents' not in page: continue
                
                for obj in page['Contents']:
                    key = obj['Key'] # Ejemplo: evidencias/123_foto.jpg
                    
                    # Ignoramos carpetas vac√≠as
                    if key.endswith('/'): continue
                    
                    # Construimos la URL que deber√≠a tener
                    url_archivo = f"https://{BUCKET_NAME}.s3.us-east-005.backblazeb2.com/{key}"
                    
                    # 2. Verificar si ya existe en la BD (Usando el cursor 'c')
                    c.execute("SELECT id FROM Evidencias WHERE Url_Archivo = %s", (url_archivo,))
                    existe = c.fetchone()
                    
                    if not existe:
                        print(f"   üì• Recuperando: {key}...")
                        
                        # Descargar para an√°lisis IA (si es imagen)
                        temp_path = None
                        ci_detectada = '9999999990' # Por defecto a bandeja recuperados
                        asignado_auto = 0
                        
                        try:
                            # Descargar archivo temporal
                            with tempfile.NamedTemporaryFile(delete=False) as tmp:
                                s3_client.download_fileobj(BUCKET_NAME, key, tmp)
                                temp_path = tmp.name
                            
                            # Intentar reconocer rostros para re-asignar
                            if key.lower().endswith(('.jpg', '.jpeg', '.png', '.webp', '.avif')) and rekog:
                                try:
                                    rostros = identificar_varios_rostros_aws(temp_path)
                                    if rostros:
                                        # Si encuentra rostros, buscamos si son estudiantes
                                        for rostro in rostros:
                                            c.execute("SELECT CI FROM Usuarios WHERE CI=%s", (rostro,))
                                            u = c.fetchone()
                                            if u:
                                                ci_detectada = u['CI']
                                                asignado_auto = 1
                                                break
                                except: pass
                            
                            # Calcular Hash nuevo
                            nuevo_hash = calcular_hash(temp_path)
                            size_kb = obj['Size'] / 1024
                            
                            # Insertar en BD (Usando el cursor 'c')
                            tipo = 'video' if key.lower().endswith(('.mp4', '.avi')) else 'imagen'
                            c.execute("""
                                INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                                VALUES (%s, %s, %s, 1, %s, %s, %s)
                            """, (ci_detectada, url_archivo, nuevo_hash, tipo, size_kb, asignado_auto))
                            
                            restaurados += 1
                            
                            if temp_path and os.path.exists(temp_path): os.remove(temp_path)
                            
                        except Exception as e:
                            print(f"   ‚ö†Ô∏è Error parcial recuperando {key}: {e}")
                            # Intentamos insertar aunque sea sin IA
                            try:
                                c.execute("""
                                    INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                                    VALUES ('9999999990', %s, 'RECUPERADO', 1, 'desconocido', 0, 0)
                                """, (url_archivo,))
                                restaurados += 1
                            except: pass

            conn.commit()
            print(f"‚úÖ OPERACI√ìN RESCATE FINALIZADA: {restaurados} evidencias restauradas.")
            
            # Actualizar estad√≠sticas (Usando el cursor 'c')
            try:
                stats = calcular_estadisticas_reales()
                fecha = ahora_ecuador().date().isoformat()
                c.execute("""
                    INSERT INTO Metricas_Sistema (Fecha, Total_Evidencias, Almacenamiento_MB) 
                    VALUES (%s, %s, %s)
                    ON CONFLICT (Fecha) DO UPDATE SET
                    Total_Evidencias = EXCLUDED.Total_Evidencias,
                    Almacenamiento_MB = EXCLUDED.Almacenamiento_MB
                """, (fecha, stats.get('total_evidencias',0), stats.get('almacenamiento_mb',0)))
                conn.commit()
            except Exception as e:
                print(f"‚ö†Ô∏è Error actualizando m√©tricas tras rescate: {e}")

        except Exception as e:
            print(f"‚ùå Error cr√≠tico en rescate: {e}")
        finally:
            conn.close()

    background_tasks.add_task(tarea_rescate)
    return JSONResponse({"mensaje": "üöë Rescate iniciado. Revisa los logs en 2 minutos."})

class ReasignarRequest(BaseModel):
    ids: str
    cedula_destino: str


    # --- AGREGA ESTE NUEVO ENDPOINT PARA RECUPERAR TUS DATOS ---

@app.post("/reasignar_evidencias")
async def reasignar_evidencias(datos: ReasignarRequest):
    """
    V2.0 - Reasignaci√≥n Multi-Destino:
    - Permite enviar una lista de c√©dulas destino (separadas por comas).
    - Al primer destino le MUEVE el archivo.
    - A los siguientes destinos les crea una COPIA (Clon) en la base de datos.
    """
    try:
        if not datos.ids or not datos.cedula_destino:
            return JSONResponse({"error": "Faltan datos"})
            
        ids_evidencias = [id.strip() for id in datos.ids.split(',') if id.strip()]
        cedulas_destino = [ced.strip() for ced in datos.cedula_destino.split(',') if ced.strip()]
        
        if not ids_evidencias or not cedulas_destino:
             return JSONResponse({"error": "Selecci√≥n inv√°lida"})

        conn = get_db_connection()
        c = conn.cursor()
        
        movidos = 0
        clonados = 0
        
        # 1. Obtener datos originales de las evidencias antes de moverlas
        placeholders = ','.join(['%s'] * len(ids_evidencias))
        evidencias_originales = c.execute(f"SELECT * FROM Evidencias WHERE id IN ({placeholders})", ids_evidencias).fetchall()

        # 2. PROCESAR CADA EVIDENCIA
        for ev in evidencias_originales:
            # A) Mover al PRIMER estudiante de la lista (UPDATE)
            primer_destino = cedulas_destino[0]
            c.execute("UPDATE Evidencias SET CI_Estudiante = %s, Asignado_Automaticamente = 0 WHERE id = %s", (primer_destino, ev['id']))
            movidos += 1
            
            # B) Clonar para el RESTO de estudiantes (INSERT)
            if len(cedulas_destino) > 1:
                for otro_destino in cedulas_destino[1:]:
                    c.execute("""
                        INSERT INTO Evidencias (CI_Estudiante, Url_Archivo, Hash, Estado, Tipo_Archivo, Tamanio_KB, Asignado_Automaticamente)
                        VALUES (%s, %s, %s, %s, %s, %s, 0)
                    """, (otro_destino, ev['Url_Archivo'], ev['Hash'], ev['Estado'], ev['Tipo_Archivo'], ev['Tamanio_KB']))
                    clonados += 1

        conn.commit()
        conn.close()
        
        mensaje = f"‚úÖ Archivos movidos a 1 estudiante."
        if clonados > 0:
            mensaje += f" Y se crearon copias para {len(cedulas_destino)-1} estudiantes m√°s."
        
        return JSONResponse({"mensaje": mensaje})
        
    except Exception as e:
        return JSONResponse({"error": str(e)})

# --- ENDPOINT DE EMERGENCIA PARA CORREGIR ADMIN ---
@app.get("/reparar_admin")
async def reparar_admin():
    """Fuerza al usuario 9999999999 a ser Administrador (Tipo 0)"""
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # 1. Verificar si existe
        c.execute("SELECT * FROM Usuarios WHERE CI = '9999999999'")
        user = c.fetchone()
        
        if not user:
            # Si no existe, lo creamos de cero
            c.execute("""
                INSERT INTO Usuarios (Nombre, Apellido, CI, Password, Tipo, Activo) 
                VALUES ('Admin', 'Sistema', '9999999999', 'admin123', 0, 1)
            """)
            mensaje = "Usuario Admin no exist√≠a. CREADO exitosamente."
        else:
            # Si existe, LO FORZAMOS a ser Tipo 0
            c.execute("UPDATE Usuarios SET Tipo = 0, Activo = 1 WHERE CI = '9999999999'")
            mensaje = "Usuario 9999999999 actualizado: AHORA ES ADMIN (Tipo 0)."
            
        conn.commit()
        conn.close()
        return JSONResponse({"status": "ok", "mensaje": mensaje})
        
    except Exception as e:
        return JSONResponse({"error": str(e)})

if __name__ == "__main__":
    import uvicorn
    
    # Configuraci√≥n del puerto
    port = int(os.environ.get("PORT", 8000))
    
    print("=" * 60)
    print("üöÄ SISTEMA EDUCATIVO DESPERTAR - BACKEND V7.0")
    print("=" * 60)
    print(f"üìÅ Base de datos: {DB_NAME}")
    print(f"üåç Zona horaria: America/Guayaquil (UTC-5)")
    print(f"ü§ñ AWS Rekognition: {'‚úÖ Disponible' if rekog else '‚ùå No disponible'}")
    print(f"üíæ S3 Storage: {'‚úÖ Disponible' if s3_client else '‚ùå No disponible'}")
    print(f"üìß Servidor SMTP: {'‚úÖ Configurado' if SMTP_EMAIL and 'tu_correo' not in SMTP_EMAIL else '‚ö†Ô∏è Simulado'}")
    print(f"üîê Usuario admin: 9999999999 / admin123")
    
    # üëáüëáüëá ESTA L√çNEA ES LA CLAVE QUE TE FALTABA üëáüëáüëá
    limpieza_duplicados_startup()
    # üëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜüëÜ
    
    print(f"üåê Servidor iniciado en: http://0.0.0.0:{port}")
    print("=" * 60)
    
    uvicorn.run(app, host="0.0.0.0", port=port)